understanding the jvm advanced features and best practices

java虚拟机在千差万别的物理机上面建立了统一的运行平台，实现了在任意一台java虚拟机上编译的程序，都能在任何其他java虚拟机上正常运行。

如何布老街虚拟机诸多技术特性的运行原理，无法写出最适合虚拟机运行和自优化的代码

需要对虚拟机的特性及调节方法具有很清晰的认识

学习虚拟机中各种自动运作特性的原理也是java程序员成长路上最终必然会接触到的一课

http://www.hzbook.com

拥抱变化

了解虚拟机如何执行程序， 才能更好滴理解怎样才能写出优秀的代码

了解并发的内幕，必须课程

java虚拟机规范
java语言规范
垃圾回收算法手册：自动内存管理的艺术
Virtual Machines: Versatile Platforms for Systems and Processes
java性能优化权威指南

世界上并没有完美的程序，但我们并不因此而沮丧，因为写程序本来就是一个不断追求完美的过程

不可忽视有点：
+ 摆脱了硬件平台的束缚，实现“一次编写，到处运行”
+ 提供一种相对安全的内存管理和访问机制，避免大部分内存泄露和指针越界问题
+ 实现热点代码检测和运行时编译及优化，使得java应用能随着运行时间的增长而获得更高的性能
+ 有一套完整的应用程序接口，还有无数的第三方类库

情不自禁想去了解java技术体系中，这些优秀的技术特性是如何出现及怎样实现？
认识这些技术运行的本质，是自己思考“程序这样写好不好”的必要基础与前提。
当再用一门技术时，不再依赖书本和他人就能得到这些问题的答案，才算是升华到“不惑”的境界

JDK(java Development Kit):用于支持java程序开发的最小环境
+ java程序设计语言
+ java虚拟机
+ java类库

JRE(java Runtime Environment)，支持java程序运行的标准环境
+ java类库API中的java SE API子集
+ java虚拟机

J2EE(Java 2 Platform, Enterprise Edition)

jdk1.2中java虚拟机第一次内置了JIT(Just In Time)即时编译器
1999年，HotSpot虚拟机诞生，jdk1.3以后称为默认的java虚拟机

2006年，sun计划开源java，建立OpenJDK组织对这些源码独立管理。
oracle收购sun后，jdk7的B计划，主要措施是吧不能按时完成的lambda、jigsaw项目和Coin项目部分改进推迟到jdk8

为保证日后jdk研发能更顺利地进行，从jdk8开始，oracle启用JEP(JDK Enhancement Proposals)来定义和管理纳入新版jdk发布范围的功能特性


Classic VM->Exact vm(Exact Memory Management)精确管理内存，知道数据的类型是值还是引用->HotSpot VM

HotSpot虚拟机的热点代码探测能力可以通过执行计数器找出最具有编译价值的代码，然后通过即使编译器以方法为单位进行编译。
若一个方法被频繁调用或方法中有效循环次数很多，将会分别出发标准即时编译和粘上替换(On-Stack Replacement,OSR)行为。

通过编译器和解释器恰当的协同工作，可以在最优的程序相应时间与最佳执行性能中取得平衡，无需等待本地代码输出才能执行程序，即使编译的时间压力
也相对减小，有助于引入更复杂的代码优化技术，输出高质量的本地代码。

java天下第一的底气来自于它庞大的用户群和及其成熟的软件生态。

HotSpot虚拟机中含有两个即时编译器:
+ 编译耗时短单输出代码优化程度较低的客户端编译器(CI)
+ 编译耗时长单输出代码优化质量也更高的服务端编译器(C2)
  通常他们会在分层编译机制下与解释器互相配合来共同构成HotSpot虚拟机的执行子系统
  jdk10起，又加入了一个即使编译器，Graal编译器，准备取代C2

AOT(Ahead of Time Compliation)，提前编译，最大好处是java虚拟机加载这些已经预编译成二进制库之后就能直接调用，而无需再等待即使编译器在
运行时将其编译成二进制机器码。
不过也破坏了java的“一次编写，到处运行”承诺，必须为每个不同的硬件、操作系统去编译对应的发型包；也显著降低了java连接过程的动态性，必须要求加载
的代码在编译期就全部已知，不能再运行期才确定。
Substrate VM满足对java提前编译的期待。在Graal VM 0.20版本出现的一个极小型的运行时环境，包括独立的异常处理、同步调度、线程管理、内存管理(垃圾
收集)和JNI访问等组件，目标是替代HotSpot用来支持提前编译后的程序执行。好处是能显著降低内存占用及启动时间。
轻量特性，非常适合嵌入其他系统。

HotSpot的定位是面向各种不同应用场景的全功能java虚拟机。团队正在持续地重构这HotSpot的架构，让它具有模块化的能力和足够的开放性，扩展性。
实现功能特性的组合拆分，是接口与实现的分离。

一门语言的功能、语法是影响语言生产力和效率的重要因素

想要窥探java虚拟机内部的实现原理，最直接的一条路径就是编译一套自己的jdk，通过阅读和跟踪调试jdk源码来了解java技术体系的运作。

等待openjdk7达到可正式对外发布的状态后，就从openjdk7的主分支延伸出用于研发jdk8以及用于发布更新补丁的openjdk7update两分支，
新的功能或bug修复通常在最新分支上进行，当功能或修复在最新分支上稳定后悔同步到其他老版本的维护分支上。

openjdk主页：http://openjdk.java.net/

## 编译openjdk
### 处理依赖
下载openjdk12源码：
https://hg.openjdk.java.net/jdk/jdk12/，点击左边Browse，再点击左边zip，171MB，解压后未579MB

认真阅读一遍源码中的doc/building.html文档

安装jdk11(Bootstrap JDK)

安装XCode
上App Store进行下载xcode，然后运行下程序，然后统一并install 一下components

安装Command Line Tools for XCode
xcode-select --install

编译freetype
brew install freetype(The FreeType Project)
brew install libx11(X Window Systme)
brew install libffi(Protable Froeign Function Interface Library)


./configure --help报错
Runnable configure script is not present
Generating runnable configure script at /Users/chaoli/softwares/jdk12-06222165c35f/build/.configure-support/generated-configure.sh

Autoconf is not found on the PATH, and AUTOCONF is not set.
You need autoconf to be able to generate a runnable configure script.
You might be able to fix this by running 'brew install autoconf'.
Error: Cannot find autoconf

安装autoconf
从http://ftp.gnu.org/gnu/autoconf/下载最新，然后
cd autoconf-2.71

### 编译
./configure --prefix=/usr/local
make
sudo make install


./configure --help
--with-debug-level=<level>：设定编译的级别，release(默认)/fastdebug/slowdebug，越后面优化越少，调试信息越多，
--enable-debug：等效于--with-debug-level=fastdebug
-with-native-debug-symbols=<method>：确定调试符号信息的编译方式，none/internal/external/zipped
--with-version-string=<string>：设置编译jdk的版本括号，在java -version的输出会显示，
--with-jvm-variants=<variant>[,<variant>...]：编译特定模式(Variants)的hostspot虚拟机，server/client/minimal/core/zero/custom
--with-jvm-features=<feature>[,<feature>]：针对--with-jvm-variants=custom时的自定义虚拟机特性列表(futures)
--with-target-bits=<bits>：指明要编译32位还是64位的java虚拟机，
--with-<lib>=<path>：指明依赖包的具体路径，lib可选boot-jd/freettype/cups/x/alsa/libffi/jtreg/libjpeg/giflib/libpng/lcms/zlib
--with-extra-<flagtype>=<flags>：用于设定c、c++和java代码编译时的额外编译器参数，flagtype可选cflags/cxxflags/ldflags代表c、c++和java代码的参数
--with-conf-name=<name>：指定编译配置名称，如linux-x86_64-server-release
--disable-warnings-as-errors：do not consider native warnings to be an error，不让warning打断编译过程

直接用./configure可以通过错误看到相关依赖内容没有，然后进行安装

注：configure命令承担了依赖项检查、参数配置和构建输出目录结构等多项职责

如：编译fastdebug版、仅含有server模式的hotspot虚拟机：
configure --enable-debug --with-jvm-variants=server
自己编译用
configure --with-debug-level=slowdebug --disable-warnings-as-errors
网上
configure --with-debug-level=slowdebug --enable-dtrace --with-jvm-variants=server --with-target-bits=64 --enable-ccache --with-num-cores=8 --with-memory-size=8000  --disable-warnings-as-errors

执行整个openjdk编译
make images(是product-images编译目标的简写别名，此目标的作用是便溢出整个jdk镜像)
除了product-images外，其他编译目标：
+ hotspot：值编译HotSpot虚拟机
+ hotspot-<variant>：只编译特定模式的HotSpot虚拟机
+ docs-image：产生jdk的文档镜像
+ test-image：产生jdk的测试镜像
+ all-images：相当于连续调用product、docs、test
+ bootcycle-images：编译两次jdk，第二次使用第一次的编译结果作为Bootstrap jdk
+ clean：清理make命令产生的临时文件
+ dis-clean：清理make和configure命令产生的临时文件

注：make过程中会在"build/配置名称"目录下产生如下目录结构，若多次编译，需要make clean和make dist-clean清理目录后才能确保新的配置生效。
+ buildtools/  用于生成、存放编译过程中用到的工具
+ hotspot/  Hotspot虚拟机编译的中间文件
+ images/  使用make *-image产生的镜像放这里
+ jdk/  编译后产生的JDK放这里
+ support/  存放编译时产生的中间文件
+ test-results/  存放编译后的自动化测试结果
+ configure-support/  这三个目录放的是执行configure、make和test的临时文件
+ make-support/
+ test-support/

验证
./build/macosx-x86_64-server-slowdebug/jdk/bin/java -version


## debug
### 用clion导入openjdk
new cmake projcet from source->选择openjdk根目录-ok，会导入源码并自动创建好CMakeLists.txt
按照clion提示选择创建CMakeLists.txt

cmake地址，不过没有12的。。
https://github.com/ojdkbuild/ojdkbuild/blob/master/src/java-12-openjdk/CMakeLists.txt

### 设定并启动
在Run/Debug Configurations中增加一个CMake Applicaiton，
Target用All targets
在Executable选择刚才编译出的java可执行文件，
program arguments:参数加上-version或某个Class文件的路径,
把Before launch里的Build去掉，可以开始运行调试

调试java代码执行时，若要跟踪具体的java代码在虚拟机中如何执行的，目前HotSpot在主流的操作系统上，都采用模板解释器来执行字节码，与即使编译器一样，
最终执行的汇编代码都是运行期间产生的，无法直接设置断点，一下参数方便开发调试解释器
-XX:+TraceBytecodes -XX:StopInterpreterAt=<n>
作用是：当遇到序号为<n>的字节码指令时，便会中断程序执行，进入断掉调试。

Hot-Spot虚拟机启动器的执行入口是java.c的JavaMain()方法
在/Users/chaoli/softwares/jdk12-06222165c35f/src/java.base/share/native/libjli/java.c中设置断点
运行程序





jvm在执行java程序过程汇总会把他所管理的内存划分为若干个不同的数据区域。
方法区(Method Are)  虚拟机栈(vm stack)  本地方法栈(native methdo statck)
堆(hep)  程序计数器(Program Counter Register)
||             ||
执行引擎  ==> 本地库接口  ->本地方法库

程序计数器(Prgram Counter Register) 一块较小的内存空间，可以看做是当前线程所执行的字节码的行号指示器。
在任何一个确定的时刻，一个处理器(对于多核处理器来说是一个核)都只会执行一条线程中的指令。
每条线程有独立的程序计数器

java虚拟机栈也是线程私有，生命周期与线程相同
描述的是java方法执行的线程内存模型：每个方法被执行时，java虚拟机都会同步创建一个栈帧(stack frame)用于存储局部变量表、操作数栈、动态链接、方法出口等信息。
每个方法被调用直至执行完毕过程，及对应一个栈帧在虚拟机中从入栈到出栈的过程。

局部变量表存放了编译期可知的各种java虚拟机基本数据类型(boolean/byte/char/short/int/float/long/double)、对象引用(reference烈性)和returnAddress类型
这些数据类型再局部变量表中存储空间以局部变量槽(slot)表示，64位长的long和double类型的数据会占用两个变量槽，其余站一个。
局部变量表所需的内存空间在编译期间完成分配，进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定的。
StackOverflowError/OutOfMemoryError

本地方法栈(native method stacks)与虚拟机栈类似，虚拟机栈为虚拟机执行java方法(字节码)服务，本地方法栈为虚拟机使用到的本地(native)方法服务
StackOverflowError/OutOfMemoryError

java堆被所有线程共享，在虚拟机启动时创建。
无论怎么划分，都存放的是对象的实例，细分的目的就是为了更好滴回收内存

方法区(Method Area)，各线程共享，用于存储已被虚拟机记载的类型信息、常量、静态变量、即时编译器编译后的代码缓存数据。
jdk7的hotspot已经把原本放在永久代的字符串常量池、静态变量等移出，到jdk8，废弃永久代的该你那，改用本地内存中实现的元数据(Metaspace)来代替，把jdk7中永久代剩余的内容(主要是类型信息)全部移到元空空间
方法区你额UC你回收主要目标是针对常量池的回收和对象类型的卸载，一般回收费劲
OutOfMemoryError

运行时常量区(Runtime Constant Pool)是方法去的一部分，class文件除了有类的版本、字段、方法、接口等描述信息，还有一项信常量池表(Constant Pool Table)，
用于存放编译期间生成的各种字面量与符号引用，在类加载后存放到方法去的运行时常量池中。
运行时常量池相对Class文件常量池的拎一个特性是具备动态性，不一定常量只能编译期产生，运行期间也可以放入，String.inter()
OutOfMemoryError

直接内存(Direct Memory)不是虚拟机运行时数据区的一部分，也不在<java虚拟机规范>中定义的内存区域，但被频繁使用，也可能导致OutOfMemory
jkd1.4引入NIO(New Input/Outpt)类，引入一种基于通道(chanel)与缓冲区(buffer)的I/O方式，可以使用native函数库直接分配堆外内存，通过一个存储在java堆
里的DirectByteBuffer对象引用这块内存。避免了java堆和native堆来回复制数据

本机直接内幕才能分配不会受到java堆大小限制，但是是内存，肯定会受到本机总内存(包括物理内存、SWAP分区或分页文件)大小及处理器寻址空间的限制，
也会有OutOfMemory


## hotspot中对象的分配、布局和访问的全过程
分配内存
当java虚拟机遇到一条字节码new指令时，检查这个指令的参数是否能在常量池中定位到一个类的符号引用，检查这个符号引用代表的类是否已被加载、解析和初始化，
若没有则必须先执行类加载过程
将为新生对象分配内存，对象所需内存大小在类加载完成后便可确定，
假设java堆中内存时绝对规整，所有被使用的过的内存都放到一边，空闲的存放到另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个
指针向空闲空间方法挪动的一段与对象大小相等的距离，指针碰撞(Bump the Pointer)。
但java堆中的内存并不是规整的，已被使用的内存和空闲的内存相互交织，没办法用指针碰撞，逊尼基要维护一个列表，记录上哪些内存块是可用的，在法分配时，从列表中找到一块足够大的空间划分给该对象实例，并更新列表上的记录。空闲列表(Free List)

一个问题：
对象创建再虚拟机中是非常频繁的，即使仅仅修改一个指针所指向的位置，在并发时也不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时
使用了原来的指针来分配内存情况。
解决办法：一种是对分配内存空间的动作进行同步处理——虚拟机采用CAS+失败重试保证更新操作的原子性；另一种是吧内存分配动作按照线程划分在不同的空间之中进行，
即每个线程在java堆中预先分配一小块内存，本地线程分配缓存(Thread Local Allocation Buffer,TLAB)，哪个线程哟啊分配内存，就在哪个线程的本地缓冲区中
分配，只有本地缓冲区用完了，分配新的缓存时才需要同步锁定。
虚拟机是否使用TLAB，可通过-XX: +/-UseTLAB参数设定

初始化零值
虚拟机必须将分配到的内存空间(但不包括对象头)都初始化为零值，若用了TLAB，这项工作可以提前至TLAB分配时顺便进行。

对对象必要设置
这些信息存放在对象的对象头(Object Header)之中。
如这个对象时哪个类的实例、如何才能找到类的源数据信息、对象的哈希吗(哈希吗会延后到真正调用Object::hashCode()方法时才计算)、对象的GC分代年龄等信息。
根据虚拟机当前运行状态不同，如是否启用偏向锁等，对象头会有不同的设置方式。

<init>
执行构造函数，Class文件中的<init>()方法。一般(由字节码流中new指令后面是否invokespecial指令所决定，java编译器会在遇到new关键字地方同事生成这两条
字节码指令，但其他方式不一定)，new指令后会接着执行<init>()方法，初始化


## 对象的内存布局
hotspot虚拟机里，对象在堆内存中的存储布局划分为三个部分：对象头(Header)、实例数据(Instance Data)、对其填充(Padding)

对象的头部分包括两类信息：
+ 存储对象自身的运行时数据，如哈希吗(HashCode)、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间等，Mark Word，考虑到虚拟机的空间效率，
  mark Word被设计为有着动态定义的数据结构，以便在极小的空间内存储尽量多的数据，根据对象的状态复用自己的存储空间。

2比特用于存储锁标志位
存储内容  标志位  状态
对象哈希吗、对象分代年龄  01  未锁定
指向锁记录的指针  00  轻量级锁定
指向重量级锁的指针  10  膨胀(重量级锁定)
空，不需要记录信息  11  GC标记
偏向线程ID、偏向时间戳、对象分代年龄  01  可偏向

+ 类型指针
  即对象指向他的类型元数据的指针，java虚拟机通过这个指针确定该对象是哪个类的实例(不一定要记录)。若对象是java数组，在对象头中还必须有一块用于记录数组
  长度的数据，因为虚拟机可以通过普通对象的元数据信息确定java对象的大小，但若数组的长度不确定，无法通过元数据中的信息推断出数组大小。


实例数据
是对象真正存储的有效信息，无论从父类继承还是子类定义的字段都必须记录。
HotSpot虚拟机默认的分配顺序为longs/doubles、ints、shorts/chars、bytes/booleans、oops(Ordinary Object Pointers,OOPs)，相同宽度的字段总是
被分配到一起存放，在满足这个条件的情况下，在父类中定义的变量会出现在子类之前。

对齐填充
占位符作用。由于HotSpot虚拟机的自动内存管理系统要求对象起始地址必须是8字节的整数倍，任何对象的大小都必须是8字节的整数倍。

## 对象的访问定位
java程序通过栈上reference数据来操作堆上的具体对象。
主流的访问方式主要：
+ 使用句柄访问
  java堆中划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自具体的地址信息
+ 直接指针
  java堆中的对象的内存布局必须考虑如何放置访问其类型元数据的相关信息，reference中存储的直接就是对象地址，若只访问对象本身则不需多一次间接访问的开销。
  -- 似乎你不用也可以不访问啊，应该是先从句柄池中找的过程慢

优缺点：
使用句柄好处就是reference中存储的稳定句柄地址，在对象被移动(垃圾收集时移动对象是非常普遍性为)时只会改变句柄中的实例数据指针，而reference本身不动。
-- 这就是decorator
使用直接指针好处，速度更快，节省了一次指针定位的时间开销，由于对象访问在java中非常频繁，因此这类开销极少程度也是成本
hotSopt，使用直接访问，从整体软件开发范围看，各种语言、框架中使用句柄来访问也十分常见

java oom
运行HeapOOM
先确定是内存泄露(Memory Leak)还是内存溢出(Memory Overflow)。
用mat分析
+ 若是内存泄漏，用Keywords下details点开即有调用泄露线程及栈，通过工具查案泄露对象到GC Roots的引用链，找到泄露对象是通过怎么的引用路径、与
  哪些GC Roots相关联，才导致垃圾收集器无法回收他们，根据泄露对象的类型信息以及它到GC Roots引用连的信息，定位到这些对象创建的位置。
+ 内存溢出，即内存中的对象必须存活，应当检查java虚拟机堆参数(Xms、Xms)设置，与机器的内存对比，看看是否有调整空间。从代码检查是否某对象生命
  周期过长、持有状态时间过长、存储结构设计不合理等，尽量减少程序运行期的内存消耗。

## 虚拟机栈和本地方法栈溢出
hotspot并不区分虚拟机栈和本地方法栈，-Xoss参数没有用，栈容量只能由-Xss设定
异常StackOverflowError/OutOfMemoryError
hotspot不支持栈的动态扩展，所以除非在创建线程申请内存时就因无法获得足够内存而出现OOM否则在线程运行时是不会因为扩展而导致内存溢出的oom，只会因为栈容量
无法容纳新的栈而导致StackOverflowError
实验表明：无论由于栈帧太大还是虚拟机栈容量太小，当心的栈帧内存无法分配时，hotspot虚拟机抛出的都是StackOverflowError


## 方法区和运行时常量池溢出
jdk8用元空间代替永久代。
String::intern()是一个本地方法，作用是如哦字符串常量池已经包含一个等与此String对象的字符串，则返回引用；否则创建String对象并添加到常量池中,返回此
String对象的引用。
jdk8以上则-XX:MamPermSize或-XX:MaxMetaspaceSize限制都不能重现jdk6的异常。因为jdk7起，存放在永久代的字符串常量池被移至java堆中。

方法区的主要职责是用于存放类型的相关信息，如类名、访问修饰符、常量池、字段描述、方法描述等。
对这部分区域的测试，基本思路是运行时产生大量的类去填满方法区，直到溢出位置。


## 本机直接内存溢出
Direct Memory通过-XX:MaxDirectMemorySize指定，默认与java堆最大值(-Xmx)一致，
由直接内存导致的内存溢出，明显特征是在HeapDump文件中不会看到明显的异常情况，若发现内存溢出后产生的dump文件很小，而程序中又直接或间接使用了DirectMemory(典型的是NIO)，那要考虑直接内存方面原因


## 垃圾收集
1960年Lisp是第一门开始使用内存动态分配和垃圾收集技术的语言。作者就思考过垃圾收集需要完成的三件事情：那些内存需要回收、什么时候回收、如何回收

当需要排查各种内存溢出、内存泄露问题时，当垃圾收集称为系统达到更高并发量的瓶颈时，需要对垃圾收集技术实施必要的监控和调节

程序计数器、虚拟机栈、本地方法栈3个区域随线程生命周期，栈中的栈帧随方法的进入和退出执行出站和入栈操作。每一个栈帧分配多少内存基本上是在类结构确
定下来时就已知的，因此这几个区域的内存分配和回收都具备确定性，当方法结束或线程结束时，内存自然就跟随者回收了

java堆和方法区不确定：一个接口的多个实现类需要的内存可能不一样，一个方法所执行的不同条件分支锁需要的内存也可能不一样，只有处于运行期间，才能知道
程序究竟会创建哪些对象，创建多少个对象，这部分内存的分配和回收是动态的。垃圾收集器所关注的正式这部分内存该如何管理。

### 计算对象是否存活
堆中存放了java世界中几乎所有的对象实例，垃圾收集前要确定哪些对象活，哪些已经死

引用计数算法(Reference Counting)，虽然占用了一些额外的内存空间来进行计数，但原理简单，判定效率也很高，大多情况不错，不过java虚拟机中并没有选用，
原因是有很多例外情况要考虑，必须要配合大量额外处理才能保证正确工作，譬如单纯的引用计数很难解决对象之间相互循环引用的问题。

当前主流的商用程序语言的内存管理子系统，都是通过可达性分析(Reachability Analysis)算法来判定对象是否存活
基本思路是通过一些列称为"GC Roots"的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，过程所走过的路径称为引用链(Reference Chain)，若
某个对象到GC Roots间没有任何引用链相连，或者用图论的话说就是从GC Roots到这个对象不可达，则证明此对象不吭呢再被使用

java技术体系中，固定可作为GC Roots的对象包括：
+ 在虚拟机栈(栈帧中的本地变量表)中引用的对象，如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等
+ 方法区中类静态属性引用的对象，如java类的引用类型静态变量
+ 方法区中常量引用的对象，如字符串常量池(String Table)里的引用
+ 本地方法栈中JNI(Native方法)引用的对象
+ java虚拟机内部的引用，如基本数据类型对应的Class对象，一些常驻的异常对象(如NullPointException、OutOfMemoryError)等，还有系统类加载器
+ 所有被同步锁(synchronized关键字)持有的对象
+ 反映java虚拟机内部情况的JMXbean、JVMTI中注册的回调、本地代码缓存等
  还有一些临时性地加入GC ROOTs中，如分代收集和局部回收(Partial GC)，如只针对java堆中某一块区域发起垃圾收集，必须考虑被其他区域对象所引用。

### 引用
jdk1.2以后，java对引用的概念进行扩充，将引用分为:
强引用(Storngly Reference)、软引用(Soft Reference)、弱引用(Weak Reference)、虚引用(Phantom Refernce)，强度一次减弱
+ 强引用就是指代码中存在的引用赋值，`Object obj = new Object()`。只要强引用关系存在，垃圾收集器永远不会收掉被引用的对象
+ 软引用描述一些还有用，但必须的对象。若对象指被软引用关联，在系统将要发生内存溢出前，会把这些对象列进回收范围之中进行二次回收，若这次回收还没有
  足够内存，则抛出内存异常。SoftReference类实现
+ 弱引用描述哪些非必须对象，但强度比`软引用`更弱一些，当垃圾收集器开始工作，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。WeakReference类
+ 虚引用，最弱的一种引用关系。无法通过虚引用来取得一个对象实例。
  为一个对象设置虚引用关联的唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知。PhantomReference类

真正宣告一个对象死亡，经历至少经历两次标记过程：
若对象在进行可达性分析后发现与GC Roots相连接的引用链，那它将会被第一次标记，随后进行一次筛选，条件是此对象是否有必要执行finalize方法，
假如对象没有覆盖finalize或已经执行过，都被视为“没有必要执行”。若必须要执行，则该对象会放置在一个FQueue的队列，稍后由一条由虚拟机自动建立的、低调度
优先级的Finalizer线程去执行他们的finalize()方法。虚拟机会触发这个方法，但不承诺一定会等待他运行结束。保证内存回收子系统不会崩溃。
稍后收集器将对FQueue中的对象进行第二次小规模的标记，如果对象要在finalize中成功拯救自己，那么再第二次标记时他将被移出“即将回收”的集合；若对象还没有
逃脱，那么久要被回收了。finalize方法只执行一次
如今被官方不推荐使用。用try-finally更好

### 回收方法区
方法区垃圾收集的“性价比”通常比较低。
方法区的垃圾收集主要两部分内容：废弃的常量和不在使用的类型。
判定常量，与堆中的对象回收相似。
判定类型是否不再被使用条件：
+ 该类所有的实例都已经被回收，java堆中不存在该类及其任何派生子类的实例
+ 加载该类的类加载器已经被回收
+ 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。

HotSpot提供了
是否要对类型进行回收：Xnoclassgc
-verbose:class以及-XX:+TraceClassLoading、-XX:+TraceClassUnLoading查看类加载和卸载信息
-verbose:class和-XX:+TraceClassLoading可以再Product版使用，-XX:+TraceClassUnLoading需要FastDebug版本

## 垃圾收集算法
<垃圾回收算法手册><The Garbage Collection Handbook>
从如何判定对象消亡的角度出发，垃圾收集算法可以分为“引用计数式垃圾收集(Reference Conuting GC)”和“追踪式垃圾收集(Tracing GC)”两大类。

### 分代收集理论
商用虚拟机的垃圾收集器，大多遵循“分代收集”(Generational Colleciton)的理论进行设计，分代收集实质是一套符合大多数程序运行实际情况的经验法则，
建立在两个分代假说之上：
1)弱分代假说(Weak Generational Hypothesis): 绝大多数对象都是朝生熄灭的
2)强分代假说(String Generational Hypothesis): 熬过越多次垃圾收集过程的对象就越难以消亡
这俩分代假说共同奠定了多款常用的垃圾收集器的一致的设计原则：收集器应该讲java堆划分为不同的区域，然后将回收对象依据其年龄(对象熬过垃圾收集过程的次数)
分配到不同的区域之中存储。
若一个区域中大多数对象都朝生熄灭，把他们集中放一起，每次回收时只关注如何保留少量存活而不是去标记那些大量将要被回收的对象，就能以较低代价回收到大量的
空间；若剩下的都是难以消亡的对象，把他们集中放一起，虚拟机便可以使用较低的频率来回收这个区域，同时兼顾了垃圾收集的时间开销和内存的空间有效利用。

有了java堆划分不同区域后，垃圾收集器才能每次只回收其中某一个或某部分的区域——因而才有了Minor GC/Major GC/Full GC；也才能对不同的区域安排与里面
存储对象存亡特征相匹配的垃圾收集算法——标记-复制算法/标记-清除算法/标记-整理算法

分代收集理论仍不断发展之中，如何实现也有许多细节可以改进。
设计者一般至少会把java堆划分为新生代(Young Generation)和老年代(Old Generation)两个区域。
分代收集并非只是简单划分一下内存区域，至少存在一个明显的困难：对象不是孤立的，对象之间会存在跨代引用。
只进行Minor GC，那么除了GC Roots之外还要遍历整个老年代中所有对象来确保可达性分析结果的正确性，反过来也一样。理论上可行，但回味内存回收带来很大的
性能负担。需要对分代收集理论添加第三条经验法则：
3)跨代引用假说(Intergenerational Reference Hypothesis)，相对于同代引用仅占极少数。
也可根据前两条假说逻辑推理得出隐含推论：存在互相引用关系的两个对象，是应该倾向于同时生存或同时消亡的。
所以，不应该再为少量的跨代引用去扫描整个老年代，也不必浪费空间专门记录每一个对象是否存在及存在哪些跨代引用，
只需在新生代上建立一个全局的数据结构(Remembered Set)，把老年代划分成若干个小块，标识出老年代的哪一块内存会存在跨代引用。
此后，当发生Minor GC时，只有包含了跨代引用的小块内存里的对象才会被加入到GC Roots进行扫描。
虽然需要在对象改变了引用关系(如将自己或某个属性赋值)时维护记录数据的正确性，会增加一些运行时开销，但比起收集时扫描整个老年代来说仍划算。

部分收集(Patial GC):指不是完整收集整个java堆
+ 新生代收集(Minor GC/Young GC):只针对新生代收集
+ 老年代收集(Major GC/Old GC):指针对老年代的收集，只有CMS会有单独收集老年代的行为。
+ 混合收集(Mixed GC):指收集整个新生代以及部分老年代。只有G1会有这种行为
  整堆收集(Full GC):收集整个java堆和方法区

### 标记-清除算法
标记出所有需要回收的对象，标记完成后，统一回收掉所有被标记的对象，也可以反过来，标记存活的对象，统一回收所有未被标记的对象。
主要缺点：
+ 执行效率不稳定，若java堆中包含大量的对象，而其中大部分都是需要被回收，这时必须进行大量标记和清除，导致两个过程的执行效率随着对象数量增大
  而降低
+ 内存空间的碎片化问题，标记、清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致当以后在程序运行过程中需要分配较大对象时无法找到
  足够的连续内存而不得不提前触发另一次垃圾收集动作。

### 标记-复制算法
为解决标记-清除算法面对大量可回收对象时执行效率低的问题，提出，可以将可用内存按容量划分为大小相等的两块，每次只使用其中一块。
当一块内存用完了，将还存活的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。
若内存中多数对象都是存活的，这种算法产生大量的内存间复制开销，但对于多数对象都是可回收的情况，算法需要赋值的就是占少数的存活对象，而每次都是
针对整个半区进行内存回收，分配内存时也不用考虑有空间碎片的复杂情况，只要一动堆顶指针，按顺序分配即可。简单，高效。
代价是将可用的内存缩小为了原来的一半，空间浪费未免太多了。

现在商用java虚拟机大多优先采用这种收集算法去回收新生代。
Appel式回收：把新生代分为一块较大的Eden空间和两块较小的Survivor空间，每次分配内存时只使用Eden和其中一块Survivor。发生垃圾收集时，将Eden
和Survivor中仍存获得对象一次性复制到另外一块Survivor空间上，然后清理掉Eden和已用过的那块Survivor空间。
hotSopt虚拟机默认Eden和Servivor比例是8:1。当Survivor空间不足以容纳一次Minor GC之后存活的对象时，就需要依赖其他内存区域(多数是老年代)进行
分配担保(Handle Promotion)

### 标记-整理算法
标记-复制算法在对象存活率较高时要进行较多的复制操作，效率会降低。关键是不想浪费50%的空间，就需要有额外的空间进行分配担保，已应对被使用的内存
中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用。

针对老年代对象的存亡特征，提出，有针对性的标记-整理(Mark-Compact)算法，标记过程一样，后续步骤是让所有存活的对象都向内存空间的一端移动，然后直接清理
掉边界以外的内存。是一种移动式的。

是否移动回收后的存活对象是一项优缺点并存的风险决策：
+ 若移动，因为会有大量存活对象，所以更新所有引用这些对象的地方将会是一项极为负重的操作，而这种操作必须全程暂停用户应用程序才能进行，更加让使用者不得不
  小心翼翼权衡其弊端了，Stop The Wordl
+ 不移动，导致空间碎片化问题只能依赖更为复杂的内存分配器和内存访问器来解决。譬如通过“分区空闲分配链表”来解决内存分配问题(计算机硬盘存储大文件就不要求
  物理连续的磁盘空间，能够在碎片化的硬盘上存储和访问就是通过硬盘分区表实现的)。内存的访问使用程序最频繁的操作，若在这个环节增加额外的负担，势必会直接
  影响应用程序的吞吐量。

基于以上两点，移动则内存回收时更复杂，不移动则内存分配时会更复杂。
从垃圾收集的停顿时间来看，不移动对象停顿时间会更短，甚至可以不需要停顿，但从整个程序的吞吐量来看，移动对象会更划算(分配省事，而仅仅每次收集费事)。
此语境中，吞吐量的实质是赋值器(Mutator，使用垃圾收集的用户程序)与收集器的效率总和。
即使不移动对象会使得收集器的效率提升一些，但因为内存分配和访问相比垃圾收集频率要高得多，这部分的耗时增加，总吞吐量仍然是下降的。
HotSpot虚拟机里关注吞吐量的Parallel Scavenge收集器是基于标记-整理算法的，而关注延迟(垃圾收集暂停时间)的CMS收集器则是基于标记-清楚算法的。

还有一种混合方案：让虚拟机平时多数时间都采用标记-清除算法，暂时容忍内存碎片的存在，直到内存空间的碎片化程度已经大到影响对象分配时，再采用标记-整理
算法收集一次，已获得规整的内存空间。CMS收集器面临空间碎片过多时采用的就是这种处理办法


## hotspot的算法细节实现

### 根节点枚举
所有收集器在根节点枚举这一步骤时都是必须暂停用户线程的，因此根节点枚举与之前提及的整理内存碎片一样会面临相似的Stop The World问题。
根节点枚举始终还是必须在一个能保障一致性的快照中才得以进行——这里“一致性”是整个枚举期间执行子系统看起来像被冻结在某个时间点上，不会出现分析过程中，
根节点结合的对象引用关系还在不断变化的情况，若这点不能满足，分析结果准确性也就无法保证。

当用户线程停顿下来后，并不需要一个不漏地检查完所有执行上下文和全局的引用位置，在HotSpot中，使用一组称为OopMap的数据结构，一旦类加载动作完成时，
hotSpot就会把对象内什么偏移量上是什么类型的数据计算出来，在即时编译过程中也会在特定的位置记录下栈里和寄存器里哪些位置是引用的。
这样收集器在扫描时可以直接得知这些信息，并不需要真正一个不漏地从方法区等GC Roots开始查找。
--每个步骤都将可能是gcroot的地方放入一个地方，便于垃圾收集时直接收集。

```hotSpot虚拟机客户端模式下生成的String::hashCode()方法的本地代码
[Verified Entry Point]
0x026eb730: mov %eax,-0x8000(%esp)
............
;; ImplicitNullCheckStub slow case
0x026eb7a9: call 0x026e83e0   ; OopMap{ebx=Oop [16]=Oop off=142}  --call指令有OopMap记录，指明ebx寄存器和栈中偏移量为16的内存区域各有一个普通
对象指针(Ordinary Object Pointer,OOP)的引用，有效范围从call开始直到 0x026eb730(指令流的起始位置)+142(OopMap记录的偏移量)=0x026eb7be(hit指令位置)
									            ; *caload
															; - java.lang.String::hashCode@48 (line 1489) ; {runtime_call}
0x026eb7ae: push   $0x83c5c18
0x026eb7b3: call   0x026eb7b8
0x026eb7b8: pusha 
0x026eb7b9: call  0x0822bec0  ; {runtime_call}
0x026eb7be: hlt
```

### 安全点
在OopMap的协助下，HotSpot可以快速准确地完成GC Roots枚举，但一个现实问题是：可能导致引用关系变化，或这说导致OopMap内容变化的指令非常多，若为每一条
指令都生成对应的OopMap，那将会需要大量的额外存储空间，这样垃圾收集伴随而来的空间成本会无法忍受。

hotSpot只是在特定的位置记录了这些信息，这些位置称为安全点(Safepoint)。也决定了用户程序执行时并非在代码指令流的任意位置都能停顿下来开始垃圾收集，
而是强制要求必须执行到达安全点后才能暂停。

安全点位置的选取基本上是以“是否具有让程序长时间执行的特征”为标准进行选定，因为每条指令执行的时间都非常短暂，程序不太可能因为指令流长度太长这样的原因
而长时间执行，
“长时间执行”的最明显特征就是指令序列的复用，如方法调用、循环跳转、异常跳转等，所以只有具有这些功能的指令才能产生安全点
--具有让程序长时间执行的特征的指令才能设定安全点

另一个安全点的问题是，如何在垃圾收集发生时让所有线程(不包括执行JNI调用的线程)都跑到最近的安全点，然后停下来。两种方案：抢先试中断(Preemptive
Suspension)和主动式中断(Voluntary Suspension)，前者中断不需要线程的执行代码主动去配合，在垃圾收集发生时，系统首先把所有用户线程全部中断，
若发现有的用户线程中断的地方不在安全点上，就恢复这条线成，让他一会在重新中断，知道跑到安全点上。现在几乎没有虚拟机采用。
主动式中断的思想是当垃圾收集需要中断线程的时候，简单地设置一个标志位，各个线程执行过程中会不停地主动去轮询这个标志，一旦发现为真就自己再最近的安全点
上主动中断挂起。
轮询标志的地方和安全点是重合的，另外还要加上所有创建对象和其他需要在java堆上分配内存的地方，为了检查是否即将要发生垃圾收集，避免没有足够内存分配
新对象。

由于轮询操作在代码中会频繁出现，要求它必须足够高效。hotSpot使用内存保护陷阱的方式，把轮询操作精简至只有一条汇编指令的程度。
下面test指令就是hotSpot生成的轮询指令，当需要暂停用户线程时，虚拟机把0x160100的内存页设置为不可读，那线程执行到test指令时就会产生一个自陷阱异常
信号，然后再预先注册的异常处理器中挂起线程实现等待，这样仅通过一条汇编指令完成安全点的轮询和触发线程中断了。--平常的情况是可读的，没有陷阱
```
0x01b6d62d: test  %eax,0x160100  ; {poll}
```

### 安全区域
安全点的机制保证了程序执行时，在不太长的时间内就会遇到可进入垃圾收集过程的安全点。
但是程序“不执行”的时候呢？在没有分配处理器时间，如用户线程处理sleep状态或Blocked状态，这时线程无法响应虚拟机的中断请求，不能再走到安全的地点去中断
挂起自己，虚拟机也显然不可能持续等待线程重新被激活分配处理器时间。这时必须引入安全区域(Safe Region)来解决。

安全区域指能够确保在某一段代码片段中，引用关系不会发生变化。在这个区域中任意地方开始垃圾收集都是安全的。也可以把安全区域看做被扩展拉伸了的安全点。

当用户线程执行到安全区域里的代码时，首先会标识自己已经进入了安全区域，那样当这段时间里虚拟机要发起垃圾收集时就不必去管这些已经声明自己在安全区域内
的线程了。当线程要离开安全区域时，他要检查虚拟机是否应完成了根节点枚举（或垃圾收集过程中其他需要暂停用户线程的阶段),若完成了，那线程就当做没事发生
过，继续执行；否则就必须一直等待，直到收到可以离开安全区域的信号为止。
--安全点代码(可以感知gc并停止的点)：长时间执行的代码，不会改变GC Roots的代码

### 记忆集与卡表
之前说，未解决对象跨带引用所带来的问题，垃圾收集器在新生代建立了记忆集(Remembered Set)的数据结构，用以避免把整个老年代加进GC Roots扫描范围。
事实上，所有涉及部分区域收集(Partial GC)行为的垃圾收集器，如G1、ZGC和Shenandoah收集器，都会面临此问题。

记忆集是一种用于记录从非收集区域指向收集区域的指针集合的抽象数据结构。弱不考虑效率和成本，简单的实现可以用非收集区域的所有含跨代引用的对象数组
来实现这个数据结构。
```以对象指针来实现记忆集的伪代码
Class RememberedSet {
Object[] set[OBJECT_INTERGENERATIONAL_REFERENCE_SIZE];
}
```
不过，这种记录全部含跨代引用对象的实现方案，无论是空间占用还是维护成本都相当高昂。
而在垃圾收集的场景中，收集器只需要通过记忆集判断出某一块非收集区域是否存在有指向了收集区域的指针即可，并不需要了解这些跨带指针的全部细节。
那设计者在实现记忆集时，可以选择更为粗犷的记录力度来节省记忆集的存储和维护成本，列举一些供选择的记录精度：
+ 字长精度：每个记录精确到一个机器字长(即处理器的寻址位数，32/64，这个精度决定了机器访问物理内存地址的指针长度)，改字包含跨代指针。
+ 对象精度：每个记录精确到一个对象，该对象里有字段含有跨代指针。
+ 卡精度：每个记录精确到一块内存区域，该区域内有对象含有跨代指针。用一种卡表(Card Table)的方式实现记忆集。定义了记忆集的记录精度、与堆内存的
  映射关系等。常用，<Remembered sets can also play cards><A Fast Write Barrier for Generational Garbage Collectors,http://www.
  hoelzle.org/publications/write-barrier.pdf>
  卡表最简单的形式可以只是一个字节数组，hotspot虚拟机也确实这样做。
```hotspot默认的卡表标记逻辑http://psy-lob-saw.blogspot.com/2014/10/the-jvm-write-barrier-card-marking.html
CARD_TABLE [this address >> 9] = 0;  --this address表示实际的内存地址
```
字节数组CARD_TABLE的每一个元素都对应着其标识的内存区域中一块特定大小的内存块，这个内存块被称作卡页（Card Page)。
一般卡页大小都是以2的N次幂的字节数，上面代码看出，hotspot使用的卡页是2^9，即512字节(地址右移9位，相当于用地址除以512)。
若卡表表示内存区域的起始地址是0x0000，数组CARD_TABLE的第0、1、2号元素，分别对应了地址范围为0x0000~0x01FF、0x0200~0x03FF、0x0400~0x05FF的卡页内存块
--0x01FF如何来的？0x01FF/512？  答案：0x01FF->00000x01FF->511,0~511就是512

一个卡页的内存中通常包含不止一个对象，只要卡页内有一个(或更多)对象的字段存在跨带指针，就将对应卡表的数组元素的值标识为1，成为这个元素变脏(Dirty)，没有
则0。垃圾收集发生时，只要筛选出卡表中变脏的元素，就能轻易得出哪些卡页内存块中包含跨代指针，把他们加入GC Roots中一并扫描。
--记忆集抽象，卡表具体，假如扫描young gen，那么就是young gen中的一个表，用来表示old指向young的表，每个元素是512内存地址，若这个地址中有则1

### 写屏障
如何维护卡表，如他们何时变脏、谁来把他们变脏等
何时变脏——有其他分代区域中对象引用了本区域对象时，其对应的卡表元素就应该变脏，变脏时间点原则上应该是发生在引用类型字段赋值的那一刻。
但问题是如何变脏，及如何在对象赋值的那一刻去更新维护卡表呢？
解释执行的字节码，虚拟机负责每条字节码指令的执行，有充分的介入空间；但在编译执行的场景，经过即时编译后的代码已经是纯粹的机器指令流，必须找到一个在机器码
层面的手段，把维护卡表的动作放在每一个赋值操作之中。
hotSpot虚拟机里是通过写屏障(Write Barrier)技术维护卡表状态的。
写屏障可以看做在虚拟机层面对“引用类型字段赋值”这个动作的AOP切面，在引用对象赋值时会产生一个环形(Around)通知，供程序执行额外的动作，即赋值的前后都在写
屏障的覆盖范畴内。写前屏障(Pre-Write Barrier)，写后屏障(Post-Write Barrier)。
直到G1收集器出现之前，其他收集器都只用到了写后屏障。
```写后屏障更新卡表
void oop_field_store(oop* field, oop new_value) { // 引用字段赋值操作
*field = new_value;
// 写后屏障，在这里完成卡表状态更新 post_write_barrier(field, new_value);
}
```
应用写屏障后，虚拟机会为所有赋值操作生成相应的指令，一旦收集器在写屏障中增加了更新卡表操作，无论更新的是不是老年代对新生代对象的引用，每次只要对引用
进行更新，就会产生额外的开销，不过与Minor GC时扫描整个老年代的代价相比还是低得多。

除了写屏障的开销，卡表在高并发场景下还面临着“伪共享”(False Sharing)问题。
伪共享是处理并发底层细节时一种经常要考虑的问题，现代中央处理器的缓存系统中时以缓存行(Cache Line)为单位存储的，当多线程修改互相独立的变量时，若这些变量
恰好共享同一个缓存行，就会彼此影响(写回、无效化或同步)而导致性能降低，就是伪共享问题。

假设处理器的缓存行大小为64字节，由于一个卡表元素占1个字节，64个卡表元素将共享同一个缓存行。这64个卡表元素对应的卡页总的内存为32KB(64*512字节)，即如果
不同线程更新的对象正好处于这32KB的内存区域内，就会导致更新卡表时正好写入同一个缓存行而影响性能。为避免伪共享问题，一种简单的办法是不采用无条件的写
屏障，而是先检查卡表标记，只有当该卡表元素未被标记过时才将其标记为变脏。
```卡表更新的逻辑
if (CARD_TABLE [this address >> 9] != 0) CARD_TABLE [this address >> 9] = 0;
```
jkd7以后，hotSpot虚拟机增加参数-XX:+UseCondCardMark，用来决定是否开启卡表更新的条件判断。
开启会增加一次额外判断的开销，但能避免伪共享为题，两者各有性能损耗，是否打开要根据应用实际运行情况进行测试权衡。
--看来，卡表并不是依据是否old指向yound，而是young把old分层，然后只要引用部分有变更，那么就依条件更新。更新只包括涉及GC Roots部分

### 并发的可达性分析
可达性分析算法理论上要求全过程都基于一个能保障一致性的快照中才能能够进行分析，意味着必须全程冻结用户线程的运行。
在根节点枚举这步中，由于GC Roots相比起整个java堆中全部的对象毕竟还是极少数，且在各种优化技术(如OopMap)的加持下，带来的停顿已经非常短暂且相对固定了。
可从GC Roots再继续往下遍历对象图，停顿时间必定会与java堆容量直接成正比例关系了。

包含“标记”阶段是所有追踪式垃圾收集算法的共同特征，若这个阶段随着堆变大而等比例增加停顿时间，其影响会涉及所有垃圾收集器，若削减则收益也是系统性的。

想解决或降低用户线程的停顿，要先搞清楚为什么必须在一个能保障一致性的快照上才能进行对象图的遍历？
为了解释问题，引入三色标记(Tri-color Marking)作为工具辅助推导，
把遍历对象图过程中遇到的对象，按照“是否访问过”这个条件标记成三种颜色：
+ 白色：表示对象尚未被垃圾收集器访问过。可达性分析开始都是白色，若在结束仍然是白色，则代表不可达
+ 黑色：表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经扫描过。是存活的。不可能直接指向某个白色对象。
+ 灰色：表示对象已经被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过。

若用户线程于收集器并发工作，可能出现两种后果。
+ 把原本消亡的对象错误标记为存活，不好，但其实可以容忍，只不过产生了一点逃过本次收集的浮动垃圾而已，下次收集清理掉就好  
  --应该是白色的，没有地方引用了，但是被标记成黑色了，是不是从没有到有然后又没有了，然后标记阶段发现错误？
+ 把原本存活的对象错误标记为已消亡，严重后果，程序肯定会因此发生错误。  
  --应该是黑色，但后来由于改了引用指向但后来后又不指向了，标记最后成白色。由于指向来回变动导致未能标记成白色，灰色指向不能继续，导致只能是白色，被误删了。

Wilson理论证明，当且仅当两个条件同时满足，会产生“对象消失”的问题，即原本应该是黑色的对象被误标为白色：
+ 赋值器插入了一条或多条从黑色对象到白色对象的新引用  --那应该可以扫描到啊，是不是原本白色，然后由于赋值改成了应该是灰色，但是没来得及扫描
+ 赋值器删除了全部从灰色对象到该白色对象的直接或间接引用  --没发继续扫描了

因此要解决并发扫描时的对象消失问题，只需要破坏这两个条件的任意一个即可。
产生两种解决方案：增量更新(Incremental Update)和原始快照(Snapshot At The Beginning,SATB)
+ 增量更新破坏的是第一个条件，当黑色对象插入新的指向白色对象的引用关系时，将这个新插入的引用记录下来，等并发扫描结束后，再将这些记录过的引用关系中的
  黑色对象为根，重新扫描一次。理解为，黑色对象一旦新插入了指向白色对象的引用后，它就重变回灰色对象了。
+ 原始快照破坏的第二个掉件，当灰色对象要删除指向白色对象的引用关系时，将这个要删除的引用记录下来，在并发扫描结束后，再将这写记录过的引用关系中的灰色
  对象为根，重新扫描一次。理解为，无论引用关系删除与否，都会按照刚开始扫描的那一刻的对象图快照来进行搜索。
  以上无论是对引用关系记录的插入还是删除，虚拟机的记录操作都是通过写屏障实现。
  hotSpot中，增量更新和原始快照解决方案都有实际应用，如CMS是基于增量更新来做并发标记的，G1、Shenandoah用原始快照实现的

### 经典垃圾收集器
收集算法是内存回收的方法论，垃圾收集器是内存回收的实践者。
<java虚拟机规范>

Young generation: Serial/ParNew/Parallel Scavenge
G1扫描young+tenured
Tenured generation: CMS/Parallel Old/Serial Old(MSC)
搭配：
Serial配合/MSC   Serial+CMS将废弃
ParNew配合CMS/MSC   ParNew+MSC将废弃
Parallel Scavenge配合MSC/Parallel Old
https://blogs.orcale.com/jonthecollector/our_collectors

虽然会对各个收集器进行比对，但并非为了挑选一个最好的收集器出来，虽然垃圾收集器的技术在不断进步，但直到现在还没有最好的收集器出现，更加不存在“万能”的
收集器，所以选择的只是对具体应用最合适的收集器
若能有一种放之四海皆准、任何场景下都适用的完美收集器存在，hotSpot虚拟机就没必要实现那么多种不同的收集器了。

### Serial收集器
控制参数:-XX:SurvivorRatio、-XX:PretenureSizeThreshold、-XX:HandlePromotionFailture等
最基础、历史最悠久的收集器。“单线程”的意义并不仅仅是说明它只会使用一个处理器或一条收集线程去完成垃圾收集工作，更重要的是强调在它进行垃圾收集时，必须
暂停其他所有线程，直到它收集结束。
STW是由于虚拟机在后台自动发起和自动完成的，在用户不可知、不可控的情况下把用户的正常工作的线程全部暂停掉，对应用来说不能接受。
示意图：
CPU0--用户线程1-->--GC线程      |--用户线程1-->|GC线程					 |--用户线程1-->
CPU1--用户线程2-->新生代采用     |--用户线程1-->|老年代采用标记-整理 |--用户线程1-->
CPU2--用户线程3-->复制算法暂停所有|--用户线程1-->|算法暂停所有用户线程|--用户线程1-->
CPU3--用户线程4-->用户线程       |--用户线程1-->|             -->|--用户线程1-->
safepoint											safepoint
一个个越来越构思精巧，越来越优秀，也越来越复杂的垃圾收集器不断涌现，用户线程的停顿时间在持续缩短，但是仍然没有办法彻底消除暂停用户线程。
hotSpot虚拟机运行在客户端模式下的默认新生代收集器，简单高效，对于内存资源受限环境，是所有收集器里额外内存消耗(Memory Footprint)最小；
对于单核处理器或处理器核心数较少的环境来说，Serial收集器由于没有现成交互开销，专心做垃圾收集自然可以获得最好的单线程收集效率。
若分配给虚拟机管理的内存一般来说并不特别大，收集几十兆甚至一两百兆的新生代(仅仅指新生代使用的内存)，垃圾收集的停顿时间玩去哪可以控制在十几、
几十毫秒，最多一百多毫秒以内，只要不是频繁发生收集，这点停顿时间对于多数用户可以接受。
--配合old收集器，内存受限(1~200newgen)、消耗最小、内核受限(较少)、收集时间少(10~100ms)、不频繁发生

### ParNew收集器
实质上是Serial收集器的多线程并行版本。
是不少运行在服务端模式下的HotSpot虚拟机，尤其是jdk7之前系统的首选的新生代收集器，
只有Serial收集器和ParNew收集器能与CMS收集器配合工作
ParNew收集器是激活CMS后(-XX:+UseConcCmarSweepGC)的默认新生代收集器。



### Parllel Scavenge收集器
也是新生代收集器，基于标记-复制算法实现，并行收集。
目标是达到一个可控的吞吐量(Throughput),CMS等收集器的关注点使尽可能低缩短垃圾收集时用户线程的停顿时间。
停顿时间越短就越适合需要与用户交互或需要保证服务响应质量的程序，良好的响应速度能提升用户体验；而高吞吐量则可以最好效地利用处理器资源，尽快
完成程序的运算任务，主要适合在后台运算而不需要太多交互的分析任务。

两个参数精确控制吞吐量
+ -XX:MaxGCPauseMillis：控制最大垃圾收集停顿时间，大于0的毫秒数，垃圾收集停顿时间缩短是以牺牲吞吐量和新生代空间为代价换取的：系统把新生代调
  的小一些，收集300MB新生代肯定比收集500B快，但这也直接导致垃圾收集发生得更频繁，原来10s收集一次、每次停顿100毫秒，现在变成5s收集一次、停顿70毫秒。
  10*100=1000，5*1000*70=35000，停顿时间下来，不过吞吐量也降下来了。
+ -XX:GCTimeRatio：设置吞吐量大小。(0,100)，垃圾收集时间占总时间的比率，相当于吞吐量的倒数。
  例如：设置19，那允许的最大垃圾收集时间占总时间的5%即(1/(1+19))，默认99，即允许最大1%(即1/(1+99))的垃圾收集时间
+ -XX:+UseAdaptiveSizePolicy：true则垃圾收集的自适应的调节策略(GC Ergonomics)。
  不需要人工指定新生代(-Xmn)/Eden/Survivor区的比例(-XX:SurvivorRatio)/晋升老年代对象大小(-XX:PretenureSizeThreadhold)等参数，虚拟机会根据当前系统运行情况收集性能监控信息，动态调整。

### Serial Old收集器
是Serial收集器的老年代版本，单线程，使用标记-整理算法。意义是供客户端模式下的HotSpot虚拟机使用。
若在服务端模式可能两种用途：
+ 在jdk5之前与Parallel Scavenge收集器搭配
+ 作为CMS收集器发生失败时的后备预案，在并发收集发生Concurrent Mode Failure时使用。

### Parallel Old收集器
是Parallel Scavenge收集器的老年代版本，多线程并发收集，基于标记-整理算法。
在注重吞吐量或处理资源较为稀缺的场合，优先考虑Parallel Scavenge+Parallel Old
Paralle Scavenge/Parallel Old示意图：
CPU0--用户线程1-->|--GC线程1-->|--用户线程1-->|--GC线程1-->|--用户线程1-->
CPU1--用户线程2-->|--GC线程1-->|--用户线程1-->|--GC线程1-->|--用户线程1-->
CPU2--用户线程3-->|--GC线程1-->|--用户线程1-->|--GC线程1-->|--用户线程1-->
CPU3--用户线程4-->|--GC线程1-->|--用户线程1-->|--GC线程1-->|--用户线程1-->
safepoint									safepoint

### CMS收集器
CMS(Concurrent Mark Sweep)收集器目标是：获取最短回收停顿时间。多类应用较为关注服务的响应速度，希望系统停顿时间尽可能短，以给用户带来良好的交互体验。
基于标记-清理算法实现。
过程分为4步：
+ 初始标记(CMS initial mark)
  stop the world，仅仅只是标记一下GC Roots能直接关联到的对象，速度快
+ 并发标记(CMS concurrent mark)
  从CG Roots的直接关联对象开始遍历整个对象图过程，耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行
+ 重新标记(CMS remakr)
  stop the world，为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那部分对象标记记录。停顿时间比初始标记阶段稍长，但远比并发标记阶段时间段
+ 并发清除(CMS concurrent sweep)
  清理删除掉标记阶段判断的已经死亡的对象，由于不需要移动存活对象，所以可以与用户线程同时并发执行。

Concurrent Mark Sweep示意图：
CPU0--用户线程1-->|           |--用户线程1-->|--重新标记-->|--用户线程1-->|--用户线程1-->|--用户线程1-->
CPU1--用户线程2-->|--初始标记-->|--用户线程1-->|--重新标记-->|--用户线程1-->|--用户线程1-->|--用户线程1-->
CPU2--用户线程3-->|           |--并发标记-->|--重新标记-->|--并发清理-->   |--重置线程-->|--用户线程1-->
CPU3--用户线程4-->|           |--用户线程1-->|--重新标记-->|--用户线程1-->|--用户线程1-->|--用户线程1-->
safepoint		safepoint 		safepoint	 	safepoint     safepoint     safepoint

主要优秀点：并发收集、低停顿
三个明显缺点：
+ CMS收集器对处理器资源非常敏感。事实上，面向并发设计的程序都对处理器资源比较敏感。并发阶段，虽然不会导致用户线程停顿，但会因为占用了一部分线程
  (或者说处理器的计算能力)而导致应用程序变慢，降低总吞吐量。CMS默认启动的回收线程数是(处理器核心数量+3)/4。
+ 由于CMS收集器无法处理“浮动垃圾”(Floaintg Garbage)，有可能出现"Concurrent Mode Failure"失败进而导致另一次完全STW的Full GC产生。
  浮动垃圾：并发标记和并发清理阶段用户线程运行产生的垃圾对象，出现在标记过程结束疑惑，CMS无法在当次收集中处理掉他们，只好留在下一次垃圾收集时处理。
  由于在垃圾收集阶段用户线程还需奥持续运行，那就还需要预留足够内存空间提供给用户线程使用，因此CMS收集器不能等待老年代几乎完全被填满了再进行收集，
  必须预留一部分空间供并发收集时的程序运作使用。
  jdk6，CMS收集器启动阈值默认92%(-XX:CMSInitiatingQccupancyFraction)，但会有另一种风险：要是CMS运行期间预留的内存无法满足程序分配新对象的
  需要，就会出现一次“并发失败”(Concurrent Mode Failure)，这时虚拟机将不得不启动后备预案，冻结用户线程的执行，临时启用Serial Old收集器来重新
  进行老年代的垃圾收集，但是停顿时间很长。用户应在生产环境中根据实际应用情况来权衡设置。
+ 收集结束会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，会出现老年代还有很多剩余空间，但无法找到足够大的连续空间来分配当前
  对象，不得不提前触发一次Full GC情况。
  为解决此问题，提供一个-XX:+UseCMSCompactAtFullCollection开关(默认开启，jdk9开始废弃)，用于在CMS收集器后就进行压缩即FullGC，
  由于这个内存整理必须移动存活对象，所以用户线程是无法并发的。这样空间碎片问题解决了，但停顿时间又会变长，
  因此又提供一个参数-XX:CMSFullGCsBeforeCompaction(jdk9开始废弃)，
  作用是要求CMS收集器在执行过若干次(数量由参数决定)不整理空间的CMS之后，下一次进入Full GC前会先进行碎片整理
  (默认0，表示每次进入Full GC时都进行碎片整理)
  --就是cms几次不进行碎片整理，而到达阈值时压缩，然后不行再fullgc?


### Gargabe First收集器
简称G1，开创了收集器面向局部收集的设计思路和基于Region的内存布局形式。
jdk8Update40时，g1才是“全功能的垃圾收集器”(Full-Featured Garbage Collector)
G1是一款主要面向服务端应用的垃圾收集器。
JKD9发布，G1宣告取代Parallel Scavenge+Parallel Old组合，成为服务端模式下的默认垃圾收集器，CMS标注Deprecated
规划jdk10功能目标时，hotspot提出“统一垃圾收集器接口”，将内存回收的“行为”和“实现”进行分离。以此为基础，日后要移除或加入某一款收集器，都会变得容易，
风险也可以控制。

G1设计者们希望一款能够建立起“停顿时间模型”(Pause Prediction Model)的收集器。
停顿时间模型：能够支持指定在一个长度为M毫秒的时间片段内，消耗在垃圾上的时间大概率不超过N毫秒这样的目标，这几乎已经是实时java(RTSJ)的中软实时垃圾
收集器特征了。

如何实现目标？要有一个思想改变，G1之前，垃圾收集的目标范围要么是整个新生代(Minor GC)，要么就是整个老年代(Major GC)，要么就是整个java堆(Full GC)。
而G1跳出了这个框架，它可以面向堆内存任何部分来组成回收集(Collection Set,CSet)进行回收，衡量标准不再是它属于哪个分代，而是哪块内存中存放的垃圾数量
最多，回收收益最大，这就是G1收集器的Mixed GC模式
G1开创的基于Region的堆内存布局是它能实现这个目标的关键。G1不在坚持固定大小及固定数量的分代区域划分，而是把连续的java堆划分为多个大小相等的独立
区域(Region)，每一个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间，或者老年代空间。
收集器能够对扮演不同角色的Region采用不同的策略去处理，这样无论是新创建的对象还是已经存活一段时间、熬过多少次收集的旧对象都能获得良好的收集效果。

Region中还有一类特殊的Humongous区域，专门用来存储大对象。G1认为只要超过了一个Region容量一半的对象即可判定为大对象。
每个Region的大小可以通过-XX:G1HeapRegionSize设定，[1MB,32MG]，且为2的N次幂。
对于那些超过了整个Region容量的大对象，将会被存放在N个连续的Humongous Region之中，G1的大多数行为都把Humongous Region作为老年代的一部分进行看待。

新生代和老年代不再是固定的了，都是一系列区域(不需要连续)的动态集合。
G1之所以能建立可预测的停顿时间模型，因为它将Region作为单词回收的最小单元，即每次收集到的内存空间都是Region大小的整数倍，这样可以有计划地避免在整个
java堆中进行全区域的垃圾收集。

具体处理思路：让G1收集器去跟踪各个Region里的垃圾堆积的"价值"大小，价值即回收所获得的空间大小以及回收所需的时间的经验值，然后在后台维护一个优先级
列表，每次根据用户设定允许的停顿时间(-XX:MaxGCPauseMillis，默认200毫秒)，优先处理回收价值最大的那些Region，这也是Garbage First名字由来。
这种用Region划分内存空间，以及具有优先级的区域回收方式，保证G1在有限的时间内获取尽可能高的收集效率。
--但是超过200ms的Region如何处理呢？

G1至少有一下关键细节问题需要妥善解决：
+ 将java堆分成多个独立Region后，Region里面存在跨Region引用如何处理？思路是之前提到的：使用记忆集避免全堆作为GC Roots扫描，但在G1收集器上记忆集
  的应用其实复杂很多，它的每个Region都维护有自己的记忆集，这些记忆集会记录下别的Region指向自己的指针，并标记这些指针分别在哪些卡页的范围内。
  G1的记忆集在存储结构的本质上是一种哈希表，Key是别的Region的其实地址，Value是一个集合，里面存放元素是卡表的索引。这种“双向”的卡表结构(卡表是
  “我指向谁”，这种结构还记录了“谁指向我”)比原来的卡表实现起来更复杂，同时由于Region数量比传统收集器的分代数量要明显多嘚多，因此G1收集器要比其他的
  垃圾收集收有更高的内存占用负担。根据经验，G1至少要耗费大约相当于java堆容量的10%~20%的额外内粗拿来维持收集器工作。
+ 在并发标记阶段如何保证收集线程于用户线程互相不干扰地运行。这里要先解决的是用户线程改变对象引用关系时，必须保证其不能打破原本的对象图结构，导致
  标记结果出现错误，解决办法之前提过：CMS收集器采用增量更新算法实现，G1收集器通过演示快照(SATB)算法实现。
  垃圾收集对用户的影响还体现在回收过程中新创建对象的内存分配上，程序要继续运行肯定会持续创建新对象，G1为每个Region设计了两个TAMS(Top at Mark Start)
  指针，把Region中的一部分空间划分出来用于并发回收过程中的新对象分配，并发回收时新分配的对象地址都必须要在这俩指针位置上。G1默认在这个地址以上的对象
  是是被隐式标记过的，即默认他们是存活的，不纳入回收范围。与CMS中的“Concurent Mode Failure”失败会导致Full GC类似，若内存回收的速度赶不上内存
  分配速度，G1也要被迫冻结用户线程执行，导致Full GC产生长时间的STW
+ 怎样建立起可靠的停顿预测模型？用户通过-XX:MaxGCPauseMillis指定的停顿时间只意味着垃圾收集发生之前的期望值，但G1要怎样做才能满足用户的期望？
  G1收集器的停顿预测模式是以衰减均值(Decaying Average)为理论基础实现的，在垃圾收集过程中，G1会记录每个Region的回收耗时、每个Region记忆集里的脏卡
  数量等各个可预测量的步骤花费的成本，并分析得出平均值、标准偏差、置信度等统计信息。
  这里强调的“衰减平均值”是指它会比普通的平均值更容易受到新数据的影响，平均值代表整体平均状态，但衰减平均值更准确地代表“最近的”平均状态。
  Region的统计状态越新越能决定其回收的机制。然后通过这些信息预测现在开始回收的话，由哪些Region组成回收集才可以在不超过预期停顿时间的约束下获得最高的
  收集。

如果不去计算用户线程运行过程中的动作(如使用写屏障维护记忆集的操作)，G1收集器的运作过程大致可划分为4个步骤：
+ 初始标记(Initial Marking)：只是标记一下GC Roots能直接关联到的对象，并且修改TAMS指针的值，让下一阶段用户线程并发运行时，能正确地在可用的Region
  中分配新对象。需要停顿线程，耗时很短，是借用进行Minor GC的时候同步完成的，所以G1收集器在这个阶段实际上并没有额外的停顿。
+ 并发标记(Concurrent Marking)：从CG Root开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象，耗时较长，可与用户程序并发执行。
  当扫描完后，还要重新处理STAB记录下的在并发时有引用变动的对象。
+ 最终标记(Final Marking)：对用户线程做另一个短暂的停顿，用于处理并发阶段结束后仍遗留下来的最后那少量的SATB记录。
+ 筛选回收(Live Data Counting and Evacuation)：更新Region的统计数据，对各个Region的回收价值和成本进行排序，根据用户所期望的停顿时间来制定回收
  计划，可以自由选择任意多个Region构成回收集，然后把决定回收的那部分Region的存活对象复制到空的Region中，再清理掉整个旧Region的全部空间。
  操作涉及存活对象的移动，必须暂停用户线程，由多条收集器线程并行完成。
  可看出，G1除了并发标记，其余阶段也是要完全暂停用户线程的，它并非纯粹地追求低延迟，官方给他设定的目标是：在延迟可控下尽可能高的吞吐量，所以才能担当起“全
  功能手机器”的重任与期望。

考虑到G1不是仅仅面向低延迟，停顿用户线程能最大幅度提高垃圾收集效率，为了保证吞吐量所以才选择完全暂停用户线程的实现方案。

G1运行示意图：
CPU0--用户线程1-->|           |--用户线程1-->|--最终标记-->|--筛选回收--> |--用户线程1-->
CPU1--用户线程2-->|--初始标记-->|--用户线程1-->|--最终标记-->|--筛选回收-->|--用户线程1-->
CPU2--用户线程3-->|           |--并发标记--> |--最终标记-->|--筛选回收--> |--重置线程-->
CPU3--用户线程4-->|           |--用户线程1-->|--最终标记-->|--筛选回收--> |--用户线程1-->
safepoint		safepoint 		safepoint	 	             safepoint

可以由用户指定期望的停顿时间是G1强大的一个功能，设置不同的期望停顿时间，可使G1在不同应用场景中取得关注吞吐量和关注延迟之间的最佳平衡。
默认的停顿目标为200ms，一般说，回收阶段占到几十到100甚至接近200ms都很正常。
但若把停顿时间调得非常低，假如设置20ms，很可能出现的结果是由于停顿目标时间太短，导致每次选出来的回收只占堆内存很小的一部分，
收集器收集的速度逐渐跟不上分配器分配的速度，导致垃圾慢慢堆积。很可能一开始收集器还能从空闲的堆内存获得一些喘息，但应用运行时间一长就不行了，最终
占满堆引发Full GC反而降低性能，所以通常把期望停顿时间设置为一两百ms或者300ms会是比较合理的。

从G1开始，垃圾收集器的设计导向都变为追求能应付应用的内存分配速率(Allocation Ratio)，而不追求一次性把整个java堆全部清理干净。
这样，应用在分配，同时收集器在收集，只要收集的速度能跟上对象分配的速度，那么一切就能运作的很完美。

G1有点很多，暂且不论可以指定最大停顿时间、分Region的内存布局、按收益动态确定回收集这些创新性设计带来的红利，单从最传统的算法理论上看，
G1也更有发展潜力。
G1从整体来看是基于标记-整理算法实现，但从局部(两个Region之间)上看又是基于标记-复制算法实现，这两种算法都意味着G1运作期间不会产生内存空间碎片，垃圾
收集完成后能提供规整的可用内存。
这种特性有利于程序长时间运行，在程序为大对象分配内存时不容易因无法找到连续内存空间而提前触发下一次收集。

G1比起CMS弱项不少，如在用户程序运行过程中，G1无论是为了垃圾收集产生的内存占用(Footprint)还是程序运行时的额外执行负载(Overload)都要比CMS高。
+ 内存占用方面，虽然G1和CMS都用卡表来处理跨代指针，但G1的卡表复杂，且堆中每个Region，无论是扮演新生代还是老年代角色，都必须有一份卡表，导致G1的记忆集
  (和其他内存消耗)可能会占整个堆容量的20%乃至更多；相比起CMS的卡表就相当简单，只有唯一一份，且只需处理老年代到新生代的引用，反过来则不需要，由于新生代
  的对象具有朝生熄灭的不稳定性，引用变化频繁，能省下这个区域的维护开销是很划算的。
+ 在执行负载角度上，由于两个收集器细节实现导致用户程序运行时的负载会不同，譬如他们都用写屏障，CMS用写后屏障更新维护卡表；而G1除了用写后屏障来进行同
  样的(由于G1的卡表结构复杂，其实更琐碎)卡表维护操作外，为了实现原始快照搜索(STAB)算法，还要用写前屏障来跟踪并发时的指针变化情况。相比起增量更新算法，
  原始快照搜索能减少并发标记和重新标记阶段的消耗，避免CMS那样在最终标记阶段停顿时间过长的缺点，但在用户程序运行过程中确实会产生由跟踪引用变化带来的
  额外负担。由于G1对写屏障的复杂操作要比CMS消耗更多的运算资源，所以CMS的写屏障实现是直接的同步操作，而G1就不得不将其实现为类似于消息队列的结构，把
  写前屏障中要做的事情放到队列里，然后再异步处理。

笔者经验，目前在小内存应用上CMS表现大概率要优于G1，而在大内存上G1则大多能发挥其优势，这个优劣的java堆容量平衡点通常在6G至8G之间。要是实测。

### 低延迟垃圾收集器
衡量垃圾收集器的三项最重要指标是：内存占用(Footprint)、吞吐量(Throughput)和延迟(Latency)，共同构成一个“不可能三角”。
https://zh.wikipedia.org/wiki/三元悖论
优秀的收集器通常最多可以同时达成其中两项。

延迟的重要日益凸显，越发备受关注。
原因是计算机硬件发展、性能提升，内存便宜，而且更大，所以能容忍收集器多占用一点点内存；硬件性能增长，有助于降低收集器运行时对应用程序的影响，吞吐量
会更高。但对于延迟不这样，内存扩大，延迟会有负面效果，越大内存耗费时间更长。

CMS和G1分别使用增量更新和原始快照技术，实现了标记阶段的并发，不会因管理的堆内存变大，要标记的对象变多而导致停顿时间随之增长。但是对于标记阶段之后
的处理，仍未得到妥善解决。
CSM使用标记-清除算法，虽然避免整理阶段收集器带来的停顿，但是清除算法不论如何优化改进，在设计原理上避免不了空闲碎片的产生，随着空间碎片不断堆积最终
还是要STW的。G1虽然可以按更小的力度进行回收，从而抑制整理阶段出现时间过长的停顿，但毕竟还是要暂停的(复制时)。

### Shenandoah收集器
是一款只有OpenJDK才会包含，而OracleJDK里不存在的收集器。
由RedHat发展项目，后来贡献给OpenJDK。项目目标是实现一种能在任何堆内存大小都可以把垃圾收集的停顿时间限制在十毫秒以内，意味着不仅要并发的垃圾标记，
还要并发地进行对象清理后的整理动作。

与G1有相似的堆内存布局，在初始标记、并发标记等许多阶段的处理思路高度一致，使得部分对G1的打磨改进和Bug修改会同时反映到Shenandoah上，而由于Shenandoah
加入所带来的新特性，也有部分会在G1中出现，譬如并发失败后的Full GC，G1由于合并了Shenandoah的代码才获得多线程Full GC的支持。

Shenandoah在管理内存方面,与G1有三个明显的不同，
xxxxxxx

### ZGC收集器
xxxxxxx


### Epsilon收集器
xxxxxxx


### 收集器的权衡
如何选择收集器，主要受限三个因素：
+ 应用程序的主要关注点是什么？若是数据分析、科学计算类任务，目标是能尽快算出结果，那吞吐量就是主要关注点；若是SLA应用，那停顿时间直接影响服务质量，
  严重的甚至会导致事务超时，延迟就是主要关注点；若是客户端应用或嵌入式应用，那垃圾收集的内存占用则是不可忽视的。
+ 运行引用的基础设施如何？譬如硬件规格，涉及的系统架构是x86-32/64、SPARC还是ARM/Aarch64；处理器的数量多少，分配内存的大小；选择的操作系统是
  Linux、Solaris还是Windows等
+ 使用的JDK的发行商是什么？版本号是多少？是ZingJDK/Zulu、OracleJDK、Open-JDK、OpenJ9亦或是其他公司的发行版？该JDK对应<java虚拟机规范>
  哪个版本?

例如，假设某个直接面向用户提供服务的B/S系统准备选择垃圾收集器，一般来说延迟时间是主要关注点，那么：
+ 若你有充足的运算但没有太多的调优经验，那么一套带商业技术支持的专有硬件或软件解决方案是不错选择，Azul公司以前推出的Vega系统和现在主推的Zing VM是
  代表，你可以使用传出中的C4收集器了
+ 若你虽没有足够预算去使用商业解决方案，但能掌握软硬件型号，使用较新的版本，同时特别注重延迟，那么ZGC值的尝试
+ 若你还对处于试验状态的收集器的稳定性有所顾虑，或应用必须运行在Windows操作系统，那么ZGC就不行了，试试Shenandoah
+ 若你接收的是遗留系统，软硬件基础设施和JDK版本都比较落后，那就根据内存规模衡量一下，对于大概4G到6G一下的堆内存，CMS一般能处理得比较好，对于更大
  的堆内存，可重点考察一下G1。
+ 根据系统实际情况去测试才是选择收集器的最终依据


## 虚拟机及垃圾收集器日志
jdk9以前，hotSpot没有提供统一的日志处理框架，虚拟机各个功能模块的日志开关分布在不同的参数上，日志级别、循环日志大小、输出格式、重定向等设置在
不同功能上都要单独解决。
直到jdk9，这种混乱才消失，hotSpot所有功能的日志都收归到了“-Xlog”参数上
-Xlog[:[selector][:[output][:[decorators][:output-options]]]]
选择器(Selecotr)，由标签(Tag)和日志级别(level)共同组成。
标签可理解为虚拟机中某个功能模块的名字，告诉日志框架用户希望得到虚拟机哪些功能的日志输出。垃圾收集器的标签名称为"gc"，垃圾收集器日志只是hotSpot
众多功能日志的其中一项，全部支持的功能模块标签名：
add,age,alloc,annotation,aot,arguments,attach,barrier,biasedlocking,blocks,bot,breakpoint,bytecode
还可用修饰器(Decorator)要求每行日志输出都附加上额外的内容，附加信息包括：
+ time：当前日志和时间
+ uptime：虚拟机启动到现在经过的时间，s
+ timemillis：当前时间的毫秒数，相当于System.currentTimeMillis()
+ uptimemillis：虚拟机启动到现在经过的毫秒数
+ timenanos：当前时间的纳秒数，相当于System.nanoTime()
+ uptimenanos：虚拟机启动到现在经过的纳秒数
+ pid：进程ID
+ tid：线程id
+ level：日志级别
+ tags：日志输出的标签集
  默认是uptime、level、tags，输出形式
  [3.080s][info][gc,cpu] GC(5) User=0.03s Sys=0.00s Real=0.01s

展示jdk9的G1统一日志框架前、后是如何获得垃圾收集器过程的相关信息，jdk9默认G1
1) 查看GC基本信息，jdk9之前-XX:+PrintGC，jdk9后-Xlog:gc
   java -Xlog:gc GCTest
2) 查看GC详细信息，jdk9之前-XX:+PrintGCDetials，jdk9后-Xlog:gc*(通配符*将GC标签下的所有细分过程都打印出来)
   java -Xlog:gc* GCTest
3) 查看GC前后的堆、方法区可用容量变化，jdk9之前-XX:+PrintHeapAtGC，jdk9后-Xlog:gc+heap=debug
   java -Xlog:gc+Heap=debug GCTest
4) 查看GC过程中用户线程并发时间以及停顿的时间，jdk9之前-XX:+PrintGCApplicationConcurrentTime和-XX:PrintGCApplicationStoppedTime，
   jdk9后-Xlog:safepoint
   java -Xlog:safepoint GCTest
5) 查看收集器Ergonomics机制(自动设置堆空间个分代区域大小、收集目标等内容，从Parallel收集器开始支持)自动调节的相关信息。
   jdk9之前-XX:+PrintAdaptiveSizePolicy，jdk9后-Xlog:gc+ergo*=trace
6) 查看熬过收集器后剩余对象的年龄分布信息。jdk9之前-XX:+PrintTenuringDistribution，jdk9后-Xlog:gc+age=trace

表3-3 jdk9前后日志参数变化
xxxxxxxx


垃圾收集器参数总结
xxxxxxxx


## 实战：内存分配与回收策略
java技术体系的自动内存管理，最根本的目标是自动化地解决俩问题：自动给对象分配内存以及自动回收分配给对象的内存。

对象的内存分配，应该都是在堆上分配。经典的分代设计下，新生对象通常在新生代中，少数情况(如对象大小超过一定的阈值)也可能会直接分配到老年代。
本结验证的使用Serial+Serial Old客户端默认收集器组合下的内存分配和回收策略。
主要学习的是分析方法，而列举的分配规则反而是次要的。

### 对象优先在Eden分配
AllocationTest
多数情况，对象在新生代Eden区中分配。当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。
-XX:+PrintGCDetails发生垃圾收集时打印内存回收日志，并在进程退出时输出当前的内存各区域分配情况。

### 大对象直接进入老年代
PretenureSizeThresholdTest
大对象指需要大量连续内存空间的java对象，典型的就是很长的字符串，或元素数量很庞大的数组。
耕坏的是一群“招生熄灭”的短命大对象。程序应该避免。
在java虚拟机中要避免大对象的原因是：在分配空间时，它容易导致内存命名还有不少空闲时就提前触发垃圾收集，以获得足够的连续空闲才能安置好他们，而当
复制对象时，大对象就意味着高额的内存复制开销。
hotSpot提供了-XX:PretenureSizeThreshold，指定大于该设置值的对象直接在老年代分配，目的是避免在Eden区及两个Survivor区之间来回复制，产生
大量的内存复制操作。

### 长期存活的对象将进入老年代
TenuringThresholdTest
hotSpot虚拟机中多数收集器都采用了分代收集来管理堆内存，那内存回收时必须能决策哪些存活对象应当放入新生代，哪些存活对象放在老年代。
为做到这点，虚拟机给每个对象定义了一个对象年龄(Age)计数器，存储在对象头中。
对象通常在Eden区诞生，若经过第一次Minor GC后仍然存活，并能被Survivor容纳，该对象会被移动到Suvivor空间中，并且将其对象年龄设为1岁。对象在Survivor
区中每熬过一次MinorGC，年龄+1，当年龄增加到一定程度(默认15)，就会被晋升到老年代。阈值-XX:MaxTenuringThreshold

### 动态对象年龄判定
TenuringThreshold2Test
为了更好地适应不同程度的内存状况，htoSpot并不是永远要求对象年龄必须达到-XX:MaxTenuringThreshold才能晋升，若在Survivor空间中相同年龄所有对象大小
的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接晋升。

### 空间分配担保
HandlePromotionTest
在发生Minor GC之前，虚拟机必须先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，若成立，那么这次Minor GC可以确保是安全的。若不成立，则
虚拟机会先看-XX:HandlePromotionFaiure是否允许担保失败(Handle Promotion Failure)；若允许，那么会继续检查老年代最大可用的连续空间是否大于历次
晋升到老年代对象的平均大小，若大于，则尝试进行一次Minor GC，尽管这次Minor GC是有风险的；若小于，或者-XX:HandlePormotionFailure设置不允许，
那这时就改为进行一次Full GC

冒险含义：新生代使用复制收集算法，但为了内存利用率，只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在Minor GC后仍存活的情况——最极端的
就是内存回收后新生代中所有对象存活，需要老年代进行分配担保，把Survivor无法容纳的对象直接送入老年代。老年代要进行担保，前提是老年代还有容纳这些对象
的剩余空间，但一共有多少对象会回收中活下来不确定，所以只能取之前每一次回收晋升到老年代对象容量的平均大小作为经验值，与老年代的剩余空间比较，决定
是否进行Full GC来让老年代腾出更多空间。
若出现担保失败，那么只能Full GC，这样停顿时间长了。虽然担保失败时绕的圈子最大，但通常-XX:HandlePromotionFaiure还是打开，避免Full GC过于频繁。
注：JDK6之后就不用此参数了。jdk6之后规则为只要老年代的连续空间大于新生代对象总大小或历次晋升的平均大小，就会进行Minor GC，否则进行Full GC

### 小结
垃圾收集器在许多场景中都是影响系统停顿时间和吞吐能力的重要因素之一，之所以提供多种不同的收集器以及大量的调节参数，是因为只有根据实际应用需求、实现
方式选择最优的收集方式才能获得最好的性能。
没有固定收集器、参数组合，没有最优的调优方法，虚拟机也就没有什么必然的回收行为。
学习虚拟机内存只是，若要到实践调优阶段，必须了解每个具体收集器的行为、优势劣势、调节参数。。


## 第4章
理论总是作为指导实践的工具，把这些知识应用到实际工作中才是最终的目的。
给一个系统定位问题的时，知识、经验是关键基础，数据是依据，工具是运用知识处理数据的手段。这里数据不仅仅是异常堆栈、虚拟机运行日志、垃圾收集日志、
线程快照(threaddump/javacore文件)、堆转储快照(heapdump/hrpof文件)等。
工具永远是知识技能的一层包装。

JKD的bin目录中软件依据软件可用性和授权不同分类：
+ 商业授权工具：JMC(Java Mission Control)及它要用到的JFR(Java Flight Recorder)
+ 正式支持工具：长期支持
+ 实验性工具：Unsupported and Experimental。事实上他们通常都非常稳定且功能强大。
  这些工具多数仅是一层薄包装，真正的功能代码是是实现在JDK的工具类库中的xx.jmod

注：若需要监控运行于JDK5之上的的程序，在程序启动时-Dcom.sum.management.jmxremote开启JMX管理功能。jdk6以上默认开启。
这些工具在jdk9之前代码的实现在jdk/lib/tools.jar中

### jps：虚拟机进程状况工具
jps(JVM Process Status Tool)：列出正在运行的虚拟机进程，并显示虚拟机执行主类(Main Class, main()函数所在类)名称以及这些进程的本地虚拟机唯一
ID(LVMID, Local Virtual Machine Identifier)
对于本地虚拟机进程，LVMID与操作系统的进程ID(PID, Process Identifier)一致。
jps命令格式：
jps [options] [hostid]
样例：jps -l

jps还可以通过RMI协议查询开了RMI服务的远程虚拟机进程状态，hostidWieRMI注册表中注册的主机名。

jps常用选项：
-q  只输出LVMID，省略主类的名称
-m  输出虚拟机进程启动时传递给主类main()函数的参数
-l  输出主类的全名，若进程执行的是JAR包，则输出JAR路径
-v  输出虚拟机进程启动时的JVM参数

### jstat:虚拟机统计信息监视工具
jstat(JVM Statistics Monitoring Tool)用于监视虚拟机各种运行状态信息。
可以显示本地或远程(需要目标提供RMI支持，jstatd可以很方便建立远程RMI服务器)虚拟机进程中的类加载、内存、垃圾收集、即时编译等运行时数据。
可定位虚拟机性能问题。

格式：
jstat [ option vmid [interval[s|ms] [count]] ]  ,interval和count代表间隔和次数
注：若是本地虚拟机进程，VMID与LVMID一致，若是远程虚拟机进程，VMID格式：[protocol:][//]lvmid[@hostname[:port]/servername]
举例：每250毫秒查询一次进程2764垃圾收集状况，一共查询20次
jstat -gc 2764 250 20

option代表用户希望查询的虚拟机信息，三类：类加载、垃圾收集、运行期编译状况

jstat主要选项
-class  监视类加载、卸载数量、总空间以及类装载所耗费的时间
-gc  监视java堆状况，包括Eden区、2个Survivor区、老年代、永久代等的容量，已用空间，垃圾收集时间合计等信息
-gccapacity  与-gc相同，但输出主要关注java堆各个区域使用的最大、最小空间
-gcutil  与-gc基本相同，但输出主要关注已使用空间占总空间的百分比
-gccause  与-gcutil功能一样，但是会额外输出导致上一次垃圾收集产生的原因
-gcnew  监视新生代垃圾收集状况
-gcnewcapacity  同-gcnew，输出主要关注使用的最大、最小空间
-gcold  监视老年代垃圾收集
-gcoldcapacity  同gcold，输出主要关注使用到的最大、最小空间
-gcpermcapacity  输出永久代使用到的最大、最小空间
-compiler  输出即时编译器编译过的方法、耗时等信息
-printcompilation  输出已经被即时编译的方法

举例:stat -gcutil 2764
S0    S1   E     O    P   YGC YGCT FGC FGCT GCT
0.00 0.00 6.20 41.42 47.20 16 0.105 3 0.472 0.577
解释：
新生代Eden区(E,表示Eden)使用了6.2%的空间，2个Survivor区(S0、S1,表示Survivor0、Survivor1)里面都是空的，
老年代(O,表示Old)和永久代(P,表示Permanent)分别使用了41.42%和47.2%的空间。
程序运行以来共发生Minor GC(YGC,表示Young GC)16次，总耗时0.105s
发生Full GC(FGC,表示Full GC)3次，总耗时(FGCT,表示Full GC Time)为0.472s
所有GC总耗时(GCT,表示GC Time)为0.577s

### jinfo：java配置信息工具
jinfo(Configuration Info for Java)作用是实时查看和调整虚拟机各项参数。
还可以用-sysprops把虚拟机进程的System.getProperties()打印
使用-flag[+|-]name或-flag name=value在运行期修改一部分运行期可写的虚拟机参数

格式：
jinfo [ option ] pid

样例：查询CMSInitiatingQccupancyFraction值
jinfo -flag CMSInitiatingOccupancyFraction 1444

jinfo 1111 就可以查看很多基本启动参数


### jmap：java内存映像工具
jmap(Memory Map for Java)用于生成堆转储快照(heap dump文件)。还可以查询finalize执行队列、java堆和方法区的详细信息，如空间使用率、当前
用户的哪种收集器等。

格式：
jmap [ option ] vmid

jmap选项
-dump  生成java堆转储快照。格式：-dump:[live,]format=b,file=<filename>，live子参数说明是否只dump出存活的对象
-finalizerinfo  显示在F-Queue中等待Finalizer线程执行finalize方法的对象。
-heap  显示java堆详细信息，如使用哪种回收器、参数配置、分代状况等。
-histo  显示堆中对象统计信息，包括类、实例数量、合计容量
-permstat  以ClassLoader为统计口径显示永久代内存状态。
-F  当虚拟机进程对-dump选项没有响应时，可使用此选项强制生成dump快照。

举例：
jmap -dump:format=b,file=eclipse.bin 3500

jmap -histo:live 41192看到有哪些类以及占用
jmap -heap 1111


### jhat：虚拟机堆和钻出快照分析同居
jhat(JVM Heap Analysis Tool)与jmap搭配使用，分析jmap生成的堆转储快照。有些简陋
使用其Heap Histogram分析内存泄露问题

### jstack：java堆栈跟踪工具
jstack(Stack Trace for java)用于生成虚拟机当前时刻的线程快照(threaddump或javacore文件)。
线程快照是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求
外部资源导致的长时间挂起等，都是导致线程长时间停顿的常见原因。
命令格式：
jstack [ option ] vmid
主要选项
-F  当正常输出的请求不被响应时，强制输出线程堆栈
-l  除堆栈外，显示关于锁的附加信息
-m  若调用到本地方法，可以显示C/C++的堆栈

举例：
jstack -l 3500

jdk5起Thread有getAllStackTraces()用于获取虚拟机中所有线程的StackTraceElement对象。可以做个管理页面

```
<%@ page import="java.util.Map"%>
<html>
<head> <title>服务器线程信息</title> </head>
<body>
<pre>
<%
for (Map.Entry<Thread, StackTraceElement[]> stackTrace : Thread.getAllStack-Traces().entrySet()) { 
Thread thread = (Thread) stackTrace.getKey();
StackTraceElement[] stack = (StackTraceElement[]) stackTrace.getValue();
if (thread.equals(Thread.currentThread())) {
continue; }
out.print("\n线程:" + thread.getName() + "\n"); 
for (StackTraceElement element : stack) {
out.print("\t"+element+"\n"); }
}
%>
</pre> </body> </html>
```

无论jdk发展到什么版本，学习这些基础的工具命令并不会过时和浪费

工具
+ 基础工具：支撑基本的程序创建和运行
  jar  创建和管理JAR文件
  java  运行工具，用于运行Class文件或JAR文件
  javac  用于java编程语言的编译器
  javadoc  java的API文档生成器
  javah  C语言头文件和Stub函数生成器，用于编写JNI方法
  javap  java字节码分析工具
  jlink  将Module和它的依赖打包成一个运行时镜像文件
  jdb  基于JPDA协议的调试器，以类似于GDB的方法进行调试java代码
  jdeps  java类依赖性分析器
  jdeprscan  用于搜索JAR包中使用了"deprecated"的类，jdk9开始
+ 安全：用于程序签名、设置安全测试等
  keytool  管理秘钥库和证书。主要用于获取或缓存Kerberos协议的票据授权票据。允许用户查看本地凭据缓存和密钥表中的条目(用于Kerberos协议)
  jarsigner  生成并验证JAR签名
  policytool  管理策略文件的GUI工具，用于管理用户策略文件(.java.policy)，jdk10移除
+ 国际化：用于创建本地语言文件
  native2ascii  本地编码到ASCII编码的转换器(Native-to-ASCII Converter)，用于“任意受支持的字符编码”和与之对应的"ASCII编码和Unicode转义"之间的转换
+ 远程方法调用：用于跨Web或网络的服务交互
  rmic  java RMI编译器，为使用JRMP或IIOP协议的远程对象生成Stub、Skeleton和Tie类，也用于生成OMG IDL
  rmiregistry  远程对象注册表服务，用于在当前主机的制定端口上创建并启动一个远程对象注册表
  rmid  启动激活系统守护进程，允许在虚拟机中注册或激活对象
  serialver  生成并返回指定类的序列化版本ID
+ 部署工具：用于程序打包、发布和部署
  javapackager  打包、签名java和javaFX应用程序，jdk11移除
  pack200  使用java GZPI压缩器将JAR文件转换为压缩的Pack200文件。压缩文件时高度压缩的JAR，可以直接部署，节省带宽并减少下载时间
  unpack200  将Pack200生成的打包文件解压提取为JAR文件
+ 性能监控和故障处理：用于监控分析java虚拟机运行信息，排查问题
  jps  JVM Process Status Tool，显示指定系统内所有HotSpot虚拟机进程
  jstat  JVM Statistic Monitoring Tool，用于收集hotspot虚拟机各方面的运行数据
  jstatd  JVM Statistic Monitoring Tool Deamon，jstat的守护程序，启动一个RMI服务器应用程序，用于监视测试的hotSpot虚拟机的创建和终止，并提供界面，
  允许远程监控工具附加到本地系统上运行的虚拟机。jdk9集成到了JHSDB中
  jinfo  Configuration Info for java，显示虚拟机配置信息。jdk9集成到JHSDB中
  jmap  Memory Map for java，生成虚拟机的聂村转储文件(heapdump)。jdk9集成到JHSDB中
  jhat  JVM Heap Analysis Tool，用于分析堆转储快照，会创建一个http/web服务器。jdk9被JHSDB代替
  jstack  Stack Trace for java，显示虚拟机的线程快照。jdk9中集成到JHSDB中
  jhsdb  Java HotSpot Debugger，一个基于Serviceability Agent的HotSpot进程调试器，jdk9开始
  jsadebugd  Java Serviceability Agent Debug Daemon，适用于java的可维护性代理调试守护程序，主要用于附加到指定的java进程、核心文件，或充当一个调试
  服务器
  jcmd  JVM Command，虚拟机诊断命令工具，将诊断命令请求发送到正在运行的java虚拟机。jdk7开始
  jconsole  java Console，用于监控java虚拟机的使用JMX规范的图形工具。可以监控本地和远程java虚拟机，还可以监控和管理应用程序
  jmc  java Mission Control，包含用于监控和管理java应用程序的工具，不会引入与这些工具相关联的性能开销。
  jvisualvm  Java VisualVM，图形工具，可在java虚拟机中运行时提供有关基于java技术的应用程序(java应用程序)的详细信息。提供内存和CPU分析、堆转出分析、
  内存泄漏检测、MBean访问和垃圾收集。jdk9开始可独立下载
+ REPL和脚本工具
  jshell  基于java的Shell REPL(Read-Eval-Print Loop)交互工具
  jjs  对Nashorn引擎的调用入口。Nashorn是基于java实现的一个轻量级高性能javaSscript运行环境
  jrunscript  java命令行脚本外壳工具(Command Line Script Shell)，主要用于解释执行JavaScript、Groovy、Ruby等脚本语言

### JHSDB：基于服务性能代理的调试工具
基于服务型代理(Serviceability Agent, SA)实现的进程外调试工具。
服务性代理时hotSpot虚拟机中一组用于映射java虚拟机运行信息的、主要基于java语言(含少量JNI代码)实现的API集合。
服务性代理以hotSpot内部的数据结构为参照物进行设计，把这些C++的数据抽象出java模型对象，相当于hotspot的C++代码的一个镜像。
通过服务性代理的API，可以在一个独立的java虚拟机的进程里分析其他hotSpot虚拟机的内部数据，或从HotSpot虚拟机进程内存中dump出来的转储快照里还原出
他的运行状态细节。
JHSDBTest

本次目的：
借助JHSDB分析代码，并回答staticObj、instanceObj、localObj三个变量本身(指针，而不是他们指向的对象)放在那里？

查看虚拟机进程id：jps -l
jhsdb hsdb --pid <pid>

查看内存布局以及地址
Tools->Heap Parameters，可以看到Serial的分代内存布局，列出了新生代的Eden、S1、S2和老年代的容量(字节)以及他们的虚拟内存地址起止范围

Heap Parameters:
Gen 0:   eden [0x000000010ee00000,0x000000010f033ac8,0x000000010f0b0000) space capacity = 2818048, 81.92933548328489 used
from [0x000000010f100000,0x000000010f100000,0x000000010f150000) space capacity = 327680, 0.0 used
to   [0x000000010f0b0000,0x000000010f0b0000,0x000000010f100000) space capacity = 327680, 0.0 usedInvocations: 6
Gen 1:   old  [0x000000010f150000,0x000000010f800000,0x000000010f800000) space capacity = 7012352, 100.0 usedInvocations: 38

注：0x000000010ee00000,0x000000010f033ac8,0x000000010f0b0000表示，起始地址，当前使用，结束地址

Windows->Console

在old范围内查找ObjectHolder实例
hsdb> scanoops 0x000000010f150000 0x000000010f800000 com.wolf.concurrenttest.utjvm.tooldemo.JHSDBTest$ObjectHolder 怎么跑old中了
0x000000010f67e208 com/wolf/concurrenttest/utjvm/tooldemo/JHSDBTest$ObjectHolder
0x000000010f67e230 com/wolf/concurrenttest/utjvm/tooldemo/JHSDBTest$ObjectHolder
0x000000010f67e240 com/wolf/concurrenttest/utjvm/tooldemo/JHSDBTest$ObjectHolder

Tools->Inspector，确认这三个地址中存放的对象
在窗口中输入上面的内存地址
展示了对象头和指向对象元数据的指针，里面包括了java类型的名字、继承关系、实现接口关系，字段信息、方法信息、运行时常量池的指针、内嵌的虚方法表(
vtable)以及接口方法表(itable)等。

根据堆中对象实例地址找出引用他们的指针
$revptrs 0x000000010f67e208
Computing reverse pointers...
Done.
null
Oop for java/lang/Class @ 0x000000010f67dea0
找到一个引用该对象的地方，是在一个java.lang.Class的实例中

通过Inspector查看该对象实例，可以看到是一个java.lang.Class类型的对象实例，里面有一个名为staticObj的实例字段
jdk7以后选择把静态变量与类型在java语言一段的映射Class对象存放在一起，存储于java堆之中。

查询第二个
$revptrs 0x000000010f67e230 找到0x000000010f67e218
找到一个类型为com/wolf/concurrenttest/utjvm/tooldemo/JHSDBTest$Test对象实例
第二个ObjectHolder的指针是在java堆中com/wolf/concurrenttest/utjvm/tooldemo/JHSDBTest$Test对象的instanceObj字段上。

查询第三个
revptrs 0x000000010f67e240
JHSDB返回null，表示未查找到任何结果，看来其不支持查找栈上指针引用
在Java Thread(启动时的那个窗口)窗口选中main线程后点击Stack Memory按钮看线程栈内存
这个线程只有两个方法帧，左边是内存地址，右边是对象地址，可以看到在Old Gen中

通过visualVM可以看到这个程序怎么old是满的，，，而且Eden还在不断增长。。还不断有Full GC。。。
jstat -gcutil 42858 1000 100也能确定
只有基本的main方法，也这样。。是Compile Time不断变更，可能是不断进行事实编译。。。


### JConsole：java监视与管理控制台
JConsole(Java Monitoring and Management Console)基于JMX(Java Management Extentions)的可视化监视、管理工具。
主要功能是通过JMX的MBean(Managed Bean)对系统进行信息收集和参数动态调整。
JMX是一种开放性的技术，不仅可以用在虚拟机本身的管理上，还可以运行于虚拟机之上的软件中，典型的如中间件大多也基于JMX来实现监控与管理。
虚拟机堆MBean的访问也是完全开放的，可以使用代码调用API、支持JMX协议的管理控制台，或者其他符合JMX规范的软件进行访问。
JMX支持跨服务器的管理，也可以用远程进程功能来连接远程服务器。

一致eden占用27328K，eden:survivor=8:1，求young gen
eden:survivor1:survivor1=8:1:1
所以eden/young = 8/10=4/5 => young=eden*5/4=> eden*125%

### VisualVM：多合-故障处理工具
VisualVM(All-in-One Java Troubleshooting Tool)功能最强大的运行监视和故障处理程序之一。
不需要被监视的程序基于特殊Agent取运行，通用性很强，度应用程序实际性能的影响也较小。这个优点是JProfiler、YourKit等工具无法媲美的。

VisualVM基于NetBeans平台开发工具，一开始就具备了通过插件扩展功能的能力，有了插件扩展支持，可以做到：
+ 显示虚拟机进程以及进程的配置、环境信息(jps、jinfo)
+ 监视应用程序的处理器、垃圾收集、堆、方法区以及线程的信息(jstat、jstack)
+ dump以及分析堆转储快照(jmap、jhat)
+ 方法及的程序运行性能分析，找出被调用最多、运行时间最长的方法
+ 离线程序快照：收集程序的运行时配置、线程dump、内存dump等信息建立一个快照，可以将快照发送给开发者处理。
+ 其他插件来带来的无限可能性  --是不是将jvm内部的信息暴露给插件，由他们来决定处理？
  Tools->Plugins

在Profiler页签中，体用了程序运行期间方法级的处理器执行时间分析以及内存分析。会对程序运行性能有比较大的影响，一般不在生产环境使用，或者改用
JMC完成，JMC的Profiling能力更强，对应用的影响非常轻微

BTrace插件，本身也是一个可运行的独立程序。
https://github.com/btraceio/btrace/tags
作用是在不中断目标程序运行的前提下，通过HotSpot虚拟机的Instrument功能动态加入原本并不存在的调试代码。
选择进程，右键，选择“Trace Application..” 输入脚本，点击Start

用途很广泛，打印调用堆栈、参数、返回值，进行性能监视、定位连接泄露、内存泄露、解决多线程竞争问题等
之所以能够实现动态修改程序行为，是因为它基于java虚拟机的Instrument开发。
Instrument是java虚拟机工具接口(Java Virtual Machine Tool Interface, JVMTI)的重要组件，提供了一套代理(Agent)机制，使得第三方工具程序
可以以代理的方式访问和修改java虚拟机内部的数据。Arthas也通过Instrument实现了与BTrace类似的功能。

https://visualvm.github.io/uc/release21/updates

### Java Mission Control：可持续在线的监控工具
JFR(Java Flight Recorder)是一套内建在hotSpot虚拟机里的监控和基于事件的信息搜集框架，与其他(如JProfiling)，
oracle强调他“可持续在线”(Always-On)的特性。
JFR在生产环境对吞吐量的影响一般不超过1%(甚至号称Zero Performance Overhead)，且JFR监控过程的开始、停止都完全可动态，不需要重启应用。
JFR的监控对应用也完全透明，不需要对应用程序的源码做任何改动，或基于特定的代理来运行

JMC与虚拟机之间同样采用JMX协议进行通信，JMC一方面作为JMX控制台，显示来自虚拟机MBean提供的数据；另一方面作为JFR的分析工具，展示其数据。

启动飞行记录时，可以进行记录时间、垃圾收集器、编译器、放发财羊、线程记录、异常记录、网络和文件I/O、事件记录等选项和频率设定。

飞行记录报告包含基类信息：
+ 一般信息：关于虚拟机、操作系统和记录的一般信息
+ 内存：关于内存管理和垃圾收集的信息
+ 代码：关于方法、异常错误、编译和类加载的信息
+ 线程：关于应用程序中线程和锁的信息
+ I/O：关于文件和套接字输入、输出的信息
+ 系统：关于正在运行java虚拟机的系统、进程和环境变量的信息
+ 事件：关于记录中的事件类型的信息，可以根据线程或堆栈跟踪，按日志或图形的格式查看

JFR的基本工作逻辑是：开启一系列事件的录制动作，当某个时间发生时，这个事件的所有上下文数据将会以循环日志的形式被保存至内存或指定的某个文件当中，
循环日志相当于数据流被曝存在一个环境缓存中，所以只有最近发生的事件数据才可用。
JMC从虚拟机内存或文件中读取并展示这些事件数据，并通过这些数据进行性能分析

JFR提供的数据质量也要比其他工具通过代理形式采样获得或者从MBean中取得数据高。
以垃圾收集为例，hotSpot的MBean中一般由各个分代大小、收集次数、时间、占用率等数据，这些都属于“结果”类的信息，而JFR还可以看到内存中这段时间分配了
哪些对象、哪些在TLAB中(或外部)分配、分配速率和压力大小如何、分配归属的线程、收集时对象分带晋升的情况等，这些就属于“过程”类的信息，对排查问题的
价值是难以估量的。

jmc执行后，左侧的“jvm浏览器”中自动显示通过JDP协议(Java Discovery Protocol)找到本机正在运行的hotSpot虚拟机进程。
也可以"文件->连接"创建远程连接，远程虚拟机启动时应该设定参数：
-Dcom.sun.management.jmxremote.port=9999
-Dcom.sun.management.jmxremote.ssl=false
-Dcom.sun.management.jmxremote.authenticate=false
-Djava.rmi.server.hostname=192.168.31.4
-XX:+UnlockCommercialFeatures -XX:+FlightRecorder


### HSDIS：JIT生成代码反汇编
<java虚拟机规范>详细定义了虚拟机指令集中每条指令的语义，尤其是执行过程前后对操作数栈、局部变量表的影响。
后来技术的发展，高性能虚拟机真正的细节实现方式偏离，而规范仅仅称为java虚拟机实现的“概念模型”。实现只保证等效，二不一定按照规范描述去执行。

HSDIS是官方推荐的hotSpot虚拟机即时编译代码的反汇编插件。
插件的租用是让hotSpot的-XX:+PrintAssembly指令调用它即使编译器动态生成的本地代码还原为汇编代码输出，还会自动产生大量有价值注释。
搜索、下载编译好的插件，放到jdk/jre/bin/server目录(jdk9以下)或jdk/lib/amd64/server(jdk9以上)即可。

注：若用的SlowDebg或FastDebug版，可以直接通过-XX:+PrintAssembly指令使用的插件；若用的是Product版，要额外加入-XX:+UnlockDiagnosticVMOptions

hsdis安装---docker中
git clone https://github.com/liuzhengyang/hsdis
cd hsdis
tar -zxvf binutils-2.26.tar.gz
make BINUTILS=binutils-2.26 ARCH=amd64
cp build/linux-amd64/hsdis-amd64.so /usr/lib/jvm/java-1.8.0/jre/lib/amd64/server/
验证：java -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -version


解读汇编代码：
```
[Disassembling for mach='i386']
[Entry Point]
[Constants]
# {method} 'sum' '(I)I' in 'test/Bar'
# this: ecx = 'test/Bar'         
# parm0: edx = int
#        [sp+0x20] (sp of caller)
.....
0x01cac407: cmp     0x4(%ecx),%eax
0x01cac40a: jne     0x01c6b050		       ; {runtime_call}
[Verified Entry Point]
0x01cac410: mov     %eax,-0x8000(%esp)  --检查栈溢
0x01cac417: push    %ebp                --保存上一栈帧基址
0x01cac418: sub     $0x18,%esp           ; *aload_0     --给新镇分配空间
                                         ; - test.Bar::sum@0 (line 8)
;; block B0 [0, 10] 
0x01cac41b: mov     0x8(%ecx),%eax       ; *getfield a    --取实例变量a，0x8(%ecx)就是ecx+0x8意思，上面已提示[Constants]中ecx寄存器中放的就是this对象的地址。
                                                            偏移0x8是越过this对象头的对象头，之后就是实例变量a的内存位置，这次是访问java堆中的数据
                                         ; - test.Bar::sum@1 (line 8)
0x01cac41e: mov     $0x3d2fad8,%esi      ; {oop(a     --取test.Bar在方法区的指针
'java/lang/Class' = 'test/Bar')}
0x01cac423: mov     0x68(%esi),%esi      ; *getstatic b      --取类变量b，这次是访问方法区中的数据
																				 ; - test.Bar::sum@4 (line 8)
0x01cac426: add     %esi,%eax                     
0x01cac428: add     %edx,%eax 
                                         --以上，做2次加法，求a+b+c值，前面把a放在eax中，把b放在esi中，而c在[Constants]中提示了，"param0: edx=int"说明c在edx中
0x01cac42a: add     $0x18,%esp           --撤销栈帧
0x01cac42d: pop     %ebp                 --恢复上一栈帧
0x01cac42e: test    %eax,0x2b0100        ; {poll_return}    --轮询方法返回处的SafePoint
0x01cac434: ret                                             --方法返回
```

本例代码简单，直接看汇编可行，但正式环境很多，必须借助工具辅助了
JITWatch是HSDIS搭配使用的可视化的编译日志分析工具
https://github.com/AdoptOpenJDK/jitwatch
在JITWatch中加载日志。可看到执行期间使用过的各种对象类型和对应调用过的方法了。

选择cofig进行配置，源码和class的根目录，然后点击open log选择，点击start进行
选择想要查看的类和方法，右键->show TriView，即可查看对应的java源代码、字节码和即时编译生成的汇编代码


## 调优案例分析与实战
本部分赵忠考虑如何在应用部署层面去解决问题，有不少案例的确可以再设计和开发阶段先行避免，暂时不讨论。

### 大内存硬件上的程序部署策略
15万PV/日足有的在线文档类型网站。硬件：4路至强处理器、16GB物理内存，64位CentOS5.4操作系统，Resin作为web服务器。jdk是64位JDK5
抵用了一个虚拟机-Xms和-Xmx固定12GB。使用一段时间后发现服务器运行效果十分不理想，经常不定期出现长时间失去响应。
监控服务器运行状况后发现网站失去响应是由于垃圾收集停顿导致。hotSpot虚拟机以服务端模式运行，默认使用的是吞吐量优先收集器，回收12G的java堆，一次Full GC停顿
时间就高达14s。
由于程序设计原因，访问文档时会把文档从磁盘提取到内存，导致内存中出现很多由文档序列化产生的大对象，这些大对象大多在分配时就直接进入老年代，没有在Minor GC被清理掉。
此情况即使有12GB的堆，内存也很快耗尽，由此导致每个几分钟出现几十秒的停顿。

程序部署上的主要问题显然是过大的堆内存进行回收时带来的长时间停顿。
调查，之前用的32位操作系统，hotSpot用1.5GB堆内存，当时用户确实感觉到使用湾站比较慢，但还不至于发生长达几十秒的明显停顿，后来升级到64位操作系统、16GB内存希望
提升效能，却反而出现了停顿问题，尝试将java堆缩小到1.5GB，的确可以避免长时间停顿，但硬件浪费。

每一款java虚拟机的每一款垃圾收集器都有自己的应用目标与最合适的应用场景。
对于用户交互性强、对停顿时间敏感、内存又较大的系统，并不是一定要使用Shenandoah、ZGC这些明确以控制延迟为目标的垃圾收集器才能解决问题(不否认，若情况允许的话，这是
最值得考虑的方案)，使用Parallel Scavenge/Old收集器，并且给java虚拟机分配较大的堆内存也是有很多运行得很成功的案例，但前提是必须把应用的Full GC频率控制得足够
低，至少要低到不会再用户使用过程中发生，譬如几十个小时乃至一整天都不出现一次Full GC，这样可以通过在深夜执行定时任务的方式触发Full GC甚至自动重启应用服务器来保持
内存可用空间在一个稳定的水平。
控制Full GC频率的关键是老年代的相对稳定，主要取决于应用中绝大多数对象能否符合“招生熄灭”原则，即大多数对象的生存时间不应当太长，尤其不能有成批量的、长生成时间的
大对象产生，这样才能保障老年代空间的稳定。
B/S应用中，多数对象的生存周期都应该是请求级或页面级，会话级和全局级的长生命对象相对较少。只要代码合理，实现在超大堆中正常使用没有Full GC应当不困难，这样的话，
使用超大堆内存时，应用响应速度才可能会有所保证。
若计划用单虚拟机实例管理大内存，还要考虑问题：
+ 回收大堆导致的长时间停顿，自从G1的出现，增量回收得比较好的应用，这个问题有所缓解，但要到ZGC和Shenandoah成熟之后猜得到相对彻底解决
+ 大内存必须有64位java虚拟机支持，但由于压缩指针、处理器缓存行容量(Cache Line)等因素，64位虚拟机的性能测试结果普遍低于相同版本的32位虚拟机
+ 必须保证应用程序足够稳定，因为这种大型单体应用要是发生堆内存溢出，几乎无法产生堆转出快照(要产生几十GB乃至更大的快照文件)，即使生成也不好分析；若确实出了问题要
  诊断，可能必须应用JMC这种能在生产环境中进行的运维工具
+ 相同的程序在64位虚拟机中消耗的内存一般比32位虚拟机要打，这是由于指针膨胀，以及数据类型对其补白等因素导致的，可以开启(默认即开启)压缩指针功能来缓解

鉴于上述问题，会有一些人选择另一种部署方式：同时使用若干个虚拟机建立逻辑集群来利用硬件资源。一台物理机器上启动多个应用服务进程，为每个服务器进程分配不同端口，然后
在前段搭建一个负载均衡器，以反向代理的方式分配访问请求。
考虑到在一台物理机上建立逻辑集群的目的仅仅是尽可能利用硬件资源，并不是要按职责、按领域做应用拆分，也不需要考虑状态保留、热转移之类的高可用性需求，不需要保证每个
虚拟机进程有绝对准确的均衡负载，因此使用无Session复制的亲合式集群。仅仅要保障集群具备亲和性，及均衡器按一定规则(如Session ID分配)将一个固定的用户请求永远分配
到一个固定的集群节点进行处理即可。

缺点：
+ 节点竞争全局的资源，典型的就是磁盘竞争，各节点若同时访问某个此案文件(尤其是并发写操作容易出问题)，很容易导致I/O异常
+ 很难高效率地利用某些资源池，譬如连接池，一般都是各节点建立自己独立的连接池，这样有可能导致一些节点的连接池已经满，而另外一些节点仍有较多空余。尽管可以使用集中式
  的JNDI来解决，不过有一定复杂性并且可能带来额外的性能代价
+ 若用32位虚拟机，各个节点仍不可避免受到32位的内存限制，win只能用2GB内存，考虑到堆外内存开销，堆最多只能开到1.5GB。linux最高4GB限制
+ 大量使用本地缓存(若大量用HashMap)的应用，在逻辑集群中会造成较大的内存浪费，因为每个逻辑节点都有一份缓存，这时可以考虑把本地缓存改为集中式缓存

案例的解决方案：
最后部署方案没有选择升级jdk，而是调整为建立5个32位jdk的逻辑集群，每个进程按2GB内存计算(堆固定1.5GB)，占用了10GB内存。另外建立一个Apache服务器作为前端均衡代理
作为访问门户。考虑到用户对响应速度比较关心，并且文档服务的主要压力集中在磁盘和内存，处理器资源敏感度较低，因此改为CMS收集器进行回收。
高正后，服务再没有出现长时间停顿，速度比起硬件升级前有较大提升。

### 集群间同步导致的内存溢出
一个基于B/S的MIS系统，硬件为：两台双路处理器、8GB内存的HP小型机，应用中间件是WebLogic9.2，每台机器启动了3个WebLogic实例，构成一个6节点的亲合式集群。
由于亲合式集群，节点间没有进行Session同步，但有一些需求需要实现部分数据在各节点间共享。最开始这些数据放在数据库，但由于读写频繁、竞争激烈，性能影响较大，后面使用
JBossCache构建了一个全局缓存。服务正常使用一段较长的时间，但最近不定期出现多次的内存溢出问题。

内存溢出异常不出现时，服务回收内存状况正常，每次回收都能恢复到一个稳定的可用空间。
开始怀疑是程序某些不常用的代码路径中存在内存泄露，但同事反映最近程序并未更新、升级，也没有进行特别操作。
只好带着-XX:+HeapDumpOnOutOfMemoryError，查看dump结果，里面大量org.jgroups.protocols.pbcast.NAKACK对象
JBossCache是基于自家的JGroups进行集群建的数据通信，JGroups使用协议栈的方式来实现收发数据包的各种所需特性自由组合，数据包接收和发送要经过每层协议栈的up和down方法，
其中NAKACK栈用于保障各个包的有效顺序以及重发。

由于信息有传输失败需要重发的可能性，在确认所有注册在GMS(Group Membership Service)的节点都收到正确的信息前，发送的信息必须在内存中保留。
而此时MIS的服务端中有一个负责安全校验的全局过滤器，每当接收到请求时，均会更新一次最后操作时间，并且将这个时间同步到所有节点中去，
使得一个用户在一段时间内不能再多台机器上重复登录。
在服务使用过程中，往往一个页面会产生数次乃至数十次的请求，因此这个过滤器导致集群各个节点之间网络交互非常频繁。当网络情况不能满足传输要求时，重发数据在内存中不断
堆积，很快产生了内存溢出。

此案例中，既有JBossCache缺陷，也有MIS系统实现上缺陷。JBossCache讨论很多次类似内存溢出异常问题。更重要的缺陷是，这一类被集群共享的数据要使用类似JBossCache这种
非集中式的集群缓存来同步的话，可以允许读操作频繁，因为数据在本地内存有一份副本，读取的动作不会耗费多少资源，但不应当有过于频繁的写操作，会带来很大的网络同步的开销。
--分布式集群数据同步量太大！

### 堆外内存导致的溢出错误
小型项目，基于BS考试系统，为了实现客户端能实时地从服务端接收考试数据，系统使用了逆向AJAX技术(也称Comet或Server Side Push)，选用CometD1.1.1作为服务端推送框架，
服务器是Jetty7.14，硬件为普通PC，Corei5CPU，4GB内存，32位Win操作系统

测试期间发现服务端不定式抛出内存溢出异常，服务不一定每次都出现异常。网管尝试过把堆内存跳到最大，32位系统最多到1.6G，也没效果，抛出内存溢出异常更加频繁。
加入-XX:+HeapDumpOnOutOfMemoryError，居然也没有任何反应，抛出内存溢出异常时什么文件都没有产生。
无奈，只好挂着jstat紧盯屏幕，发现垃圾收集并不频繁，Eden区、Survivor区、老年代以及方法区的内存全部很稳定，压力不大，但是照样不停抛出内存溢出异常。
最后，在内存移除后从系统日志中找到异常堆栈：
```
[org.eclipse.jetty.util.log] handle failed java.lang.OutOfMemoryError: null at sun.misc.Unsafe.allocateMemory(Native Method)
at java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:99)
at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:288)
at org.eclipse.jetty.io.nio.DirectNIOBuffer.<init> ......
```
操作系统对每个进程能管理的内存是有限制的，32位win限制是2GB，1.6G给了java堆，而Direct Memory耗用的内存并不算入这1.6G的堆之内，因此他最大也只能在剩余0.4G空间中
再分出一部分而已。
在应用中导致溢出的关键是垃圾收集进行时，虚拟机虽然会对直接内存进行回收，但直接内存并不像新生代、老年代那样，发现空间不足就主动通知收集器进行垃圾回收，它只能等待
老年代满后Full GC出现后，顺便帮他清理掉内存的废弃对象。否则就不得不一直等到抛出内存溢出异常时，先捕获到异常，再在Catch中通过System.gc触发垃圾收集。
但如果虚拟机打开了-XX:+DisableExplicitGC开关，禁止了人工出发垃圾收集的话，那只能眼睁睁看堆中还有许多空闲内存，自己却不得不抛出内存溢出异常了。
本案例中使用的ComnetD1.1.1框架，大量使用NIO操作需要使用到直接内存

在处理小内存或32位的应用问题时，除了java堆和方法区外，还要注意到下面区域还会占用较多内存，这里所有的内存总和受到操作系统进程最大内存的限制：
+ 直接内存：可通过-XX:MaxDirectMemorySize调整，内存不足时抛出OutOfMemoryError或OutOfMemoryError:Direct buffer memory
+ 线程堆栈：可通过-Xss调整，内存不足时抛出StackOverflowError(若线程请求的栈深度大于虚拟机允许的深度)或OutOfMemoryError(若虚拟机栈容量可以动态扩展，当栈扩展
  时无法申请到足够的内存)
+ Socket缓存区：每个Socket连接都Receive和Sent两个缓存区，分别占大约37KB和25KB内存，连接多的话这块内存占用也可观。若无法分配，可能抛出IOException:Too many
  open files异常
+ JNI代码：若代码中使用了JNI调用本地库，那本地库使用的内存也不在堆中，而是占用虚拟机的本地方法栈和本地内存的
+ 虚拟机和垃圾收集器：虚拟机、垃圾收集器的工作也要消耗一定数量的内存

### 外部命令导致系统缓慢
一个数字校园应用系统，四路处理器的Solaris 10操作系统，中间件WieGlassFish服务器。
系统在大并发压测时，发现请求响应时间比较慢，通过操作系统的mpstat工具发现处理器使用率高，但是系统中占用绝大多数处理器资源的程序并不是该应用本身。
这个不正常的现象，通常情况下用户应用的处理器占用率应该占主要地位，才能说明系统是在正常工作
通过Solaris10的dtrace脚本可以查看当前情况下哪些系统调用花费了最多的处理器资源，发现最消耗处理器资源的是“fork”系统调用。
fork系统调用是linux用来产生新进程的，在java虚拟机中，用户编写的java代码通常最多只会创建新线程，不应该有进程的产生，这又是不正常的现象
通过联系人员，找到答案：每个用户请求的吹了都需要执行一个外部Sheel脚本来获得系统的一些信息。执行这个Shell脚本是通过Java的Runtime.getRuntime().exec方法来调用的。
这种调用方式可以达到执行Shell脚本的目的，但在虚拟机中非常消耗资源，即使外部命令本身很快执行，频繁调用时创建进程的开销也非常可观。
这个命令执行时，先复制一个和当前虚拟机用于一样环境变量的进程，再用这个新的进程去执行外部命令，最后再推出这个进程。
若频繁执行这个操作，系统的消耗必然很大，而且不仅是处理器消耗，内存负担也很重要。

用户根据建议去掉这个Shell脚本的执行的语句，改为使用java的API去获取这些信息后，系统恢复正常

### 服务器虚拟机进程崩溃
一个基于B/S的MIS系统，硬件为两台双路处理器、8G内存的HP系统，服务器是WebLogic9.2。正常运行一段时间后，发现在运行期间频繁出现集群节点的虚拟机进程自动关闭现象，留下
一个hs_err_pid###.log文件后，虚拟机进程小时，两台物理机里的每个节点都出现过进程崩溃现象。
从系统日志注意到，每个节点的虚拟机进程在崩溃前，都发生过大量相同的异常：
```

java.net.SocketException: Connection reset
at java.net.SocketInputStream.read(SocketInputStream.java:168)
at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
at java.io.BufferedInputStream.read(BufferedInputStream.java:235)
at org.apache.axis.transport.http.HTTPSender.readHeadersFromSocket(HTTPSender.java:583) at org.apache.axis.transport.http.HTTPSender.invoke(HTTPSender.java:143)
... 99 more
```
这时一个远端断开连接的异常，通过网管了解到系统最近与一个OA门户做了集成，在MIS系统工作流的待办事项变化时，要通过Web服务通知OA门户系统，把待办事项的变化同步到OA门户中
通过SoapUI测试了一下OA的同步待办事项的几个web服务，发现调用后竟然需要长达3分钟才能返回，并且返回结果都是超市导致的连接中断。
由于MIS系统的用户多，待办事项变化快，为了不被OA系统速度拖累，使用了异步的方式调用Web服务，但由于两百年服务速度完全不对等，时间越长就累积了越多Web服务没有调用完成，
导致在等待的吸纳城和Socket连接越来越多，最终超过虚拟机的承受能力后导致虚拟机进程崩溃。
通过OA门户方修复无法使用的集成接口，并将一部改为生产者/消费者模式的消息队列实现后，系统恢复正常。
--还还得了解业务，知道这时在干什么导致大量的错误日志

### 不恰当数据结构导致内存占用过大
一个后台RPC服务器，64位虚拟机，内存配置-Xms4g-Xmx8g-Xmn1g，使用ParNew加CMS收集器。
平时对外服务的Minor GC月在30ms以内，完全可以接受。但业务上需要每10分钟加载一个月80MB的数据文件到内存进行数据分析，这些数据会在内存中形成超过100万个
HashMap<Long,Long>的entry，这段时间里Minor GC会造成超过500ms的停顿，对于这种长度的停顿时间接受不了。

观察gc相关日志，平时Minor GC时间很短，原因是新生代的绝大部分对象都是可清除的，在Minor GC后Eden和Survivor基本上处于完全空闲。
但在分析数据文件期间，800M的Eden空间很快填满引发垃圾收集，但Minor GC后，新生代中绝大部分依然存活。
而ParNew收集器使用的是复制算法，这个算法的高效是建立在大部分对象都朝生熄灭的特性上的，若存活对象过多，把这些对象复制到Survivor并维护这些对象引用的正确性就是负担，
因此导致垃圾收集的停顿时间很长
若不修改程序，仅从GC调优角度解决此问题，考虑将Survivor空间去掉(加入-XX:SurvivorRatio=65536、-XX:MaxTenuringThreshold=0或-XX:+AlwaysTenure)，让
新生代中存活的对象在第一次Minor GC后立即进入老年代，等到MajorGC时再去清理他们。这种措施可以治标，但副作用大；治本的方案必须要修改程序，因为这里产生问题的根因
是用HashMap<Long,Long>结构来存储数据文件空间效率太低。

具体分析一下HashMap的空间效率，只有key和value所存放的两个长整型数据是有效的，共16字节(2*8字节)。这俩长整形数据包装成java.lang.Long对象之后，分别具有8字节
的Mark Work、8字节的KClass指针，再加上8字节存储数据的long值。然后这2Long对象组成Map.Entry后，又多了16字节的对象头，然后一个8字节的next字段和4字节的int型
的hash字段，为了对其，还必须添加4字节的对象头，最后还有HashMap中对这个Entry的8字节的引用，这样增加两个长整形数字，
实际消耗的内存为(Long(24byte)*2)+Entry(32byte)+HashMapRef(8byte=88byte)，空间效率为有效数据处理全部内存空间，即16字节/88字节=18%，很低
-- 应该是依据场景进行优化，使用更低的容器存放，太多包装反而会带来很多问题，又或者使用部分加载?

### 由Win虚拟内存导致的长时间停顿
一个带心跳检测功能的GUI桌面程序，每15s会发送一次心跳检测信号，若对方30s内没有信号返回，那认为对方程序的连接已经断开。
程序上线后发现新桃检测有误报的可能，查询日志发现误报原因是程序会偶尔出现间隔约1分钟的时间完全无日志输出，处于停顿状态。

因为桌面程序，所需内存并不大(-Xmx256m)，一开始没有想到垃圾收集导致程序停顿，但假如-XX:+PrintGCApplicationStoppedTime、-XX:+PrintGCDateStamps、-XLoggc:gclog.log
后，从收集器日志文件中确认了停顿确实是由于垃圾收集导致，大部分收集时间都控制在100ms以内，但偶尔会出现一次接近1min的长时间收集过程。

从收集器日志找到长时间停顿的具体日志信息(再添加-XX:+PrintReferenceGC)，找到日志片段如下。从日志中看，真正执行垃圾收集动作的时间并不长，但从准备开始收集，到真正
开始收集之间所消耗的时间却占了绝大部分
2012-08-29T19:14:30.968+0800: 10069.800: [GC10099.225: [SoftReference, 0 refs, 0.0000109 secs]10099.226: [WeakR

除收集器日志外，还观察到这个GUI程序内存变化的一个特点，当它最小化时，资源管理中显示占用内存大幅减小，但虚拟内存则没有变化，因此怀疑程序在最小化时他的工作内存被
自动交换到磁盘的页面文件中了，这样发生垃圾收集时就可能因为回复页面文件的操作导致不正常的垃圾收集停顿。

在MSDN查证，确认了猜想，在java的GUI程序中要避免这种现象，加入-Dsun.awt.keepWorkingSetOnMinimize=true解决。保证程序在恢复最小化时能立即响应。
http://support.microsoft.com/default.aspx?scid=kb;en-us;293215

### 由安全点导致长时间停顿
一个比较大的承担公共计算任务的离线HBase集群，jdk8，G1收集器。每天都有大量的MapReduce或Spark离线分析任务对其进行访问，同时由很多其他在线集群Replication过来的
数据写入，因为集群读写压力较大，而离线分析任务对延迟又不会特别敏感，所以将-XX:MaxGCPauseMillis设置500ms。
不过运行时间后发现垃圾收集的停顿经常达到3s以上，且实际垃圾收集进行回收的动作只占其中的几百毫秒。
[Times: user=1.51 sys=0.67, real=0.14 secs]
2019-06-25T 12:12:43.376+0800: 3448319.277: Total time for which application threads were stopped: 2.2645818 se

解释下user、sys、real概念：
+ user：进程执行用户态代码所耗费的处理器时间
+ sys：进程执行和心态代码所耗费的处理器时间
+ real：执行动作从开始到结束耗费的时钟时间。
  注意，前俩是处理器时间，而最后一个是时钟时间，区别是处理器时间代表的是线程占用处理器一个核心的耗时计算，而时钟时间时现实世界中的时间计数。
  若单核场景，这俩可以认为等价，若多核，同一个时钟时间内有多个处理器核心正在工作，就会有多少倍的处理器时间被消耗和记录下来。
  垃圾收集调优时，主要依据real时间为目标来优化程序，因为最终用户只关心发出请求到得到相应所花费时间，即响应速度，而不太关心程序到底用了多少个线程或处理器完成任务。

日志显示这次垃圾收集一共花了0.14s，但其中用户线程却停顿了2.26s，两者差距远超出了正常的TTSP(Time To Safepoint)耗时的范围。所以加入-XX:+PrintSafepointStatistics
和-XX:PrintSafepointStatisticsCount=1看安全点日志：
```
vmop [threads: total initially_running wait_to_block] 
65968.203: ForceAsyncSafepoint [931 1 2]
[time: spin block sync cleanup vmop] page_trap_count 
[2255 0 2255 11 0] 1
```
日志显示当前虚拟机的操作(VM Operation，VMOP)是等待所有用户进入到安全点，但是有俩线程特别慢，导致发生了很长时间的自旋等待。
日志中的2255毫秒自旋(Spin)时间指由于部分线程已经走到了安全点，但还有一些特别慢的线程没有到，所以垃圾收集线程无法开始工作，只能空转(自旋)等待。

第一步先找出这俩线程，-XX:SafepointTimeout和-XX:SafepointTimeoutDelay=2000，让虚拟机等到线程进入安全点的事件超过2000毫秒就认定为超时，这样会输出导致问题的
线程名称：
```
# SafepointSynchronize::begin: Timeout detected:
# SafepointSynchronize::begin: Timed out while spinning to reach a safepoint.
# SafepointSynchronize::begin: Threads which did not reach the safepoint:
# "RpcServer.listener,port=24600" #32 daemon prio=5 os_prio=0 tid=0x00007f4c14b22840
nid=0xa621 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE
# SafepointSynchronize::begin: (End of list)
```
从日志看到，导致问题的线程名为RpcServer.listener,port=24600。但为什么它会出问题，什么因素可以阻止线程进入安全点？
之前说到，安全点是以“是否具有让程序长时间执行的特征”为原则进行选定，所以方法调用、循环跳转、异常跳转这些位置都可能会设有安全点，但hotSpot虚拟机为了避免安全点过多
带来过重的负担，对循环还有一项优化措施，认为循环次数较少的话，执行时间应该也不会太长，所以使用int类型或范围更小的数据类型作为索引值的循环时不会被放置安全点的。
这种循环别称为可数循环(Counted Loop)，对应地，使用long或范围更大的数据类型作为索引值的循环就被成为不可数循环(Uncounted Loop)，将会被放置安全点。
通常这个优化措施可行，但循环执行的时间不单单由其次数决定，若循环体单词执行特别慢，那即使是可数循环也可能会耗费很多时间。
hotSpot也提供了-XX:+UseCountedLoopSafepoints去强制在可数循环中也放置安全点，不过jdk8下有bug，有导致虚拟机崩溃的风险，所以就不得不找到RpcServer线程里
缓慢代码来进行修改。
最终查明导致这个问题是HBase中一个连接超时清理的函数，由于集群会有多个MapReduce或Spark任务进行访问，而每个任务又会同时起多个Mapper/Reducer/Executer，其中
每个都会作为一个HBase的客户端，这就导致了同时连接的数量非常多。更为关键的是，清理连接的索引就是int类型，所以这是一个可数循环，hotSpot不会再循环中插入安全点。
当垃圾收集发生时，若RpcServer的Listener线程刚好执行到该函数里的可数循环时，则必须等待线程全部跑完才能进入安全点，此时其他线程也必须一起等待，所以从现象上看就是
长时间的停顿。
解决方案，把循环索引的数据类型从int改为long。

### Eclipse运行速度调优
Eclipse由于插件、代码大，从启动到所有项目编译完成需要4~5分钟。
机器是32位win7系统，虚拟机为hotSpot1.5b64，硬件为ThinkPadX201，Inteli5CPU，4GB内存。
初始配置文件eclipse.ini中，除了jdk路径、设置最大堆512MB以及开启JMX管来(需要在VisualVM中收集原始数据)外，未做任何改动，
```初始配置
-vm
D:/_DevSpace/jdk1.5.0/bin/javaw.exe
-startup plugins/org.eclipse.equinox.launcher_1.0.201.R35x_v20090715.jar --launcher.library plugins/org.eclipse.equinox.launcher.win32.win32.x86_1.0.200.v20090519 -product
org.eclipse.epp.package.jee.product
--launcher.XXMaxPermSize
256M
-showsplash
org.eclipse.platform
-vmargs
-Dosgi.requiredJavaVersion=1.5
-Xmx512m
-Dcom.sun.management.jmxremote
```
为了与调优后的结果进行量化对比，调优开始前做了一次初始数据测试。
测试用例，就是收集从Eclipse启动开始，直到所有插件加载完成为止的总耗时以及运行状态数据，虚拟机的运行数据通过VisualVM以及插件VisualGC进行采集。
测试过程中反复启动数次Eclipse直到测试结果稳定，取最后一次运行的结果作为数据样本(为避免操作系统未能及时进行磁盘缓存而产生的影响)。
样本截图，每个代，多少次gc等
写个插件统计eclipse启动总耗时

总结原始配置下的测试结果：
+ 整个启动过程平均耗时约15s
+ 最后一次启动的数据样本中，垃圾收集总耗时4.149s，其中
    + Full GC被触发19次，供x
    + Minor GC被处罚378次，供耗时0.983s
        + 加载类9115个，耗时4.114s
        + 即时编译时间1.999s
        + 交给虚拟机的512MB堆内存被分配为40MB的新生代(31.5M的Eden和2个4MB的Survivor)以及472M的老年代
          客观说，考虑到硬件条件，15s还可以接受，但从VisualGC中反映的数据看，存在问题是费用户程序时间(Compile Time、Class Load Time、GCTime)占比非常高，占了
          这个启动过程耗时的一半以上(少许夸张，因为如即时编译等动作是在后台线程完成的，用户程序在此期间也正常并发执行，最多就是速度变慢，所以并没有占用一半以上绝对时间)
          虚拟机后台占用太多时间也直接导致Eclipse在启动过程后的使用过程中经常有卡顿的感觉，进行调优还是有较大价值的。

#### 升级JDK版本的性能变化及兼容问题
调优第一步，对虚拟机的版本进行升级，希望先从虚拟机版本呢身上得到一些免费的性能提升
技术进步确实会促使性能改进。

升级jdk6后，使用接分钟，出现内存溢出
出乎意料，决定对eclipse做调优时因为速度慢，之前一直很稳定，没有出现过内存溢出，而这次升级除了修改虚拟机路径外，还未做任何运行参数的调整。
打开VisualVM，监视。
在java堆中监视曲线里，“堆大小”的曲线与“使用堆”的曲线一直都很大的间隔距离，每当两条曲线开始出现相互靠近趋势时，“堆大小”的曲线快速向上转向，而“使用堆”的曲线会
向下转向。“堆大小”的曲线向上代表虚拟机内部在进行堆扩容，因为参数并没有指定最小堆(-Xms)的值与最大堆(-Xmx)相等，所以堆容量一开始并没有扩展到最大，而是根据使用
情况进行伸缩扩展。“使用堆”的曲线向下是因为虚拟机内部触发了一次垃圾收集，一些废弃对象的空间被回收后，内存用量相应减少。
从图形上看，java堆运作是正常的。

但永久代的监视曲线明显问题，“PermGen大小”的曲线与“使用的PermGen”曲线几乎完全在一起，说明永久代已经没有可回收的资源了，所以“使用的PermGen”曲线不会向下发展，
并且永久代中也没有空间可以扩展了，所以“PermGen大小”的曲线不能向上发展，说明这次内存溢出很明显是永久代导致的内存溢出
再看图，永久代最大容量67108864字节，即64MB，恰好是JDK在未使用-XX:MaxPermSize参数明确指定时默认值。
对于Eclipse这种规模的java程序，64M的永久代内存空间显然不够，内存溢出是肯定的，但为何jdk5中没有发生溢出？
在VisualVM的“概述->JVM参数"页签中，分别检查jdk5和jdk6运行eclipse时虚拟机启动参数，发现jdk6，只有3个启动参数
-Dcom.sun.management.jmxremote -Dosgi.requiredJavaVersion=1.5 -Xmx512m
而jdk5，有4个参数
-Dcom.sun.management.jmxremote -Dosgi.requiredJavaVersion=1.5 -Xmx512m -XX:MaxPermSize=256M，多出了MaxPermSize

#### 编译时间和类加载时间的优化
从启动时间来看，升级jdk6基本上没有提升，多次测试的平均值与jdk5的差距完全在实验误差范围内
查看运行细节，有个有意思的事情：jdk6中启动完eclipse所消耗的类加载时间比jdk5长了接近1倍！ jstat -class pid
不过这个问题，并不能作为一个普适性的测试结论，只在一部分机器存在。

考虑到实际情况，eclipse使用者甚多，他的编译代码我们可以认为是安全可靠的，不需要再加载时再进行字节码验证，-Xverify:non禁止掉字节码验证过程。
加载类速度提升。

编译时间(Compile Time)占用很多，是什么？程序在运行前不是已经编译了吗？
编译时间：指虚拟机的即使编译器(Just In Time Compiler)编译热点代码(Hot Spot Code)的耗时。

java为了实现跨平台的特性，java代码编译出来后形成Class文件中存储的是字节码(Byte Code)，虚拟机通过解释方式执行字节码执行，比起C/C++编译成本地二进制
代码来说，速度慢不少。为了解决程序解释执行的速度问题，jdk1.2后，hotSpot虚拟机内置了两个即使编译器，若一段java代码被调用次数达到一定程度，就会判定为
热点代码交给即使编译器即时编译为本地代码，提高运行速度(这就是HotSpot虚拟机名字由来)。而且完全有可能在运行期动态编译比C/C++的编译期静态编译出来的结果
更加优秀，因为运行期的编译器可以收集很多静态编译器无法得知的信息，也可以采用一些激进的优化手段，针对“大多数情况”而忽略“极端情况”进行假设优化，当优化条件
不成立时再逆优化退回到解释状态或重新编译执行。
所以java程序只要代码编写没问题(如各种泄露问题，内存泄露、连接泄露)，随着运行时间增长，代码被编译得越来越彻底，运行速度应当是月运行越快。
不过java的运行期编译的一大缺点是：它进行编译需要消耗机器的计算资源，影响程序正常的运行时间，这也就是上面的编译时间

HotSpot虚拟机有两个即使编译器：当运行在客户端模式时，使用的是一个C1轻量级编译器，还有一个C2相对重量级的服务端编译器提供更多的优化措施。

#### 调整内存设置控制垃圾收集频率
GC时间，是一个稳定持续的消耗。
我们做的测试是在测试程序的启动时间，类加载和编译时间的影响力在这项测试里被大幅放大了。绝大多数应用中，都不可能持续不断地类被加载和卸载。
程序运行一段时间后，随着热点方法被不断编译，新的热点方法数量也会下降，这都会让类加载和即使编译的影响随运行时间增长而下降，但垃圾收集则随着程序运行而持续
运作，所以他对性能的影响才显得更为重要

在eclipse启动的原始数据样本中，15s内供发生了19次Full GC和378次Minor GC，一共397次GC共造成了超过4s的停顿，及超过1/4的时间在做垃圾收集，太糟糕

先解决新生代的Minor GC，尽管垃圾收集的总时间不到1s，但发生了378次，从VisualGC的线程监视中看到eclipse启动期间一共发起了超过70条线程，同时在运行的线程
数超过25条，每当发生一次垃圾收集，所有用户线程，都必须跑到最近的一个安全点然后挂起线程来等待垃圾回收。这样过于频繁的垃圾收集会导致很多没必要的线程挂起及恢复动作。
新生代垃圾收集频繁发生，很明显由于虚拟机分配给新生代的空间太小导致，Eden区加上一个Survivor区的总大小还不到35MB，有必要-Xmn调整

再看Full GC，19次总耗时3.166s，占了绝大部分的垃圾收集时间，降低垃圾收集停顿时间的主要目标就是降低Full GC时间。
从VisualGC曲线图上看不够精确，这次直接从收集器日志中分析Full GC如何产生。
```Full GC记录
0.278: [GC 0.278: [DefNew: 574K->33K(576K), 0.0012562 secs]0.279: [Tenured: 1467K->997K(1536K), 0.0181775 secs] 
0.312: [GC 0.312: [DefNew: 575K->64K(576K), 0.0004974 secs]0.312: [Tenured: 1544K->1608K(1664K), 0.0191592 secs 
0.590: [GC 0.590: [DefNew: 576K->64K(576K), 0.0006360 secs]0.590: [Tenured: 2675K->2219K(2684K), 0.0256020 secs 
0.958: [GC 0.958: [DefNew: 551K->64K(576K), 0.0011433 secs]0.959: [Tenured: 3979K->3470K(4084K), 0.0419335 secs 
1.575: [Full GC 1.575: [Tenured: 4800K->5046K(5784K), 0.0543136 secs] 5189K->5046K(6360K), [Perm : 12287K->1228 
1.703: [GC 1.703: [DefNew: 703K->63K(704K), 0.0012609 secs]1.705: [Tenured: 8441K->8505K(8540K), 0.0607638 secs 
1.837: [GC 1.837: [DefNew: 1151K->64K(1152K), 0.0020698 secs]1.839: [Tenured: 14616K->14680K(14688K), 0.0708748 
2.144: [GC 2.144: [DefNew: 1856K->191K(1856K), 0.0026810 secs]2.147: [Tenured: 25092K->24656K(25108K), 0.111242 
2.337: [GC 2.337: [DefNew: 1914K->0K(3136K), 0.0009697 secs]2.338: [Tenured: 41779K->27347K(42056K), 0.0954341 
2.465: [GC 2.465: [DefNew: 2490K->0K(3456K), 0.0011044 secs]2.466: [Tenured: 46379K->27635K(46828K), 0.0956937
```
这10次Full GC发生的原因全部都是老年代空间耗尽，没发生一次Full GC都伴随一次老年代空间扩容：1536K->1664K->2684K..42056K->46828K
eclipse启动完成时，老年代容量扩大到103428KB，代码编译开始后，老年代容量达到473M，整个java堆到达最大容量512M

日志还显示有时内粗你回收状况很不理想，空间扩容称为获取可用内存的最主要手段：
Tenured: 25092K->24656K(25108K) , 0.1112429 secs
老年代当前容量为25108K，内存使用到24656K时发生Full GC，花费0.11s把内存降低到了24656K，回收了不到500K内存，这次垃圾收集基本没什么回收效果，仅仅做了
扩容，扩容过程相比回收过程可以看做是基本不需要花费时间的，所以说着0.11s几乎是白浪费

以上分析得出结论：eclipse启动时Full GC大多数是由于老年代容量扩展而导致，由永久代空间扩展而导致的也有一部分。
为避免这些扩展所带来的性能浪费，可以把-Xms和-XX:PermSize参数设置为-Xmx和-XX:MaxPermSize一样，这样就强制虚拟机在启动时把老年代和永久代的容量固定，避免
运行时自动扩展。

依据以上分析，优化计划确定为：把新生代容量提升x，避免频繁Minor GC，把java堆、永久代固定y、z，避免内存扩展。这几个值时根据硬件和eclipse插件、工程数量决定，
可以依据VisualGC和日志中收集到的实际数据进行设置。
```调整后参数

-vm
D:/_DevSpace/jdk1.6.0_21/bin/javaw.exe
-startup plugins/org.eclipse.equinox.launcher_1.0.201.R35x_v20090715.jar --launcher.library plugins/org.eclipse.equinox.launcher.win32.win32.x86_1.0.200.v20090519 -product
org.eclipse.epp.package.jee.product
-showsplash
org.eclipse.platform
-vmargs
-Dosgi.requiredJavaVersion=1.5
-Xverify:none
-Xmx512m
-Xms512m
-Xmn128m
-XX:PermSize=96m
-XX:MaxPermSize=96m
```
配置后，eclipse启动后一分钟建施图，只发生了8次Minor GC和4次Full GC，总耗时1.928s

小瑕疵：从Old Gen曲线看，老年代直接固定在384M，而内存使用量只有66M，一直很平滑，完全不应该发生Full GC才对，那4次Full GC是如何来的？
用jstat -gccause查看最近一次GC原因
```
S0 S1 E O P YGC YGCT FGC FGCT GCT LGCC GCC
0.00 0.00 1.00 14.81 39.29 6 0.422 20 5.992 6.414 System.gc() No GC
```
从LGCC(Last GC Cause)中看到原来是System.gc，在内存设置调整后，这种显示垃圾收集不符合我们的期望，因此加入-XX:+DisableExplicitGC。
再次测试发现启动期间的Full GC没有了。

#### 选择收集器降低延迟
在eclipse中进行有用且耗时的操作：代码编译。
从图看到，新生代每次回收耗时65ms，老年代每次回收耗时725毫秒。对于用户，65毫秒基本无法察觉，而老年代接近1秒，虽然较长时间出现一次，但这样的停顿已经可以感知了。
再注意下编译期间的处理器资源使用，整个编译过程平局你只用了不到30%的处理器资源，垃圾收集的处理器使用率曲线更几乎与坐标横轴紧贴在一起(很少)，这说明处理器资源还有
很多可利用的余地。

列举垃圾收集的停顿时间、处理器资源富裕的目的，是为了给接下来替换掉客户端模式的虚拟机中默认的新生代、老年代串行收集器做个铺垫。
由于代码多，逼着在全量编译或清理动作时使用Run in Background功能，一边编译一边工作。此种场景，符合CMS。添加-XX:+UseConcMarkSweepGC和-XX:+UseParNewGC。
再测试，新生代停顿从每词65ms下降到每次53ms，而老年代停顿时间从725到36ms
当然由于CMS的停顿时间只是整个收集过程一小部分，大部分收集行为与用户程序并发进行，所以并不是真的把垃圾收集时间直降。在收集日志中可以看到CMS与程序并发的时间约
为400毫秒，这样比较满意。


# 类文件结构
我们希望有不同硬件体系结构、各种不同的操作系统。
与平台无关的理想最终只有实现在操作系统以上的应用层，虚拟机可以载入和执行一种平台无关的字节码，从而实现程序的“一次编写，到处运行”
各种不同平台的虚拟机，以及所有平台都同意支持的程序存储格式——字节码(Byte Code)是构成平台无关性的基石。
虚拟机的另一种中立特性——语言无关性。

实现语言无关性的基础仍然是虚拟机和字节码存储格式。
虚拟机只与Class文件这种特定的热进制文件格式所关联，Class文件中包含了java虚拟机指令集、符号表以及若干其他辅助信息。

java语言中的各种语法、关键字、常量变量和运算符号的语义最终都由多条字节码指令组合来表达，这决定了字节码指令所能提供的语言描述能力必须必java语言本身更强大才行。

## Class文件的结构
这部分是java虚拟机的重要基础之一，是了解虚拟机的必经之路，若想比较深入地学习虚拟机相关知识，这部分是无法回避的

java技术能一致保持非常聊好的向后兼容性，Class文件结构的稳定功不可没，任何一门程序语言能获得商业上的成功，都不可能去做升级版本后，旧版本变异的产品就不再能够运行
这种事情。

任何一个Class文件都对应着唯一的一个类或接口的定义信息，但反过来，类或接口并不一定都定义在文件里(譬如类或接口也可以动态生成，直接送入类加载器中)。

Class文件时一组以8个字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑地排列在文件中，中间没有添加任何分隔符，这使得这个Class文件中存储的内容几乎全部是程序
运行的必要数据，没有空隙存在。当遇到需要占用8个字节以上空间的数据项时，则会按照高位在前的方式分割成若干个8字节进行存储。
Big-Endian：顺序是，按高位字节在地址最低位，最低字节在地址最高位来存储数据

Class文件格式采用一种类似C结构体的伪结构来存储数据，只有两种数据类型：无符号数和表。
+ 无符号数属于基本的数据类型，以u1、u2、u4、u8来代表1个字节、2个字节、4个字节、8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或按照UTF8编码
  构成字符串值
+ 表示由多个无符号数或其他表作为数据项构成的复合数据类型，便于命名，表以_info结尾。表用于描述有层次关系的复合结构的数据，整个Class文件本质上也可以视作一张表，
  这张表由下面数据项按照严格顺序排列构成。
  Class文件格式——示意图
  类型  名称  数量
  u4  magic  1
  u2  minor_version  1
  u2  major_version  1
  u2  constant_pool_count  1
  cp_info  constant_pool  constant_pool_count-1
  u2  access_flags  1
  u2  this_class  1
  u2  super_class  1
  u2  interface_count  1
  u2  interfaces  interfaces_count
  u2  fields_count  1
  field_info  fields  fields_count
  u2  methods_count  1
  method_info  methods  methods_count
  u2  attributes_count  1
  attribute_info  attributes  attributes_count

无论是无符号数还是表，当需要描述同类型但数量不定的多个数据时，经常会用一个前置的容量计数器加若干个连续的数据项形式，这时这一系列连续的某一类型的数据为某一类型
的“集合”
强调：Class的结构没有任何分隔符号，所以上表的数据项，无论是顺序还是数量，甚至于数据存储的字节序(Byte Ordering，Class中为Big-Endian)这样的细节，都别严格
限定，哪个字节代表什么含义，长度多少，先后顺序如何，全都不允许改变。

## 魔数与Class文件的版本
每个Class文件的头4个字节为模数(Magic Number)，作用是确定这个文件是否为一个能被虚拟机接受的Class文件。
使用魔数而不是扩展名来识别主要是基于安全考虑，因为文件扩展名可以随意改动。

紧接魔数的4字节存储的是Class文件的版本号：第5和6字节是此版本号(Minor Version)，第7和8是主版本号(Major Version)
jdk1.1后的每个jdk大版本发布主版本号+1，高版本的jdk能向下兼容以前版本的Class文件，但不能运行以后版本的Class文件，<java虚拟机规范>规定。

编译后
```
cafe babe 0000 0037
```
看到前4个字节的十六进制表示是0xcafebabe，次版本号为0x0000，主版本号为0x0037，jdk11，
次版本号，jdk1.2以后到12均未使用，都为0.

### 常量池
紧接着是常量池入口。
由于常量池中常量的数量不固定，所以在常量池的入口需要放入一项u2类型的数据，代表常量池容量计数值(constant_pool_count)。这个容量计数从1开始，
常量池容量(偏移地址：0x00000008)为十六进制数0x0016，即十进制的22，代表常量池中有21项常量，索引值范围1~21.
Class文件格式规范制定之时，设计者将第0项常量空出来有特殊考虑，目的是，若后面某些指向常量池的索引值的数据在特定情况下需要表达“不引用任何一个常量池项目”的含义，可以把
索引值设置为0来表示。
常量池中主要存放两大类常量：字面量(Literal)和符号引用(Symbolic References)。
字面量如文本字符串、被声明为finla的常量值等。
符号引用包括几类常量：
+ 被模块导出或开放的包(Package)
+ 类和接口全限定名(Full Qualified Name)
+ 字段的名称和描述符(Descriptor)
+ 方法的名称和描述符
+ 方法句柄和方法类型(Method Handle、Method Type、Invoke Dynamic)
+ 动态调用点和动态常量(Dynamically-Conputed Call Site、Dynamically-Computed Constant)
  java代码在进行javac编译时，不像C/C++那样有“连接”这一步骤，而是在虚拟机加载Class文件时进行动态连接。
  在Class文件中不会保存各个方法、字段最终在内存的布局信息，这些字段、方法的符号引用不经过虚拟机在运行期转换的话，是无法得到真正的内存入口地址，也就无法直接被虚拟机
  使用的。当虚拟机做类加载时，将会从常量池获得对应的符号引用，再在类创建时或运行时解析、翻译到具体的内存地址之中。

常量池中每一项常量都是一个表。
17类表都有一个共同特点，表结构的第一位是个u1类型的标志位(tag，取值见下表的标志列)，代表当前常量属于哪种常量类型。
常量池的项目类型——示意图：
类型  标志  描述
CONSTANT_Utf-8_info  1  UTF-8编码的字符串
CONSTANT_Integer_info  3  整型字面量
CONSTANT_Float_info  4  浮点型字面量
CONSTANT_Long_info  5  长整形字面量
CONSTANT_Double_info  6  双精度浮点型字面量
CONSTANT_Class_info  7  类或接口的符号引用
CONSTANT_String_info  8  字符串类型字面量
CONSTANT_Fieldref_info  9  字段的符号引用
CONSTANT_Methodref_info  10  类中方法的符号引用
CONSTANT_InterfaceMethodref_info  11  接口中方法的符号引用
CONSTANT_NameAndType_info  12  字段或方法的部分符号引用
CONSTANT_MethodHandle_info  15  表示方法句柄
CONSTANT_MethodType_info  16  表示方法类型
CONSTANT_Dynamic_info  17  表示动态计算常量
CONSTANT_InvokeDynamic_info  18  表示一个动态方法调用点
CONSTANT_Module_info  19  表示一个模块
CONSTANT_Package_info  20  表示一个模块中开放或导出的包

```
0  1  2  3  4  5  6  7  8  9  A  B  C  D  E  F
CA FE BA BE 00 00 00 32 00 16 07 00 02 01 00 1D
```

看上面Class文件的常量池的第一项常量，它的标志位(偏移地址：Ox0000000A)是0x07，查找标志列可知这个常量属于CONSTANT_Class_info类型，此类型的常量代表一个类或接口的
符号引用。
-- 标志位本身就能从上表查得，然后本身位置就是代表tag有u1位置，然后后面name_index就是下一个u2了

CONSTANT_Class_info型常量的结构：
类型  名称  数量
u1  tag  1
u2  name_index  1
tag是标志位，用于区分常量类型；name_index是常量池的索引值，它指向常量池中一个CONSTANT_Utf8_info类型常量，此常量代表了这个类(或接口)的全限定名，本例中name_index值
(偏移地址：Ox0000000B)为0x0002，指向了常量池中的第二项常量。从表中可以查得第二项常量，标志位(地址0x0000000D)是0x1，查表可知确实是一个CONSTANT_Utf8_info类型的常量。

CONSTANT_Utf8_info型常量的结构：
类型  名称  数量
u1  tag  1
u2  length  1
u1  bytes  length
length值说明了这个UTF-8编码的字符串长度是多少字节，后面紧跟着的长度为length字节的连续数据是一个使用UTF-8缩略编码表示的字符串。
UTF-8缩略编码与普通的UTF-8区别是：从'\u0001'到'\u007f'之间的字符(相当于1~127的ASCII码)的缩略编码使用一个字节标识，从'\u0008'到'\u07ff'之间的所有字符的缩略编码用
两个字节标识，从'\u0800'到'\ufff'之间的所有字符的缩略编码就按照普通的UTF-8编码规则使用三个字节表示。

本例中这个字符串的length值(偏移地址:0x0000000E)为0x001D，即29个字节长，往后29字节正好都在1~127的ASCII码范围以内，内容为"org/fenixsoft/clazz/TestClass"。
--这就是为了重用，定义不同常量，然后相互引用

jdk的bin下有专门分析Class文件字节码的工具：javap。
javap -verbose TestClass
计算机帮我们把整个常量池的21项常量都计算出来，并且第1、2项的结果也与上面计算一样。
仔细看会发现，其中有些常量如"I""V""<init>""LineNumberTable""LocalVariableTable"等，看起来在源代码中不存在的常量是哪里来的？
这些都是编译器自动生成，会被后面的字段表(field_info)、方法表(method_info)、属性表(attribute_info)所引用，他们将会被用来描述一些不方便使用“固定字节”进行表达的
内容，譬如方法的返回值是什么，有几个参数，每个参数的类型是什么。
因为java中的类时无穷五尽的，无法通过简单的无符号数来描述一个方法用到了什么类，因此在描述方法的这些信息时，需要引用常量表中的符号引用进行表达。

常量池中17种数据类型的结构总表：
常量  项目  类型  描述
CONSTANT_Utf-8_info  tag  u1  值为1
length  u2  UTF-8编码的字符串占用了字节数
bytes  u1  长度为length的UTF-8编码的字符串
CONSTANT_Integer_info  tag  u1  值为3
bytes  u4  按照高位在前存储的int值
CONSTANT_Float_info  tag  u1  值为4
bytes  u4  按照高位在前存储的float值
CONSTANT_Long_info  tag  u1  值为5
bytes  u8  按照高位在前存储的long值
CONSTANT_Double_info  tag  u1  值为6
bytes  u8  按照高位在前存储的double值
CONSTANT_Class_info  tag  u1  值为7
index  u2  指向全限定名常量项的索引
CONSTANT_String_info  tag  u1  值为8
index  u2  指向字符串字面量的索引
CONSTANT_Fieldref_info  tag  u1  值为9
index  u2  指向声明字段的类型或接口描述符CONSTANT_Class_info的索引项
index  u2  指向字段描述符CONSTANT_NameAndType的索引项
CONSTANT_Methodref_info  tag  u1  值为10
index  u2  指向声明方法的类描述符CONSTANT_Class_info的索引项
index  u2  指向名称及类型描述符CONSTANT_NameAndType的索引项
CONSTANT_InterfaceMethodref_info  tag  u1  值为11
index  u2  指向声明方法的接口描述符CONSTANT_Class_info的索引项
index  u2  指向名称及类型描述符CONSTANT_NameAndType的索引项
CONSTANT_NameAndType_info  tag  u1  值为12
index  u2  指向该字段或方法名称常量项的索引
index  u2  指向该字段或方法描述符常量项的索引
CONSTANT_MethodHandle_info  tag  u1  值为15
reference_kind  u1  值必须在[1,9]，它决定了方法句柄的理性。方法句柄类型的值标识方法句柄的字节码行为
reference_index  u2  值必须是对常量池的有效索引
CONSTANT_MethodType_info  tag  u1  值为16
descriptor_index  u2  值必须是对常量池的有效索引，常量池在该索引处的项必须是CONSTANT_Utf8_info结构，标识方法的描述符
CONSTANT_Dynamic_info  tag  u1  值为17
bootstrap_method_attr_index  u2  值必须对当前Class文件中引导方法表的bootstrap_methods[]数组的有效索引
name_and_tyep_index  u2  值必须对当前常量池的有效索引，常量池在该所索引处的项必须是CONSTANT_NameAndType_info结构，表示方法名和方法描述符
CONSTANT_InvokeDynamic_info  tag  u1  值为18
bootstrap_method_attr_index  u2  值必须对当前Class文件中引导方法表的bootstrap_methods[]数组的有效索引
name_and_tyep_index  u2  值必须对当前常量池的有效索引，常量池在该所索引处的项必须是CONSTANT_NameAndType_info结构，表示方法名和方法描述符
CONSTANT_Module_info  tag  u1  值为19
name_index  u2  值必须对常量池的有效索引，常量池在该索引处的项必须是CONSTANT_Utf8_info结构，表示模块名字
CONSTANT_Package_info  tag  u1  值为20
name_index  u2  值必须对常量池的有效索引，常量池在该索引处的项必须是CONSTANT_Utf8_info结构，表示包名称


### 访问标志
紧接着的2个字节是访问标志(access_flags)，用于识别一些类或接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；若是类，是否
被声明为final；等等。

访问标志：
标志名称  标志值  含义
ACC_PUBLIC  0x0001  是否Wiepublic类型
ACC_FINAL  0x0010  是否被声明为final，只有类可设置
ACC_SUPER  0x0020  是否允许使用invokespecial字节码指定的新语义，invokespcial指令语义在jdk1.0.2发生过改变，为了区别这条指令使用哪种语义，1.0.2之后编译出来的类为true
ACC_INTERFACE  0X0200  标识这是一个接口
ACC_ABSTRACT  0X0400  是否为abstract类型，对于接口或抽象类，此标志为真，其他类型为假
ACC_SYNTHETIC  0x1000  标识这个类并非由用户代码产生的
ACC_ANNOTATION  0X2000  表示这是一个注解
ACC_ENUM  0X4000  表示这是一个枚举
ACC_MODULE  0X8000   标识这是一个模块

本例中，TestClass是一个java普通类，不是接口、枚举、注解或模块，被publish修饰但没有声明为final和abstract，使用jdk1.2之后的编译器编译，因此ACC_PUBLIC/ACC_SUPER=true，
其他为假，access_flags=0x0001|0x0020=0x0021


### 类索引、父类索引与接口索引集合
类索引(this_class)和父类索引(super_class)类型为u2，而接口索引集合(interfaces)是一组u2类型的数据的集合，Class文件中油这三项数据确定该类型的继承关系。
类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名。除java.lang.Object外，所有java类的父类索引都不为0.
接口索引集合就是用来描述这个类实现了哪些接口，这些被实现的接口将按implements关键字(接口则是extends)后的顺序从做左到右排列在接口索引集合中。

类索引、父类索引和接口索引集合都按顺序排列在访问标志之后，类索引和父类索引用两个u2类型的索引值标识，各自指向一个类型为CONSTANT_Class_info的类描述符常量，通过
CONSTANT_Class_info类型的常量中的索引值可以找到定义在CONSTANT_Utf8_info类型的常量中的全限定名字符串。

本例代码的类索引查找过程：
this_class  ->      #1 CONSTANT_Class_info -> #2 CONSTANT_Utf8_info
value:1(第一个常量)   index:2                   bytes:org/fenixsoft/clazz/TestClass

接口索引结合，入口的第一项u2类型的数据为接口计数器(interfaces_count)，表示索引表的容量。若没有实现任何接口，则为0.
本例中：
从便宜地址0x000000F1开始的3个u2类型值为0x0001、0x0003、0x0000，即类索引为1，父类索引为3，接口索引集合大小为0
对应之前javap产出，找到常量池数据
const #1 = class #2; // org/fenixsoft/clazz/TestClass
const #2 = Asciz org/fenixsoft/clazz/TestClass;
const #3 = class #4; // java/lang/Object
const #4 = Asciz java/lang/Object;

### 字段表集合
field_info用于描述接口或类中声明的变量。
java语言的字段(field)包括类级变量及实例级变量，但不包括在方法内声明的局部变量。
字段可以包括的修饰符有字段的作用域(public/private/protected修饰符)、是实例变量还是类变量(static修饰符)、可变性(final)、并发可见性(volatile修饰符，是否强制从
主内存读写)、是否被序列化(transient修饰符)、字段数据类型(基本类型、对象、数组)、字段名称。
上述信息各个修饰符都是布尔值，很适合使用标志位表示。而字段叫什么名字、字段被定义为什么数据类型，这都是无法固定的，只能索引常量池中的常量来描述。

字段表结构：
类型  名称  数量
u2  access_flags  1
u2  name_index  1
u2  descriptor_index
u2  attributes_count  1
attribute_info  attributes  attributes_count

字段修饰符放在access_flags中，可以设置的标志位如下

字段访问标志：
标志名称  标志值  含义
ACC_PUBLIC  0X0001  字段是否public
ACC_PRIVATE  0X0002  字段是否private
ACC_PROTECTED  0X0004  字段是否protected
ACC_STATIC  0X0008  字段是否static
ACC_FINAL  0X0010  字段是否final
ACC_VOLATILE  0X0040  字段是否volatile
ACC_TRANSIENT  0X0080  字段是否transient
ACC_SYNTHETIC  0X1000  字段是否由编译器自动产生
ACC_ENUM  0X4000  字段是否enum

跟随access_flags标志的两项索引值：name_index和descriptor_index。都是对常量池项的引用，代表字段的简单名称以及字段和方法的描述符。

“org/fenixsoft/clazz/TestClass”这是类的全限定名，仅仅把类全命中的"."替换成了"/"。为了使连续的多个全限定名之间不产生混淆，在使用时最后一般加入一个";"表示全限定
名结束。
简单名称就是指没有类型和参数修饰的方法或字段名称，本例中的inc方法和m字段的简单名称分别是"inc"和"m"
描述符的作用是用来描述字段的数据类型、方法的参数列表(包括数量、类型及顺序)和返回值。根据描述符规则，基本数据类型(byte、char、double、float、int、long、short、
boolean)以及代表无返回值的void类型都用一个大写字符来表示，而对象类型则用字符L加对象的全限定名来表示

描述符标识字段含义：
标识字符  含义
B  基本类型byte
C  基本类型char
D  基本类型double
F  基本类型float
I  基本类型int
J  基本类型long
S  基本类型short
Z  基本类型boolean
V  特殊类型void
L  对象类型，如Ljava/lang/Oject;

对于数组类型，每一维度将使用一个前置的"["字符来描述，如一个定位"java.lang.String[][]"类型的二维数组将被记录成"[[Ljava/lang/String;"，一个整形数组"int[]"将被
记录成"[I"

用描述符来描述方法时，按照先参数列表、后返回值的顺序描述，参数列表按照参数的严格顺序放在一组小括号"()"内。
如方法void inc()的描述符为"()V"，方法java.lang.String.toString()的描述符为"()Ljava/lang/String;"，方法int indexOf(char[]source, int sourceOffset,
int sourceCount, char[] target, int targetOffset, int targetCount, int fromIndex)的描述符为"([CII[CII)I"

对于TestClass.class文件，字段表集合从地址0x000000F8开始，第一个u2类型的数据为容量计数器fields_count，值为0x0001，说明只有一个字段表数据。
紧跟的是access_flags标志，值为0x0002，代表private修饰符ACC_PRIVATE标志位为真，其他修饰符为假。
代表字段名称的name_index值为0x0005，从常量表可查得第五项是一个CONSTANT_Utf8_info类型的字符串，值为"m"。
代表字符描述符的descriptor_index值为0x006，指向常量池的字符串"I"。
推断出源代码定义的字段为：private int m;

字段表包含的固定数据项目到descriptor_index为止就全部结束，不过descriptor_index之后跟随一个属性表集合，用于存储一些额外信息。
本例字段m，他的属性表计数器为0，及没有额外描述信息，但若将m改为final static int m = 123;，那可能会存在一项名为ConstantValue的属性，其值指向常量123.

字段表集合不会列出从父类或父接口中继承而来的字段，但可能出现特别字段，如在内部类中为了保持对象外部类的访问，编译器会自动添加指向外部类实例的字段。
另外，在java中字段是无法重载的，两个字段的数据类型、修饰符不管是否相同，都必须使用不一样的名称，但对于Class文件格式来讲，只要两个字段的描述符不是完全相同，那字段重名就合法

### 方法表集合
方发表的结构如同字段表一样，依次包括访问标志(access_flags)、名称索引(name_index)、描述符索引(dscriptor_index)、属性表集合(attributes)。

方法表结构：
类型  名称  数量
u2  access_flags  1
u2  name_index  1
u2  descriptor_index
u2  attributes_count  1
attribute_info  attributes  attributes_count

方法访问标志：
标志名称  标志值  含义
ACC_PUBLIC  0X0001  方法是否public
ACC_PRIVATE  0X0002  方法是否private
ACC_PROTECTED  0X0004  方法是否protected
ACC_STATIC  0X0008  方法是否static
ACC_FINAL  0X0010  方法是否final
ACC_SYNCHRONIZED  0x0020  方法是否为synchronized
ACC_BRIDGE 0X0040  方法是不是由编译器产生的桥接方法
ACC_VARARGS  0X0080  方法是否接受不定参数
ACC_NATIVE  0X0100  方法是否为native
ACC_ABSTRACT  0x0400  方法是否为abstract
ACC_STRICT  0x0800  方法是否为strictfp
ACC_SYNTHETIC  0x1000  方法是否由编译器自动产生

方法的定义可以通过访问标志、名称索引、描述索引来表达清楚，但方法内代码在哪里？经过javac编译器编译成字节码指令后，存放在方法属性表集合中一个名为"Code"的属性里，属性
表作为Class文件格式中最具扩展性的一种数据项目。

本例，方法表集合的入口地址为0x00000101，第一个u2类型数据(即计数器容量)值为0x0002，代表集合中有两个方法，为编译器添加的实例构造器<init>和源码中定义的inc()。
第一个方法的访问标志值为0x0001，即ACC_PUBLIC=true，名称索引值为0x0007，查找常量池得到方法名为<init>，描述符索引值为0x0008，对应常量"()V"，属性表计数器
attributes_count值为0x0001，表示此方法的属性表集合有1项属性，属性名称的索引为0x0009，对应常量为"Code"，说明此属性是方法的字节码描述。

若父类方法在子类中没有被重写(Override)，方法表集合中就不会出现来自父类的方法信息。有可能出现由编译器自动添加的方法，如类构造器"<clinit>()"方法和实例构造器
"<init>()"方法

java中，要重载(Override)一个方法，除了要与原方法具有相同的简单名称外，还要求必须拥有一个与原方法不同的特征签名。
特征签名指一个方法中各个参数在常量池中的字段符号引用的集合，也正是因为返回值不会包含在特征签名中，所以java语言无法仅仅依靠返回值不同来对一个已有方法重载。
但在Class文件格式中，特征签名的范围要大一些，只要描述符不是完全一致的两个方法就可以共存，即方法有相同的名称和特征签名，但返回值不同，也可以共存于同一个Class文件中。
注：java代码的方法特征签名只包括方法名、参数顺序及参数类型，而字节码的特征签名还包括方法返回值以及受检查异常表。


### 属性表集合
attribute_info，Class文件、字段表、方法表都可以携带自己的属性表集合，以描述某些场景专有的信息

虚拟机规范预定义的属性
属性名  使用位置  含义
Code  方法表  java代码编译成的字节码指令
ConstantValue  字段表  由final关键字定义的常量值
Deprecated  类、方法表、字段表  被声明为deprecated的方法和字段
Exceptions  方法表  方法抛出的异常列表
EnclosingMethod  类文件  仅当一个类为局部类或匿名类时才能拥有这个属性，用于标识这个类所在的外围方法
InnerClass  类文件  内部类列表
LineNumberTable  Code属性  java源码的行号与字节码指令的对应关系
LocalVariableTable  Code属性  方法的局部变量描述
StackMapTable  Code属性  jdk6新增，供新的类型检查验证器(Type Checker)检查和处理目标方法的局部变量和操作数栈所需的类型是否匹配
Signature  类、方法表、字段表  jdk5新增，用于支持泛型情况下的方法签名。java中，任何类、接口、初始化方法或成员的泛型签名若包含了类型变量(Type Variables)或参数
化类型(Parameterized Types)，则Signature属性会为它记录泛型签名信息。由于java的泛型采用擦除法实现，为避免类型信息被擦除后导致签名混乱，需要这个属性记录泛型信息
SourceFile  类文件  记录源文件名称
SourceDebugExtension  类文件  jdk5新增，用于存储额外的调试信息。譬如在进行JSP文件调试时，无法通过java堆栈来定位到JSP的行号。使用该属性即可用于存储这些调试信息
Synthetic  类、方法表、字段表  标识方法或字段为编译器自动生成的
LocalVariableTypeTable  类  jdk5新增，使用特征签名代替描述符，是为了引入泛型语法后能描述泛型参数化类型而添加
RuntimeVisibleAnnotations  类、方法表、字段表，为动态注解提供支持。用于指明哪些注解是运行时(运行时就是进行反射调用)可见的
RuntimeInvisibleAnnotations  类、方法表、字段表  用于指明哪些注解是运行时不可见的
RuntimeVisibleParameterAnnotations  方法表  与RuntimeVisibleAnnotations类似，不过作用对象为方法参数
RuntimeInvisibleParameterAnnotations  方发表  与RuntimeInvisibleAnnotations类似，作用对象为方法参数
AnnotationDefault  方法表  用于记录注解元素的默认值
BootstrapMethods  类文件  用于保存invokedynamic指令引用的引导方法限定符
RuntimeVisibleTypeAnnotations  类、方法表、字段表，Code属性  用于指明哪些类注解是运行时可见的
RuntimeInvisibleTypeAnnotations  类、方法表、字段表，Code属性  指明哪些注解是运行时不可见的
MethodParameters  方法表  用于支持(编译时加上-parameters参数)将方法名称编译进Class文件中，并可运行时获取。
Module  类  用于记录一个Module的名称以及相关信息(requires、exports、opens、uses、provides)
ModulePackages  类  记录一个模块所有被exports或opens的包
ModuleMainClass  类  用于指定一个模块的主类
NestHost  类  用于支持嵌套类(java中的内部类)的反射和访问控制的API，一个内部类通过该属性得知自己的宿主类
NestMembers  类  用于支持嵌套类(java中的内部类)的反射和访问控制的API，一个宿主类通过该属性得知自己有哪些内部类

对于每一个属性，他的名字要从常量池中引用一个CONSTANT_Utf8_info类型的常量来表示，而属性值的结构则完全自定义，只要通过一个u4长度属性去说明属性所占用的位数即可。

属性表结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u1  info  attribute_length


#### Code属性
java程序方法体的代码经过javac编译器处理后，最终变为字节码指令存储在Code属性内。
Code属性出现在方发表的属性集合之中，但并非所有方发表都必须存在这个属性，譬如接口或抽象类中的方法就不存在Code属性

Code属性表结构
类型  名称  数量
u2  attribute_name_idnex  1
u4  attribute_length  1
u2  max_stack  1
u2  max_locals  1
u4  code_length  1
u1  code  code_length
u2  exception_table_length  1
exception_info  exception_table  exception_table_length
u2  attributes_count  1
attribute_info  attributes  attributes_count

attribute_name_idnex是一项指向CONSTANG_Utf8_info型常量的索引，此常量值固定为"Code"，代表了该属性的属性名称，attribute_length知识了属性值的长度，由于属性名称
索引与属性长度一共为6个字节，所以属性的长度固定为整个属性表长度减去6个字节。
max_stack代表操作数栈(Operand Stack)深度的最大值。方法执行时，操作数栈都不会超过这个深度。虚拟机运行时需要根据这个值分配栈帧(Stack Frame)中的操作栈深度。
max_locals代表局部变量表所需的存储空间。单位是变量槽(Slot)，变量槽是虚拟机为局部变量分配内存使用的最小单位。对于byte、char、float、int、short、boolean和
returnAddress等长度不超过32位的数据类型，每个局部变量占用一个变量槽，而double和long这俩64位数据类型需要两个变量槽存放。
方法参数(包括实例方法中的隐藏参数"this")、显示异常处理程序的参数(Exception Handler Parameter，即try-catch中catch块中所定义的异常)、方法体重定义的局部变量都要
依赖局部变量表来存放。
注：并不是在方法中用了多少个局部变量，就把这些局部变量所占变量槽数量只和作为max_locals的值，操作数栈和局部变量表直接决定一个该方法的栈帧所耗费的内存，不必要的操作数
栈深度和变量槽刷领会造成内存浪费。
虚拟机做法是将局部变量表中的变量槽重用，当代码执行超过一个局部变量的作用域时，这个局部变量所占用的变量槽可以被其他局部变量所使用，javac编译器会根据变量的作用域来
分配变量槽给各个变量使用，根据同时生成的最大局部变量数量和类型计算出max_locals的大小。

code_length和code用来存储java源程序编译后生成的字节码指令。code_length代表字节码长度，code用于存储字节码指令的一系列字节流。
每个指令是一个u1类型的单字节，当虚拟机读取到code中的一个字节码时，可以对应找出这个字节码代表的是什么指令，并可以知道这条指令后面是否需要跟随参数，以及后续的参数应当
如何解析。
一个u1数据类型的取值范围0x00~0xFF，十进制0~255，即一共可以表达256条指令。
code_length类型是u4不过实际只能用u2长度

Code属性是Class文件中最重要的一个属性，若把一个java程序的信息分为代码(Code，方法体中的java代码)和元数据(Metadata，包括类、字段、方法定义及其他信息)两部分，那么
在整个Class文件中，Code属性用于描述代码，所有的其他数据项目都用于描述元数据。

```
00 01 00 01 00 00 00 05 2A B7 00 0A B1
```
本例TestClass.class中，这是实例构造器<init>()方法的Code属性。
操作数栈的最大深度和本地本地变量表的容量都为0x0001，字节码区域所占空间长度为0x0005。
虚拟机读取到字节码区域的长度后，按照顺序依次读入紧随的5个字节，并根据字节码指令表翻译出所对应的字节码指令。
范围2AB7000AB1过程为：
1)读入2A，查表得0x2A对应的指令为aload_0，将第0个变量槽中为reference类型的本地变量推送到操作数栈顶
2)读入B7，查表得0xB7对应指令为invokespecial，以栈顶的reference类型的数据所指向的对象作为方法接收者，调用此对象的实例构造器方法、private方法或它的父类的方法。
这个方法有一个u2类型的参数说明具体调用哪个方法，它指向常量池中的一个CONSTANT_Methodref_info类型常量，即此方法的符号引用
3)读入000A，这是invokespecial指令的参数，代表一个符号引用，查常量池得0x000A对应的常量为实例构造器<init>()方法的符号引用
4)读入B1，查表得0xB1对应的指令为return，是从方法的返回，并且返回值为void。这条指令执行后，当前方法正常结束

再用javap查看inc方法字节码指令
java语言的潜规则：在任何实例方法里，都可以通过this访问到此方法所属的对象。实现是通过在javac编译器编译时把this关键字的访问转变为对一个普通方法参数的访问，然后在
虚拟机调用实例方法时自动传入此参数而已。因此在实例方法的局部变量表中至少会存在一个指向当前对象实例的局部变量，局部变量表中也会预留出第一个变量槽位来存放对象实例的
引用，所以实例方法参数值从1开始。

字节码指令之后是这个方法的显示异常处理表集合。

属性表结构(异常表)
类型  名称  刷领
u2  start_pc  1
u2  end_pc  1
u2  handle_pc  1
u2  catch_type  1

若存在异常表，那它包含4个字段，含义为：
若当字节码从第start_pc行到第end_pc行之间(不含)出现了类型为catch_type或其子类的异常(catch_type为指向一个CONSTANT_Class_info型常量的索引)，
则转到第handler_pc行继续处理。当catch_type=0时，代表任意异常情况都需要转到handler_pc处进行处理


ShowExceptionTable
// 编译后的ByteCode字节码及异常表
public int inc();
Code:
Stack=1, Locals=5, Args_size=1
0: iconst_1  // try块中的x=1
1: istore_1
2: iload_1  保存x到returnValue中，此时x=1  --感觉这里有问题
3: istore 4
5: iconst_3  finaly块中的x=3
6: istore_1
7: iload 4  将returnValue中的值放到栈顶，准备给ireturn返回
9: ireturn
10: astore_2  给catch中定义的Exception e赋值，存储在变量槽 2中          
11: iconst_2  catch块中的x=2
12: istore_1
13: iload_1   保存x到returnValue中，此时x=2
14: istore 4
16: iconst_3  finaly块中的x=3
17: istore_1
18: iload 4  将returnValue中的值放到栈顶，准备给ireturn返回
20: ireturn
21: astore_3  如果出现了不属于java.lang.Exception及其子类的异常才会走到这里
22: iconst_3  finaly块中的x=3
23: istore_1
24: aload_3  将异常放置到栈顶，并抛出
25: athrow
Exception table:
from to target type
0  5  10  Class java/lang/Exception
0 5 21  any
10 16 21  any

编译器为这段java代码生成了三条异常表记录，对应三条可能出现的代码执行路径。
从java语义上讲，这三条路径分别为：
+ 若try语句块中出现属于Exception或其子类的异常，跳转到catch语句块处理
+ 若try语句块中出现不属于Exception或其子类的异常，跳转到finlly语句块处理
+ 若catch语句块中出现任何异常，跳转到finally语句块处理

返回值多少？若没有异常，返回1；若有Exception异常，返回2；若出现了Exception以外的异常，方法非正常退出，没有返回值。
从字节码层面看看为何会有这样的返回结果：
0~4行所做的操作时将整数1赋值给变量x，将此时x的值复制一份副本到最后一个本地变量表的变量槽中(这个槽的值在ireturn指令执行前会被重新读到操作数栈顶，作为返回值，起名
returnValue)。
若这时没有异常，则就想走5~9行，将变量x赋值为3，让后将之前保存在returnValue中的1读入到操作数栈顶，最后ireturn以int形式返回操作栈顶中的值，结束。
若出现异常，PC寄存器指针跳转到第10行，第10~20行所做是将2赋给变量x，然后将变量x此时的值付给returnValue，最后再将变量x的值改为3。方法返回前同样将returnValue中
保留的整数2读到了操作栈顶。
从第21行开始代码作用是将变量x的值赋为3，并将栈顶的异常抛出，方法结束




































### 谈论垃圾收集器的上下文语境中，并行与并发：
+ 并行(Parallel)：描述的是多条垃圾收集器线程之间的关系，说明同一时间有多条这样的线程在协同工作，通常默认此时用户线程是处于等待状态的。
+ 并发(Concurrent)：描述的是垃圾收集器线程与用户线程之间的关系，说明同一时间垃圾收集线程与用户线程都运行。由于用户线程并未被冻结，所以
  仍然能响应服务请求，但由于垃圾收集器线程占用了一部分系统资源，此时应用程序的处理的吞吐量将受到一定影响。

吞吐量：处理器用于运行用户代码的时间与处理器总消耗时间的比值。
吞吐量=运行用户代码时间/运行用户代码时间+运行垃圾收集时间
例如：若虚拟机完成某个任务，用户代码加上垃圾收集总共耗费100分钟，其中垃圾收集花费1分钟，吞吐量就是99%.

#### Exceptions属性
作用是列举出方法中可能抛出的受检查异常(Checked Exceptions)，也就是方法描述时在throw后的异常

Exceptions属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u2  number_of_exceptions  1
u2  exception_index_table  number_of_exceptions

number_of_exceptions表示方法可能抛出number_of_exceptions种受查异常，每一种受查异常使用一个exception_index_table表示。
exception_index_table是一个指向常量池中CONSTANT_Class_info型常量的索引，代表了该受查异常的类型

#### LineNumberTable属性
用于描述java源码行号与字节码行号(字节码的偏移量)之间的对应关系。
javac用-g:none或-g:lines来取消或要求生成这项信息。
若不选择，那么对程序运行产生的最主要影响是当抛出异常时，堆栈中将不会显示出错的行号，并在调试程序时，无法按照源码行来设置断点。

LineNumberTable属性结构：
类型  名称  数量
u2  attriute_name_index  1
u4  attribute_length  1
u2  line_number_table_length  1
line_number_info  line_number_table  line_number_table_length
line_number_table是一个数量为line_number_table_length、类型为line_number_info的集合，
line_number_info表包含start_pc和line_number两个u2类型的数据项，前者是字节码行号，后者是java源码行号

#### LocalVariableTable及LocalVariableTypeTable属性
LocalVariableTable属性用于描述栈帧中局部变量表的变量与java源码中定义的变量之间关系，默认生成到Class文件中。
可用javac -g:none或-g:vars取消或开启。
若没有生成这项属性，影响是当其他人引用这个方法时，所有的参数名都将会消失，如IDE会将注入arg0、arg1之类的占位符代替原有的参数名，而且再调试期间无法根据参数名从上
下文中获得参数值。

LocalVariableTable属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u2  local_variable_table_length  1
local_variable_info  local_variable_table  local_variable_table_length
local_variable_info代表了一个栈帧与源码中局部变量的关联。

local_variable_info项目结构
类型  名称  数量
u2  start_pc  1
u2  length  1
u2  name_index  1
u2  descriptor_index  1
u2  index  1

start_pc和length属性分别代表这个局部变量的生命周期开始的字节码偏移量及其作用范围覆盖的长度，两者结合就是这个局部变量在字节码之中的作用域范围
name_index和descriptor_index都是指向常量池中CONSTANT_Utf8_info型常量的索引，代表局部变量的名称以及这个局部变量的描述符
index是这个局部变量在栈帧的局部变量表中变量槽的位置。当变量类型64位时，占用的变量槽为index和index+1两个
jdk1.5依然怒泛型后，增加一个LocalVariableTypeTable，与之相似，仅仅把记录的字段描述符的descriptor_index替换成了字段的特征签名(Signature)。对于非泛型类型
，描述符和特征签名能描述的信息一致，但泛型引入后，由于描述符中反省的参数化类型被擦除掉，描述符不能准确描述泛型类型了。因此出现了LocalVariableTypeTable属性，
使用字段的特征签名来完成泛型的描述。

#### SourceFile及SourceDebugExtension属性
SourceFile用于记录生成这个Class文件的源码文件名称。

SourceFile属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u2  sourcefile_index  1

sourcefile_index指向常量池中CONSTANT_Utf8_info型常量的索引，常量值是源码文件的文件名

为了便于编译器和动态生成的Class中加入供程序员使用的自定义内容。jdk5增加了SourceDebugExtension属性用于存储额外的代码调试信息。

SourceDebugExtension属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u1  debug_extension[attribute_length]  1

debug_extension存储额外的调试信息，是一组通过变长UTF8格式来表示的字符串。

#### ConstantValue属性
作用是通知虚拟机自动为静态变量赋值。只有被static修饰的变量(类变量)才可以使用此项竖向。
对于非static类型的变量(实例变量)的赋值时再实例构造器<init>()方法中进行的；对于类变量，则有两种方式供选择：在类构造器<clinit>()或使用ConstantValue属性。
javac编译器选择是，若有final+static且这个变量数据类型是基本类型或java.lang.String，就会生成ConstantValue属性来初始化；若这个变量没有被final或并非基本类型及
字符串，则将会选择在<clinit>()中初始化
此属性的属性值是一个常量池的索引号，由于Class文件格式的常量类型中只有与基本属性和字符串相对应的字面量。

ConstantValue属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u2  constantvalue_index  1

可看出ConstantValue属性是一个定长属性，attribute_length数据项必须固定为2。constantvalue_index代表了常量池中一个字面量常量的引用，根据字段类型不同，字面量可以
是CONSTANT_Long_info、是CONSTANT_Float_info、是CONSTANT_Double_info、是CONSTANT_Integer_info和是CONSTANT_String_info的一种。

#### InnerClasses属性
用于记录内部类与宿主类之间的关联。若一个类中定义了内部类，那编译器会为他以及他所包含的内部类生成InnerClasses属性。

InnerClasses属性结构：
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u2  number_of_classes  1
inner_classes_info  inner_classes  number_of_classes

number_of_classes代表需要记录多少个内部类信息，每一个内部类信息都由一个inner_classes_info表进行描述

inner_classes_info表的结构
类型  名称  数量
u2  inner_class_info_index  1
u2  outer_class_info_index  1
u2  inner_name_idnex  1
u2  inner_class_access_flags  1

inner_class_info_index和outer_class_info_index都是指向常量池中CONSTANT_Class_info型常量的索引，代表内部类和宿主类的符号引用
inner_name_idnex指向常量池中CONSTANT_Utf8_info型常量的索引，代表这个内部类的名字，若是匿名内部类，这项为0
inner_class_access_flags是内部类的访问标志，类似于类的access_flags

inner_class_access_flags标志
标志名称  标志值  含义
ACC_PUBLIC  0X0001  内部类是否public
ACC_PRIVATE  0X0002  内部类是否private
ACC_PROTECTED  0X0004  内部类是否protected
ACC_STATIC  0X0008  内部类是否static
ACC_FINAL  0X0010  内部类是否final
ACC_INTERFACE  0X0020  内部类是否为接口
ACC_ABSTRACT  0X0400  内部类是否为abstract
ACC_SYNTHETIC  0x1000  内部类是否并非由用户代码产生
ACC_ANNOTATION  0x2000  内部类是不是一个注解
ACC_ENUM  0x4000  内部类是不是一个枚举

#### Deprecated及Synthetic属性
都属于标志类型的布尔属性。
Deprecated表示类、字段或方法，已经被程序作者定位不再推荐使用。
Synthetic属性代表此字段或方法并不是由java源码直接产生，而是由编译器自行添加的。

Deprecated及Synthetic属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1

attribute_length值必须为0x00000000，因为没有任何属性值需要设置

#### StackMapTable属性
变长属性，位于COde属性的属性表中。会在虚拟机类加载的字节码验证阶段被新类型检查验证器(Type Checker)使用，
目的在于代替以前比较消耗性能的基于数据流分析的类型推导验证器

新的验证器省略了运行期通过数据流分析去确认字节码的行为逻辑是否合法性的步骤，而在编译阶段将一系列的验证类型(Verification Type)直接记录在Class文件中，通过检查这些
验证类型代替了类型推导过程，从而大幅提升字节码验证的性能。  --拆开

StackMapTable属性中包含零至多尔衮栈映射帧(Stack Map Frame)，每个栈映射帧都显示或隐式地代表了一个字节码偏移量，用于表示执行到该字节码时局部变量表和操作数栈的
验证类型。类型检查验证器会通过检查目标方法的局部变量和操作数栈所需要的类型来确定一段字节码指令是否符合逻辑约束

StackMapTable属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u2  number_of_entries  1
stack_map_frame  stack_map_frame_entries  number_of_entries

一个方法的Code属性最多只能有一个StackMapTable属性。

#### Signature属性
定长属性，可以出现于类、字段表和方发表结构的属性表中。
jdk5大幅增强java语法，此后，任何类、接口、初始化方法或成员的泛型签名若包含了类型变量(Type Varaiable)或参数化类型(Parameterized Type)，则Signature属性会为
它记录泛型签名信息。
因为java语言的泛型采用的是擦除法实现的伪泛型，字节码(Code属性)中所有的泛型信息编译(类型变量、参数化类型)在编译之后都通通被擦除掉。
使用擦除法的好处是实现简单(主要修改javac编译器，虚拟机内部只做了很少改动)、非常容易实现Backport，运行期也能节省一些类型所占的内存空间。但坏处是运行期无法像C#等
真泛型支持的语言那样，将泛型类型与用户定义的普通类型同等对待，例如运行期做反射时无法获得泛型信息。
Signature属性时为了弥补这个缺陷而增设的。现在java的反射API能获取的泛型类型，最终数据来源也是这个属性。

Signature属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u2  signature_index  1

signature_index值必须是一个对常量池的有效索引，必须是CONSTANT_Utf8_info结构，表示类签名或方法类型签名或字段类型签名。

#### BootstrapMethods属性
变长属性，位于类文件的属性表中。用于保存invokedynamic指令引用的引导方法限定符
直到jdk8中lambda表达式和接口默认方法的出现，InvokeDynamic指令才算在java语言生成的Class文件中有了用武之地。

BootstrapMethods属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length
u2  number_bootstrap_methods  1
bootstrap_method  bootstrap_methods  num_bootstrap_methods

number_bootstrap_methods给出了bootstrap_method[]数组中的引导方法限定符的数量。bootstrap_method[]数组的每个成员包含了一个指向常量池CONSTANT_MethodHandle结构
的索引值，代表了一个引导方法。

bootstrap_method属性结构
类型  名称  数量
u2  bootstrap_method_ref  1
u2  num_bootstrap_arguments  1
u2  bootstrap_arguments  num_bootstrap_arguments

bootstrap_method_ref必须是对常量池的有效索引，值必须是CONSTANT_MethodHandle_info结构
num_bootstrap_arguments给出了bootstrap_arguments[]数组成员的数量
bootstrap_arguments[]数组的每个成员必须是一个对常量池的有效索引。

#### MethodParameters属性
用在方法表中的变长属性。作用是记录方法的各个形参名称和信息
后来-g:var成为了javac及许多IDE编译Class时默认值，这样会将方法参数的名称生成到LocalVariableTable属性中。不过由于LocalVariableTable属性是Code属性的子属性——
没有方法体存在，自然就不会有局部变量表，但对于其他情况，如抽象方法和接口方法，是理所当然地可以不存在方法体，对于方法签名来说，还是没有找到一个统一完整的保留方法
参数名的地方。
jdk8新增此属性，使得编译器可以(编译时用-parameters)将方法名称也写进Class文件中，而MethodParameters是方法表的属性，与Code属性平级，可以运行时通过反射API获取。

MethodParameters属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u1  parameters_count
parameter  parameters  parameters_count

parameter属性结构
类型  名称  数量
u2  name_index  1
u2  access_flags  1

name_index是一个指向常量池CONSTANT_Utf8_info常量的索引值，代表该参数的名称。
access_flags是参数的状态指示器，可以包含三种状态的一种或多种：
+ 0x00010(ACC_FINAL)：表示该参数被final修饰
+ 0X10000(ACC_SYNTHETIC)：表示该参数并未出现在源文件中，是编译器自动生成的
+ 0x8000(ACC_MANDATED)：表示该参数在源文件中隐式定义的。Java中典型场景是this


#### 模块化相关属性
jdk9重量级功能是java的模块化功能，因为模块描述文件(module-info.java)最终是要编译成一个独立的Class文件来存储的，所以Class文件格式也扩展了Module、ModulePackages和
ModuleMainClass三个属性用于支持java模块化相关功能。

Module属性变长，除了表示该模块的名称、版本、标志信息外，还存储了这个模块的requires、exports、opens、uses和provides定义的全部内容

Module属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u2  module_name_index  1
u2  module_flags  1
u2  module_version_index  1
u2  requires_count  1
require  requires  requires_count
u2  exports_count  1
export  exports  exports_count
u2  opens_count  1
open  opens  opens_count
u2  uses_count  1
use uses_index  uses_count
u2  provides_count  1
provide  provides  provides_count

module_name_index指向常量池CONSTANT_Utf8_info常量的索引值，代表了该模块的名称。
module_flags模块的状态指示器，可以包含一下状态中一种或多种：
+ 0x0020(ACC_OPEN)：表示该模块是开放的
+ 0x1000(ACC_SYNTHETIC)：表示该模块并未出现在源文件中，是编译器自动生成
+ 0x8000(ACC_MANDATED)：表示该模块是在源文件中隐式定义的

module_version_index指向常量池CONSTANT_Utf8_info常量的索引值，代表了该模块的版本号

exports属性结构
类型  名称  数量
u2  exports_index  1
u2  exports_flags  1
u2  exports_to_count  1
export  exports_to_index  exports_to_count

exports属性的每一元素都代表一个被模块所导出的包。
exports_index指向常量池CONSTANT_Package_info常量的索引值，代表了被该模块导出的包。
exports_flags是该导出包的状态指示器，可包含一下状态的一种或多种：
+ 0x1000(ACC_SYNTHETIC)：表示该导出包并未出现在原文件中，是编译器自动生成
+ 0x8000(ACC_MANDATED)：表示该导出包是在原文件中隐式定义的

exports_to_count是该导出包的限定计数器，若为0，说明该导出包是无限定的(Unqualified)，即完全开放。
若不为0，则后面的exports_to_index是以计数器值为长度的数组，每个元素都是一个指向常量池CONSTANT_Module_info常量的索引值，代表只有在这个数组范围内的模块才能
被运行访问该导出包的内容。


ModulePackages是另一个用于支持java模块化的变长属性，用于描述该模块中所有的包，不论是不是被export或open的

ModulePackages属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u2  package_count  1
u2  package_index  package_count

package_count是package_index数组的计数器，package_index中每个元素都是指向常量池CONSTANT_Package_info常量的索引值，代表当前模块中的一个包。

ModuleMainClass属性是一个定长属性，用于确定该模块的主类(Main Class)

ModuleMainClass属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u2  main_class_index  1

main_class_index是一个指向常量池CONSTANT_Class_info常量的索引值，代表了该模块的主类

#### 运行时注解相关属性
为了存储源码中的注解信息，Class文件同步增加了RuntimeVisibleAnnotations、RuntimeInvisibleAnnotations、RuntimeVisibleParameterAnnotations和
RuntimeInvisibleParameterAnnotations。
到jdk8进一步加强java语言的注解使用范围，有新增类型注解，所以Class文件也同步增加RuntimeVisibleTypeAnnotations和RuntimeInvisibleTypeAnnotations

RuntimeVisibleAnnotations是一个变长属性，记录了类、字段或方法的声明上记录运行时可见注解，当用反射API获取类、字段或方法上的注解时，返回值就是通过这个属性来取得

RuntimeVisibleAnnotations属性结构
类型  名称  数量
u2  attribute_name_index  1
u4  attribute_length  1
u2  num_annotations  1
annotation  annotations  num_annotations

num_annotations是annotations数组的计数器，annotations中每个元素代表了一个运行时可见的注解，注解在Class文件中以annotation结构存储

annotation属性结构
类型  名称  数量
u2  type_index  1
u2  num_element_value_pairs  1
elemnt_value_pair  element_value_pairs  num_element_value_pairs

type_index是一个指向常量池CONSTANT_Utf8_info常量的索引值，该常量应以字段描述符的形式表示一个注解。
num_element_value_pairs是elemnt_value_pairs数组的计数器elemnt_value_pairs中每个元素都是一个键值对，代表该注解的参数和值


## 字节码指令简介
java虚拟机的指令由一个字节长度的、嗲表这某种特定操作含义的数字(称为操作码，Opcode)以及跟随其后的零至多个代表此操作所需的参数(称为操作数,Operand)构成。
由于java虚拟机采用面向操作数栈而不是面向寄存器的架构，所以大多数指令都不包含操作数，只有一个操作码，指令参数都存放在操作数栈中。

字节码指令集可算是一种具有鲜明特点、优势和劣势均很突出的指令集架构，操作码长度为一个字节(0~255)，即最多256条；由于Class文件格式放弃了编译后代码的操作数
长度对其，意味着虚拟机在处理那些超过一个字节的数据时，不得不在运行时从字节中重建出具体数据的结构，譬如要将一个16位长度的无符号整数使用两个无符号字节存储起来
假设byte1和byte2，值应该为：(byte1 << 8 ) | byte2，这种操作在某种程度上会导致解释执行字节码时将损失一些性能，但这样做的优势是放弃了操作数长度对其，意味着
可以省略掉大量的填充和间隔符号；用一个字节来代表操作码，也是为了尽可能获得短小精干的编译代码。
这种追求尽可能小数据量、高传输效率的设计时由java语言设计之初主要面向网络、智能家电的技术背景决定的，一直沿用。

若不考虑异常处理，那虚拟机的解释器可以使用下面伪代码作为最基本的执行模型。
```
do{
  自动计算PC寄存器的值+1
	根据PC寄存器指示的位置，从字节码流中取出操作码；
	if (字节码存在操作数) 从字节码流中去除操作数；
	执行操作码所定义的操作；
} wihle (字节码流长度 > 0);
```

### 字节码与数据类型
java虚拟机指令集中，大多数指令都包含其操作所对应的数据类型信息。
如，iload指令用于从局部变量表中加载int型的数据到操作数栈中，fload指令加载的是float类型数据。
这俩指令的操作在虚拟机内部可能会用同一段代码实现，但在Class文件中他们必须拥有各自独立的操作码

大部分与数据类型相关的字节码指令，操作码助记符中都有特殊的字符来表明专门为那种数据类型服务：i代表int类型，l代表long，s代表short，b代表byte，c代表char，f代表
float，d代表double，a代表reference。
也有一些指令助记符中没有明确指明操作类型的字母，如arraylength指令，操作数永远只能是一个数组类型的对象。
又如，无条件跳转指令goto则是与数据类型无关的指令

因为java虚拟机的操作码长度只有一字节，所以包含了数据类型的操作码就位指令集的设计带来了很大压力：若每一种与数据类型相关的指令都支持虚拟机所有运行数据类型的话，那么
指令的数量恐怕会超出一字节所能表示的数量范围了。
因此，虚拟机指令集对于特定的操作只提供了有限的类型相关指令去支持他，指令集将会被故意设计成非完全独立的。Not Orthogonal

java虚拟机指令集所支持的数据类型(T表示可能的类型)
opcode  byte  short  int  long  float  double  char  reference
Tipush  bipush  sipush
Tconst               iconst  lconst  fconst  dconst      aconst
Tload                iload  lload  fload  dload    aload
Tsotre               istore  lstore  fstore  dstore    astore
Tinc                 iinc
Taload  baload  saload  iaload  laload  faload  daload  caload  aaload
Tastore  bastore  sastore  iastore  lastore  fastore  dastore  castore  aastore
Tadd                 iadd  ladd  fadd  dadd
Tsub                 isub  lsub  fsub  dsub
Tmul                 imul  lmul  fmul  dmul
Tdiv                 idiv  ldiv  fdiv  ddiv
Trem                 irem  lrem  frem  drem
Tneg                 ineg  lneg  fneg  dneg
Tshl                 ishl  lshl
Thsr                 ishr  lshr
Tushr                iushr  lushr
Tand                 iand  land
Tor                  ior  lor
Txor                 ixor  lxor
i2T  i2b  i2s              i2l  i2f  i2d
l2T                  l2i        l2f  l2d
f2T                  f2i  f2l        f2d
d2T                  d2i  d2l  d2f
Tcmp                      lcmp
Tcmpl                           fcmpl  dcmpl
Tcmpg                           fcmpg  dcmpg
if_TcmpOP            if_icmpOp                                         if_acmpOP
Treturn              ireturn  lreturn  freturn  dreturn                areturn

编译器会在编译期或运行期将byte和short类型的数据带符号扩展(Sign-Extend)为相应的int类型数据，将boolean和char类型数据零位扩展(Zero-Extend)为相应的int类型数据。
处理boolean、byte、short和char类型的数组时，也会转换为使用对应的int类型的字节码指令来处理。

阅读字节码作为了解java虚拟机的基础技能，是一项应当熟练掌握的能力。

### 加载和存储指令
加载和存储指令用于将数据在栈帧中的局部变量表和操作数栈之间来回传输。
包括
+ 将一个局部变量加载到操作栈：iload、iload_<n>、lload、lload_<n>、fload、fload_<n>、dload、dload_<n>、aload、aload_<n>
+ 将一个数值从操作数栈存储到局部变量表：istore、istore_<n>、lstore、lsotre_<n>、fstore、fstore_<n>、dstore、dstore_<n>、astore、astore_<n>
+ 将一个常量加载到操作数栈：bipush、sipush、ldc、ldc_w、ldc2_w、aconst_null、iconst_ml、iconst_<i>、lconst_<l>、fconst_<f>、dconst_<d>
+ 扩充局部变量表的访问索引的指令：wide

存储数据的操作数栈和局部变量表主要由加载和存储指令操作，还有少量指令，如访问对象的字段或数组元素的指令也会向操作数栈传输数据
iload_<n>代表了ilaod_0、ilaod_1、ilaod_2、ilaod_3，这几组指令都是某个带有一个操作数的通用指令的特殊形式。

### 运算指令
算输指令用于对两个操作数栈上的值进行某种特定运算，并把结果重新存入到操作栈顶。
大体分为：对整形数据进行运算的指令与堆浮点型数据进行运算的指令。
都是使用java虚拟机的算数类型来进行计算，即byte、short、char和boolean都使用操作int类型的指令代替。
包括：
+ 加法：iadd、load、fadd、dadd
+ 减法：isub、lsub、fsub、dsub
+ 乘法：imul、lmul、fmul、dmul
+ 除法：idiv、ldiv、fdiv、ddiv
+ 求余：irem、lrem、frem、drem
+ 取反：ineg、lneg、fneg、dneg
+ 位移：ishl、ishr、iushr、lshl、lshr、lushr
+ 按位或：ior、lor
+ 按位与：iand、land
+ 按位异或：ixor、lxor
+ 局部变量自增：iinc
+ 比较：dcmpg、dcompl、fcmpg、fcmpl、lcmp

<java虚拟机规范>仅规定在处理整形数据时，只有除法(idiv和ldiv)以及求余(irem和lrem)中，当出现除数为零时导致虚拟机抛出ArithmeticException异常。

### 类型转换指令
可以将两种不同的数值类型相互转换，这些操作一般用于实现用户代码中的显示类型转换操作，或用来处理字节码指令集中数据类型相关指令无法与数据类型一一对应问题。

java虚拟机直接支持(即转换时无需显示转换指令)一下数值类型的宽化类型转换(Widening Numeric Conversion，即小范围类型向大范围类型的安全转换)：
+ int类型到long、float或double
+ long类型到float、double类型
+ float类型到double类型

处理窄化类型转换(Narrwoing Numeric Conversion)时，必须显示地使用转换指令完成，包括i2b、i2c、i2s、l2i、f2i、f2l、d2i、d2l和d2f。
可能会导致转换结果产生不同的正负号、不同的数量级的情况，转换过程可能会导致数值的精度丢失。

### 对象创建与访问指令
虽然类实例和数组都是对象，但java虚拟机堆类实例和数组的创建与操作使用了不同的字节码指令。
对象创建后，就可以通过对象访问指令获取对象实例或数组实例中的字段或数组元素
包括：
+ 创建类实例：new
+ 创建数组：newarray、anewarray、multianewarray
+ 访问类字段(static字段，类变量)和实例字段(非static字段，实例变量)：getfield、putfield、getstatic、putstatic
+ 把一个数组元素加载到操作数栈：baload、caload、saload、iaload、laload、faload、daload、aaload
+ 将一个操作数栈的值存储到数组元素中：bastore、castore、sastore、iastore、fastore、dastore、aastore
+ 取数组长度：arraylength
+ 检查类实例类型的指令：instanceof、checkcast

### 操作数栈管理指令
直接操作操作数栈的指令：
+ 将操作数栈顶一个或两个元素出栈：pop、pop2
+ 复制栈顶一个或两个数值并将复制值或双份的复制值重新压入栈顶：dup、dup2、dup_x1、dup2_x1、dup_x2、dup2_x2
+ 将栈最顶端的两个数值互换：swap

### 控制转移指令
可以让java虚拟机有条件或无条件地从指定位置指令(而不是控制转移指令)的下一条指令继续执行程序。概念模型上讲，可以认为控制指令就是在有条件或无条件地修改PC寄存器的值。
包括：
+ 条件分支：ifeq、iflt、ifle、ifne、ifgt、ifge、ifnull、ifnonnull、if_icmpeq、if_icmpne、if_icmplt、ifimcpgt、if_icmple、if_icmpge、ifacmpeq、if_acmpne
  -- ifacmpeq是对于引用
+ 复合条件分支：tableswitch、lookupswitch
+ 无条件分支：goto、goto_w、jsr、jsr_w、ret

对于boolena、byte、char、short的条件分支比较操作，都会用int类型的比较指令完成。
对于long类型、float、double的条件分支比较操作，会先执行相应类型的比较运算指令(dcmpg、dcmpl、fcmpg、fcmpl、lcmp)，运算指令会返回一个整形值到操作数栈中，随后再执行
int类型的条件分支比较操作完成整个分支跳转。

### 方法调用和返回指令
举例五条指令用于方法调用：
+ invokevirtual指令：用于调用对象的实例方法，根据对象的实际类型进行分派(虚方法分派)，常见
+ invokeinterface指令：用于调用接口方法，会在运行时搜索一个实现了这个接口方法的对象，找出适合的方法进行调用。
+ invokespecial指令：用于调用一些需要特殊处理的实例方法，包括实例初始化方法、私有方法和父类方法
+ invokestatic指令：用于调用类静态方法(static方法)
+ invokedynamic指令：用于在运行时动态解析出调用点限定符所引用的方法，并执行该方法。前面四种分派逻辑都固化在java虚拟机内部，用户无法改变，而此指令的分派逻辑是由用户
  所设定的引导方法决定的。

方法调用指令与数据类型无关，而方法返回指令是根据返回值的类型区分的，包括ireturn(当返回值是boolean、byte、char、short和int时用)、lreturn、freturn、dreturn和areturn，
还有一条return指令供声明为void的方法、实例初始化方法、类和接口的类初始化方法使用。

### 异常处理指令
java中显示抛出异常的操作(throw语句)都有athrow指令实现，还有许多运行时异常会在java虚拟机指令检测到异常时自动抛出。如ArithmeticException
java虚拟机中，处理异常(catch语句)不是由字节码指令实现的(之前曾用jsr和ret指令实现，现在不用了)，而是采用异常表来实现

### 同步指令
java虚拟机支持方法级和方法内部一段指令序列的同步，使用管程(Monitor，锁)来是实现

方法级同步是隐式的，虚拟机可以从方法常量池中的方发表结构中的ACC_SYNCHRONIZED访问标志得知一个方法是否声明为同步方法。当方法调用时，调用指令将会检查方法的
ACC_SYNCHRONIZED访问标志是否被设置，若设置了，执行线程就要先成功持有管程，然后才能执行方法，最后当方法完成时释放管程。
不论方法是否正常完成都会释放

同步一段指令集序列，java虚拟机的指令集中有monitorenter和monitorexit两条指令支持synchronized代码块的语义，正确实现synchronized需要javac编译器与java虚拟机
两者共同协作支持。

```同步代码
void onlyMe(Foo f) { synchronized(f) {
doSomething(); }
}
```
编译后，生成的字节序列：
```
Method void onlyMe(Foo)
0 aload_1  // 将对象f入栈
1 dup  // 复制栈顶元素(即f的引用)
2 astore_2  // 将栈顶元素存储到局部变量表变量槽 2中
3 monitorenter  // 以栈定元素(即f)作为锁，开始同步
4 aload_0  // 将局部变量槽 0(即this指针)的元素入栈
5 invokevirtual #5   // 调用doSomething()方法
8 aload_2  // 将局部变量Slow 2的元素(即f)入栈
9 monitorexit  // 退出同步
10 goto 18  // 方法正常结束，跳转到18返回
13 astore_3  // 从这步开始是异常路径，见下面异常表的Taget 13
14 aload_2  // 将局部变量Slow 2的元素(即f)入栈
15 monitorexit  // 退出同步
16 aload_3  // 将局部变量Slow 3的元素(即异常对象)入栈
17 athrow  // 把异常对象重新抛出给onlyMe()方法的调用者
18 return  // 方法正常返回
Exception table:
FromTo Target Type
  4     10    13 any 
	13    16    13 any
```
如上，为了保证在方法异常完成时monitorenter和monitorexit指令依然可以正确配对执行，编译器自动产生一个异常处理程序，这个异常处理程序声明可处理所有的异常，
他的目的就是用来执行monitorexit指令


## 共有设计，私有实现
<java虚拟机规范>描述了java虚拟机应有的共同程序存储格式：Class文件格式以及字节码指令集。
这些内容与硬件、操作系统和具体的java虚拟机实现之间是完全独立的，虚拟机实现者可能更愿意把他们看做程序在各种java平台实现之间互相安全地交互手段。

理解共有设计与私有实现之间的分界线是有必要的，任何款java虚拟机实现都必须能读取Class文件并精确实现包含在其中的java虚拟机代码的语义。
一个优秀的虚拟机实现，在满足<java虚拟机规范>的约束下对具体实现做出修改和优化也是完全可行的。
只要优化后Class文件依然可以被正确读取，并且包含在其中的语义能得到完整保持，那实现者就可以选择以任何方式去实现这些语义，虚拟机在后台如何处理Class文件完全是实现者
字节的事情，只要他在外部接口上看起来与规范描述的一致即可。

虚拟机实现者可以使用这种伸缩性来让java虚拟机获得更高性能、更低的内存消耗或更好的可移植性，选择哪种特性取决于java虚拟机实现的目标和关注点是什么。
虚拟机实现方式主要有：
+ 将输入的java虚拟机代码在加载时执行或翻译成另一种虚拟机的指令集
+ 将输入的java虚拟机代码在加载时或执行时翻译成宿主机处理程序的本地指令集(即即使编译器代码生成技术)

精确定义的虚拟机行为和目标文件格式，不应当对虚拟机实现者的创造性产生太多的限制，java虚拟机是被设计成可以允许有众多不同的实现，并且各种实现可以在保持兼容性的同时
提供不同的新的、有趣的解决方案

### Class文件结构的发展
20年，Class文件结构一直处于一个相对比较稳定的状态，Class文件的主体结构、字节码指令的语义和数量几乎没有出现变动，所有Class文件格式的改进，都集中在访问标志、
属性表这些设计上原本就是可扩展的数据结构中添加新内容

Class文件格式所具备的平台中立(不依赖于特定硬件及操作系统)、紧凑、稳定和可扩展的特点，是java技术体系实现平台无关、语言无关两项特性的重要支柱


## 虚拟机类加载机制
虚拟机的类加载机制：java虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的java类型

java天生可以动态扩展的语言特性就是依赖运行期动态加载和动态链接这个特点实现的。例如，编写一个面向接口的应用程序，可以等到运行时再指定其实际的实现类，用户可以通过
java预置的或自定义类加载器，让某个本地的应用程序在运行时从网络或其他地方上加载一个二进制流作为其程序代码的一部分。这种动态组装应用的方式目前已广泛应用于java程序
之中，从最基础的Applet、JSP到相对复杂的OSGi技术，都依赖java语言运行期类加载才得以实现。

### 类加载的时机
类生命周期7阶段：加载(Loading)、验证(Verification)、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)和卸载(Unloading)
其中，验证、准备、解析统称为连接(Linking)
加载、验证、准备、初始化和卸载这5阶段必须按部就班地开始(可能互相交叉地混合进行)，
而解析阶段不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持java语言的运行时绑定特性(动态绑定)

<java虚拟机规范>严格规定有且只有6中情况必须立即对类进行“初始化”(而加载、验证、准备自然在此之前开始)：主动引用
+ 遇到new、getstatic、putstatic或invokestatic四条指令时，若类型没有进行过初始化，则需要先触发其初始化阶段。
  能触发这4条指令的典型java代码场景：
    + 使用new关键字实例化对象
        + 读取或设置一个类型的静态字段(被final修饰、已在编译期把结果放入常量池的静态字段除外)
        + 调用一个类型的静态方法
+ 时候用java.lang.reflect包的方法对类型进行反射调用时，若类型没有初始化，需要先触发其初始化
+ 当初始化类时，若发现其父类还没有进行过初始化，需要先触发其父类的初始化
+ 当虚拟机启动时，用户需要指定一个要执行的主类(包含main()方法的类)，虚拟机会先初始化这个主类
+ 当使用jdk7新加入的动态语言支持时，若一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_getStatic、REF_putStatic、REF_invokeStatic、
  REF_newInovkeSpecial四中类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发其初始化
+ 当一个接口中定义了jdk8新加入的默认方法(default修饰的接口方法)时，若有这个接口的实现类发生了初始化，那该接口要在其之前被初始化

查看NotInitialization

对接口加载过程说明：
接口也有初始化过程，编译器会为接口生成<clinit>()类构造器，用于初始化接口中所定义的成员变量。
接口与类真正有所区别是上述的第三种：当一个类在初始化时，要求其父类全都已经初始化过了，但一个接口在初始化时，不要求其父接口全部都完成初始化，只有在真正使用到父接口
时(如引用接口中定义的常量)才会初始化。


### 类加载过程

#### 加载
完成三件事：
+ 通过一个类的全限定名来获取定义此类的二进制字节流
+ 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。
+ 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口

对数组类有所不同，数组类本身不通过类加载器创建，它是由java虚拟机直接在内存中动态构造出来的。
一个数组类(简称C)创建过程遵循规则：
+ 若数组的组件类型(Component Type，指数组去掉一个维度的类型，而不是去掉所有维度)是引用类型，那就递归采用这里定义的加载过程去加载这个数组类型，数组C将被标识在
  加载该组件类型的类加载器的类名称空间上(一个类型必须与类加载器一起确定唯一性)
+ 若数组的组件类型不是引用类型(如int[]数组的组件类型为int)，java虚拟机将会把数组C标记为与引导类加载器关联
+ 数组类的可访问性与它的组件类型的可访问性一致，若组件类型不是引用类型，它的数组类可访问性将默认为public，可被所有的类和接口访问到

加载阶段结束后，java虚拟机外部的二进制字节流就按照虚拟机所设定的格式存储在方法区中。
然后再java堆内存中实例化一个java.lang.Class类的对象，作为程序访问方法区中的类型数据的外部接口。

加载阶段与连接阶段的部分动作(如一部分字节码文件格式验证动作)是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始，但这些加载加载阶段之中进行的动作，仍然属于连接
阶段的一部分，这俩阶段的开始时间仍然保持着固定的先后顺序。

#### 验证
这一阶段的目的是确保Class文件的字节流中包含的信息符合<java虚拟机规范>的全部约束要求，保证这些信息被当做代码运行后不会危害虚拟机自身的安全。

验证阶段大致完成4个阶段的检验动作：文件格式验证、元数据验证、字节码验证和符号引用验证：

1.文件格式验证
验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理。
可能包括：
+ 是否以魔数0xCAFEBABE开头
+ 主、次版本号是否在当前java虚拟机接受范围之内
+ 常量池的常量中是否有不被支持的常量类型(检查常量tag标志)
+ 指向常量的各种索引值中是否有指向不存在的常量或不符合类型的常量。
+ CONSTANT_Utf8_info型的常量是否有不符合UTF-8编码的数据
+ Class文件中各部分及文件本身是否有被删除的或附加的其他信息
  ...

该阶段的主要目的是保证输入的字节流能正确地解析并存储于方法区之内，格式上符合描述一个java类型信息的要求。

2.元数据验证
对字节码描述的信息进行语义分析，以保证其描述的信息符合<java虚拟机规范>要求。
可能包括
+ 这个类是否有父类(除java.lang.Object之外，所有类都应当有父类)
+ 若这个类不是抽象类，是否实现了其父类或接口之中要求实现的所有方法
+ 类中的字段、方法是否与父类产生矛盾(如覆盖了父类的final字段，或出现不符合规则的方法重载，如方法参数都一致，但返回类型却不同等)
  ...

本阶段目的是对类的元数据信息进行语义校验，保证不存在<java虚拟机规范>定义相悖的元数据信息

3.字节码验证
主要目的是通过数据流分析和控制流分析，确定程序语义是合法的、符合逻辑的。
这阶段对类的方法体(Class文件中的Code属性)进行校验分析，保证被校验类的方法在运行时不会做出危害虚拟机安全的行为。
包括：
+ 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作，类型匹配
+ 保证任何跳转指令不会跳到方法体外的字节码指令上
+ 保证方法体的类型转换有效，如继承关系强转是否可行
  ....

由于数据流分析和控制流分析的高度复杂性，java虚拟机设计团队为避免过多的执行时间消耗在字节码验证阶段，jdk6之后的javac编译器和java虚拟机进行了一项联合优化，把尽可
能多的校验辅助措施挪到了javac编译器里进行。
做法是给方法体Code属性的属性表中新增加一项名为"StackMapTable"的新属性，这项属性描述了方法体所有的基本块(Basic Block，指按照控制流拆分的代码块)开始时本地变量
表和操作栈应有的状态，在字节码验证期间，java虚拟机就不需要根据程序推导这些状态的合法性，只需要检查StackMapTable属性中记录是否合法即可。
jdk6提供-XX:-UseSplitVerifier选项来关掉这项优化，或用-XX:+FailOverToOldVerifier要求在类型校验失败时退回到旧类型推导方式校验。
jdk7不在允许退回到原来的类型推导的校验方式

4.符号引用验证
最后一阶段校验发生在虚拟机将符号引用转化为直接引用时，这个转化动作将在连接的第三阶段——解析阶段发生。
符号引用验证可以看做是对类自身以外(常量池中的各种符号引用)的各类信息进行匹配校验，简单说是校验该类是否缺少或被禁止访问它依赖的某些外部类、方法、字段等。
本阶段验证：
+ 符号引用中通过字符串描述的全限定名是否能找到对应的类
+ 在指定类中是否存在符合方法的字段描述符及简单名称所描述的方法和字段
+ 符号引用中的类、字段、方法的可访问性(private、protected、public、<package>)是否可被当前类范文
  ....

主要目的是确保解析行为能正常执行，若不通过，则抛出IncompatibleClassChangeError的子类异常，如IllegalAccessError、NoSuchFieldError、NoSuchMethodError等
如果程序运行的全部代码(包括自己编写的、第三方包中、从外部加载的、动态生成的等所有代码)都已经被反复使用和验证过，在生产环境的实施阶段可以考虑-Xverify:none关闭
大部分的类验证措施，以缩短虚拟机类加载的时间

#### 准备
准备阶段是正式为类中定义的变量(即静态变量，static修饰的)分配内存并设置类变量初始值(零值)的阶段。
个为，这些变量所使用的内存都应当在方法区中分配，但要注意，方法区本身是一个逻辑上的区域。jdk8之后，类变量会随着Class对象一起存放在java堆中。

这时进行内存分配的仅包括类变量，不包括实例变量，实例变量将会在对象实例化时随对象一起分配在java堆中。
如：public static int value = 123;
变量value在准备阶段过后的初始值为0，因为这时尚未开始执行任何java方法。
而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器<clinit>()方法之中，所以把value赋值为123的动作要到类的初始化阶段才会执行。

基本数据类型的零值：
数据类型  零值
int  0
long  0L
short  (short)0
char '\u0000'
byte  (byte)0
boolean  false
float  0.0f
double  0.0d
reference  null

若类字段的字段属性表中存在ConstantValue属性，那在准备阶段变量值就会被初始化为ConstantValue属性所指定的初始值，
如：public static final int value = 123;
编译时javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为123

#### 解析
此阶段，java虚拟机将常量池内的符号引用替换为直接引用。
符号引用，在Class文件中以CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等类型的常量出现。

符号引用与直接引用：
+ 符号引用(Symbolic References)：以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局
  无关，引用的目标并不一定是已经加载到虚拟机内存当中的内容。
+ 直接引用(Direct References)：是可以直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用和虚拟机实现的内存布局直接相关，同一个符号引用在不同
  虚拟机实例上翻译出来的直接引用一般不同。若有了直接引用，那引用的目标必定已经在虚拟机的内存中存在。

<java虚拟机规范>并未规定解析阶段发生的具体时间，只要求了在执行anewarray、checkcast、getfield、getstatic、instanceof、invokedynamic、invokeinterface、
invokespecial、invokestatic、invokevirtual、ldc、ldc_w、ldc2_w、multianewarray、new、putfield和putstatic这17个用于操作符号引用的字节码指令前，先对
他们所使用的符号引用进行解析。

对同一个符号引用进行多次解析请求很常见，除invokedynamic外，虚拟机实现可以对第一次解析的结果进行缓存。
对于invokedynamic，上述规则不成立。当碰到某个前面已经由invokedynamic指令触发过解析的符号引用时，并不意味着这个解析结果对于其他的invokedynamic指令也生效。
因为invokedynamic的目的就是用于动态语言支持，对应的引用称为"动态调用点限定符(DynamicallyComputed Call Site Specifier)"，动态的含义是必须等到程序实际
运行到这条指令时，解析动作才能进行。
所以除invokedynamic以外的上述指令都是可缓存的，可以在完成加载阶段，还没有开始执行代码时提前解析，而invokedynamic不能。

解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行，对应于常量池的CONSTANT_Class_info、CONSTANT_Fieldref_info、
CONSTANT_Methodref_info、CONSTANT_InterfaceMethodref_info、CONSTANT_MethodType_info、CONSTANT_MethodHandle_info、CONSTANT_Dynamic_info和
CONSTANT_InvokeDynamic_info的8种常亮类型。

1.类或接口的解析
假设当前代码所处的类为D，若要把一个从未解析过的符号引用N解析为一个类或接口C的直接引用。
虚拟机完成整个解析的过程有3个步骤：
+ 若C不是一个数组类型，那虚拟机将会把代表N的全限定名传递给D的类加载器去加载这个类C。加载过程，可能由于元数据验证、字节码验证的需要，会触发其他相关类的加载动作，
  例如加载这个类的父类或实现的接口。一旦加载过程有异常，则解析过程失败
+ 若C是一个数组类型，并且数组的元素类型为对象，也就是N的描述符会是类似"[Ljava/lang/Integer"的形式，那将会按照第一点规则加载数组元素类型。若N的描述符如前假设，
  需要加载的元素类型就是"java.lang.Integer"，接着由虚拟机生成一个代表该数组维度和元素的数组对象
+ 若上面两步没有异常，那么C在虚拟机中实际上已经称为一个有效的类或接口了，但在解析完成前还要进行符号引用验证，确认D是否具备对C的访问权限。
  若发现不具备，抛出IllegalAccessError异常

说一个D拥有C的访问权限，意味着一下3条规则至少满足一条：
+ 被访问类C是public的，并且与访问类D处于同一个模块
+ 被访问类C是public的，不与访问类D处于同一个模块，但被访问类C的模块允许类D的模块进行访问
+ 被访问类C不是public的，但是它与访问类D处于同一个包中。

2.字段解析
要解析一个未被解析过得字段符号引用，首先将会对字段表内class_index项中索引的CONSTANT_Class_info符号引用进行解析，及字段所属的类或接口的符号引用。
若在解析这个类或接口符号引用时有异常，都会导致字段符号引用解析的失败。
若解析成功完成，那把这个字段所属的类或接口用C表示，<java虚拟机规范>要求按照下面步骤对C进行后续字段搜索：
+ 若C本身就包含了简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，查找结束
+ 否则，若在C中实现了接口，将会按照继承关系从下往上递归搜索各个接口和他的父接口，若接口中包含了简单名称与字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，
  查找结束
+ 否则，若C不是java.lang.Object，将会按照继承关系从下往上递归搜索其父类，若在父类中包含简单名称和字段描述符都与目标相匹配的字段，则返回这个字段的直接引用，结束
+ 否则，查找失败，抛出NoSuchFieldError异常

若查找到，则将对这个字段进行权限验证，若发现不具备对字段的访问权限，抛出IllegalAccessError异常

3.类方法解析
先解析出方法表的class_index项中索引的方法所属的类或接口的符号引用，若解析成功，依然用C表示这个接口，
虚拟机按照如下步骤进行后续的接口方法搜索：
1)由于Class文件格式中类的方法和接口的方法符号引用的常量类型定义是分开的，若在类的方法表中发现class_index中的索引C是个接口，那直接抛出ImcompatibleChangeError
2)上面通过，在类C中查找是否有简单名称和描述符都与目标相匹配的方法，若有则返回这个方法引用，结束
3)否在，在类C的父类中递归查找是否有简单名称和描述符都与目标相匹配的方法，若有则返回这个方法的直接引用，结束
4)否则，在类C实现的接口列表及他们的父接口之中递归查找是否有简单名称和描述符都与目标相匹配的方法，若存在，则说明C是一个抽象类，这时查找结束，抛出AbstractMethodError
5)否则，宣告失败，抛出NoSuchMethodError异常

最后，若查找成功返回了直接引用，将会对这个方法进行权限验证，若发现不具备对此方法的访问权限，将抛出IllegalAccessError

3.接口方法解析
也需要先解析出接口方法的class_index项中索引的方法所属的类或接口的符号引用，若解析成功，依然用C表示这个接口，
虚拟机按照如下步骤进行后续的接口方法搜索：
1)与类的方法解析相反，若在接口方法表中发现class_index中的索引C是个类而不是接口，那直接抛出ImcompatibleChangeError
2)否在，在接口C中查找是否有简单名称和描述符都与目标相匹配的方法，若有则返回这个方法的直接引用，结束
3)否则，在接口C的父接口中递归查找，直到java.lang.Object类为止，看是否有简单名称和描述符都与目标相匹配的方法，若有则返回方法的直接引用，结束
4)对于规则3，由于java的接口允许多重继承，若C的不同父接口存在多个简单名称和描述符都与目标相匹配的方法，那会从这多个方法中返回其中一个并结束。
5)否则，宣告失败，抛出NoSuchMethodError异常

#### 初始化
直到初始化，java虚拟机才开始执行类中编写的java程序代码，将主导权交给应用程序
此阶段，会根据程序编码制定的主观计划去初始化类变量和其他资源。是执行类构造器<clinit>()方法的过程。
<clinit>()是由javac生成。由编译器自动收集类中所有类变量的赋值动作和静态语句块(static{})中的语句合并产生，顺序是由语句在原文件中出现的顺序，
静态语句块只能访问到定义在静态语句块之前的变量，而定义在它之后的变量，他可以赋值，但是不能访问

<clinit>()方法与类的构造函数(<init>())不同，它不需要显示地调用父类构造器，java虚拟机保证在子类的<clinit>()方法执行前，父类的<clinit>()方法已经执行完毕。
也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作。
<clinit>()对于类或接口并不是必须的，若一个类没有惊天语句块，也没有对变量的赋值操作，那么编译器可以不生成<clinit>()方法
接口的<clinit>()方法不需要限制性父接口的<clinit>()方法，因为只有当父接口中定义的变量被使用时，父接口才会被初始化(由虚拟机保证)。而接口的实现类在初始化时
也一样不会执行接口的<clinit>()方法(同样由虚拟机保证)
java虚拟机必须保证一个类的<clinit>()方法在多线程环境中被正确的加锁同步，只会有一个线程去执行这个类的<clinit>()方法。
参见DeadLoopClass


### 类加载器
java虚拟机设计团队有意把类加载阶段中“通过一个类的全限定名来获取描述该类的二进制字节流”这个动作放到java虚拟机外部去实现，以便让应用程序自己决定
如何获取所需的类。----类加载器(Class Loader)

对于任意一个类，都必须由加载它的类加载器和这个类本身一起共同确立其在java虚拟机中的唯一性，每个类加载器，都有一个独立的类名称空间。
相等指：equals、isAssignableFrom、isInstance、instanceof。
参见ClassLoaderTest

#### 双亲委派模型
站在虚拟机角度，两种类加载器：
+ 启动类加载器(Bootstrap ClassLoader) ，用C++实现，是虚拟机自身一部分
+ 其他所有的类加载器，由java语言实现，独立存在于虚拟机外部，全部继承自java.lang.ClassLoader

站在开发人员角度，类加载划分器更细致。jdk1.2后，java一直保持三层类加载器、双亲委派的类加载架构，
+ 启动类加载器(Bootstrap Class Loader)：负责加载存放在<javahome>/lib下，或-Xbootclasspath指定的，而且是java虚拟机能识别的(按文件名
  识别，如rt.jar、tools.jar)类库加载到虚拟机的内存中。启动类加载器无法被java程序直接引用。
+ 扩展类加载器(Extension Class Loader)：在类sun.misc.Launcher$ExtClassLoader中以java代码的形式实现的。负责加载<javahome>/lib中，
  或被java.ext.dirs系统变量指定。
+ 应用程序类加载器(Application Class Loader)：由sun.misc.Launcher$AppClassLoader实现。也称系统类加载器。加载用户类路径(ClassPath)上
  所有的类库。一般是程序中默认类加载器

类加载器的双亲委派模型(Parents Delegation Model)：
要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器，之间的父子关系是使用组合(Composition)来复用父加载器的代码

双亲微拍模型的工作过程：
若一个类类加载器收到了类加载的请求，首先不会自己去尝试加载这个类，而是把请求委派给父类加载器去完成，每一个层次的类加载器都如此，因此所有的加载请求
最终都应该传递到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求时，子加载器才会尝试自己去完成加载。

好处是：java中的类随着他的类加载器一起具备了一种带有优先级的层次关系。如java.lang.Object类，存放在rt.jar中，无论哪个类加载器加载这个类，最终
都委派给处于模型最顶端的启动类加载器进行加载，因此Object类能保证是同一个类。
参见loadClass方法

#### 破坏双亲委派模型
jdk1.2后才引入双亲委派模型，为了兼容已有代码，无法以技术手段避免loadClass被子类覆盖的可能性，只能添加方法findClass，引导用户编写的类加载逻辑
时尽可能重写此方法，因为loadClass中时双亲委派的具体逻辑，直接重写其可能会破坏已有逻辑。

第二次破坏是由于这个模型自身的缺陷导致。
双亲委派已经很好地解决了各个类加载器协作时基础类型的一致性问题(越基础的类由越上层的加载器进行加载)。
基础类总是作为被用户代码继承、调用的API存在，但程序设计往往没有绝对不变的完美规则，若有基础类型又要调用回用户的代码，怎么办？
如JNDI服务，是java的标准服务，他的代码由启动类加载器完成加载(jdk1.3加入rt.jar)。但JNDI存在的目的就是对资源进行查找和集中管理，需要调用由其他
厂商实现并部署在应用程序的ClassPath下的JNDI服务提供者接口(Service Provider Interface,SPI)的代码，问题是，启动类加载器不可能认识、加载
这些代码，那如何？
为解决此问题，java设计团队只好引入不太优雅设计：线程上下文类加载器(Thread Context ClassLoader)。
可以用setContextClassLoader设定，若创建线程时没有设定，将会从父线程中继承一个，若在应用程序的全局范围内都没有设置过，那这个类加载器默认是
应用程序类加载器。
这样，JNDI服务使用这个线程上下文类加载器去加载所需的SPI服务代码，这是一种父类加载器去请求子类加载器完成类加载的行为，违背双亲委派但无可奈何。
java中的涉及SPI的加载基本上采用这种方式完成，例如JNDI、JDBC、JCE、JAXB和JBI等。
但，当SPI的服务提供了多于一个时，代码只能根据具体提供者的类型来硬编码判断，为了消除这种不优雅的实现，jdk6提供了java.util.ServiceLoader类，
以META-INF/services中的配置信息，辅以责任链模式，才算是给SPI加载提供了一个相对合理的解决方案。--由用户自己控制加载，也就没有BootstrapClassLoader事了?

第三次破坏是由于用户对程序动态性的追求而导致的，指代码热替换(Hot Swap)、模块热部署(Hot Deployment)等。
OSGi已稳定，称为业界事实上的java模块化标准。
OSGi实现模块化热部署的关键是它自定义的类加载器机制的实现，每一个程序模块(OSGi称Bundle)都有一个自己的类加载器，当需要更换一个Bundle时，就把Bundle
连同类加载器一起换掉以实现代码的热替换。OSGi环境下，类加载器不再双亲委派而是进一步发展为网状结构。
当收到类加载请求时，OSGi按照下面顺序进行类搜索：
+ 将以java.*开头的类，委派给父类加载器加载
+ 否则，将委派列表名单内的类，委派给父类加载器加载
+ 否则，将Import列表的类，委派给Export这个类的Bundle的类加载器加载
+ 否则，查找当前Bundle的ClassPath，使用自己的类加载器加载
+ 否则，查找类是否在自己的Fragment Bundle中，若在，则委派给Fragment Bundle的类加载器加载
+ 否则，查找Dynamic Import列表的Bundle，委派给对应的Bundle的类加载器加载
+ 否则，类查找失败。

只要有明确的目的和充分的理由，突破旧有原则无疑是一种创新。
共识，认为OSGi中对类加载器的运用是值得学习的，完全弄懂OSGi的实现，就算是掌握了类加载器的精髓。

#### java模块化系统
jdk9引入java模块化系统(Java Platform Module System,JPMS)。是对java技术的一次重要升级，为了能实现模块化的关键目标——可配置的封装隔离机制，
java虚拟机堆类加载架构也做了变动。

jdk9的模块不仅像之前的jar包那样只是简单地充当代码的容器，还包含一下内容：
+ 依赖其他模块的列表
+ 导出的包列表，即其他模块可以使用的列表
+ 开放的包列表，即其他模块可反射访问模块的列表
+ 使用的服务列表
+ 提供服务的实现列表

可配置的封装隔离机制，首要解决jdk9之前基于类路径来查找依赖的可靠性问题。
此前，若类路径中缺失了运行时依赖的类型，那只能等运行时发生该类型的加载、链接时才会爆出运行时异常。jdk9以后，若启用了模块化进行封装，模块就可以声明
对其他模块的显示依赖，这样java虚拟机就能在启动时验证应用程序开发阶段设定好的依赖关系在运行期是否完备，若有缺失则直接启动失败。

还解决了原来类路径上跨jar文件的public类型的可访问性问题。jdk9提供了更精细的可访问性控制，必须明确声明其中哪些public的类型可以被其他哪一些模块
访问，这种访问控制也主要是在类加载过程中完成。

##### 模块的兼容性
xxxxxxx

##### 模块化下的类加载器
xxxxxxx


## 虚拟机字节码执行引擎
虚拟机是一个相对于物理机的概念，这俩都有代码执行能力，区别是物理机的执行引擎是直接建立在处理器、缓存指令集和操作系统层面上，而虚拟机的执行引擎则是
由软件自行实现，可以不受物理条件制约地定制指令集与执行引擎的结构体系，能执行哪些不被硬件直接支持的指令集格式。

<java虚拟机规范>制定了java虚拟机字节码执行引擎的概念模型，成为各大发行商的java虚拟机执行引擎的统一外观(Facade)。
从外观上，所有java虚拟机的执行引擎输入、输出都是一致的：输入的是字节码二进制流，处理过程是字节码解析执行的等效过程，输出的是执行结果。

### 运行时栈帧结构
java虚拟机以方法作为最基本的执行单元，“栈帧”(Stack Frame)是用于支持虚拟机进行方法调用和方法执行背后的数据结构，也是虚拟机运行时数据区中的
虚拟机栈(Virtual Machine Stack)的栈元素。
栈帧存储了方法的局部变量表、操作数栈、动态链接和方法返回地址等信息。
每个方法从调用开始至执行结束的过程，都对应着一个栈帧在虚拟机栈里从入栈到出栈的过程。
每个栈帧包括了局部变量表、操作数栈、动态连接、方法返回地址和一些额外的附加信息。
在编译java程序源码时，栈帧中需要多大的局部变量表，需要多深的操作数栈就已经被分析计算出来，并写入到方法表的Code属性之中。

对于执行引擎来讲，在活动线程中，只有位于栈顶的方法才是在运行的，只有位于栈顶的栈帧才是生效的，被称为当前栈帧(Current Stack Frame)，与这个栈帧
关联的方法是当前方法(Current Method)。执行引擎所运行的所有字节码指令都只对当前栈帧进行操作。

#### 局部变量表(Local Variables Table)
是一组变量值的存储空间，用于存放方法参数和方法内部定义的局部变量。
java程序被编译为Class时，就在方法的Code属性的max_locals数据项中确定了该方法所需分配的局部变量表的最大容量。
局部变量表的容量以变量槽(Variable Slot)为最小单位，规范只是导向性说到每个变量槽都应该能存放一个boolean、byte、char、short、int、float、
reference或returnAddress8种类型数据，都可以用32位或更小的物理内存来存放。
一个变量槽可以存放一个32位以内的数据类型，java中占用不超过32位存储空间的数据类型有boolean、byte、char、short、int、float、reference和
returnAddres这8种类型。
reference类型表示对一个对象实例的引用，一般，虚拟机实现至少应当能通过这个引用做到两件事：
+ 从根据引用直接或间接地查找到对象在java堆中的数据存放的起始地址或索引
+ 根据引用直接或间接地查找到对象所属数据类型在方法区中的存储类型信息，否则将无法实现规范中定义的语法约定。
  returnAddress类型已很少见，现在已全部改为采用异常表实现

对于64位的数据类型，java虚拟机会以告慰对齐的方式为其分配两个连续的变量槽空间。把long和double数据类型分割存储做法与“long和double的费原子性协定”
中允许把一次long和double数据类型读写分割为两次32位读写的做法类似。

java虚拟机通过索引定位的方式使用局部变量表，从0开始。若访问32位数据类型的变量，n代表使用n个变量槽，若访问64位数据类型的变量，会同时用n和n+1变量槽。

当一个方法被调用时，java虚拟机会使用局部变量表来完成参数值到参数变量列表的传递过程，即实参到形参的传递。
若是实例方法，则局部变量表的第0位索引的变量槽默认是用于传递方法所属对象实例的引用，在方法中可以用this访问这个隐含的参数。
参数表分配完毕后，再根据方法体内部定义的变量顺序和作用域分配其余的变量槽。

为尽可能节省栈帧的内存空间，局部变量表中的变量槽可以重用。不过，也有副作用，如某些情况下变量槽的复用会直接影响到垃圾收集。
参见AffectGc
若遇到一个方法，其后面的代码有一些耗时很长的操作，而前面又定义了占用大量内存但实际上已经不会再使用的变量，手动将其设置为null(把变量对应的局部变量
槽清空)，便不见得是一个绝对无意义的操作。可以作为一种在极特殊情形(对象占用内存大、此方法的栈帧长时间不能被回收、方法调用次数达不到即时编译器的编译条件)下的技巧。
以恰当的变量作用域来控制变量回收时间

类变量有两次赋值过程：一次在准别阶段，赋予系统初始值；另一次在初始化阶段，赋予程序的初始值。因此，即使再初始化阶段程序员没有为类变量赋值也没关系，
类变量仍有一个确定的初始值。
而局部变量不一样，若它定义了但没有赋初始值，就完全不能使用。--这就是局部变量使用之前必须有赋值动作。

#### 操作数栈(Operand Stack)
操作栈，是一个后入献出(Last In First Out,LIFO)的栈。最大深度也在编译时写入到Code属性的max_stacks数据项中。
操作数栈的每一个元素都可以是包括long和double在内的任意java数据类型。32位数据类型所占的栈容量为1，64位为2.
javac编译器的数据流分析工作保证了在方法执行的任何时候，操作数栈的深度都不会超过在max_stacks数据项中设定的最大值

当一个方法刚开始执行时，操作数栈是空，在方法的执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，出站和入栈。
例如，iadd，在运行时要求操作数栈中最接近栈顶的俩元素已经存入了俩int型的数值，当执行这个指令时，会把这俩int出站并相加，然后结果重新入栈

操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，在编译程序代码时，编译器必须要严格保证，在类校验阶段的数据流分析还要再次验证。

在概念模型中，两个不同栈帧作为不同方法的虚拟机栈的元素，是完全相互独立的。但在实现中会有优化，令两个栈帧出现部分重叠。
让下面栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起，这样不仅节约空间，更重要的是在进行方法调用时可以直接公用一部分数据，无需进行额外的
参数赋值传递了。

#### 动态连接
每个栈帧都包含了一个指向运行时常量池中该栈帧所属方法的引用，为了支持方法调用过程中的动态连接(Dynamic Linking)。
Clas文件的常量池中存有大量的符号引用，字节码中的方法调用指令就以常量池里指向方法的符号引用作为参数。
这些符号引用一部分会在类加载阶段或第一次使用时被转化为直接引用，称为静态解析。另一部分在每一次运行期间转化为直接引用，称为动态连接。

#### 方法返回地址
当一个方法开始执行后，只有两种方式退出：
+ 正常调用完成(Normal Method Invocation Completion)：执行引擎遇到任意一个方法返回的字节码指令，这时可能会有返回值传递给上层的方法调用者，
  方法是否有返回值以及返回值的类型将根据遇到何种方法返回指令来决定
+ 异常调用完成(Abrupt Method Invocation Completion)：在方法执行过程中遇到异常，并且这个异常没有在方法体内得到妥善处理。只要在本方法的异常
  表中没有搜索到匹配的异常处理器，就会导致方法退出。不会给它上层调用者提供任何返回值

在方法退出后，必须返回到最初方法被调用时的位置，程序才能继续执行，方法返回时可能需要在栈帧中保存一些信息，用来帮助恢复它上层主调方法的执行状态。
一般，方法正常退出时，主调方法的PC计数器的值可以作为返回地址，栈帧中很可能会保存这个计数器值。而方法异常退出时，返回地址要通过异常处理器表来确定，
栈帧中一般不会保存这部分信息。

方法退出的过程等同于把当前栈帧出栈，退出时可能执行的操作有：恢复上层方法的局部变量表和操作数栈，把返回值(若有)压入调用者栈帧的操作数栈中，调整PC
计数器的值以指向方法调用指令后面的一条指令等。

#### 附加信息
如与调试、性能收集相关信息等。
一般会把动态连接、方法返回地址与其他附加信息归为一类，称为栈帧信息

### 方法调用
方法调用阶段唯一任务就是确定被调用方法的版本(即调用哪一个方法)，暂时还未涉及方法内部的具体运行过程。
Class文件的编译过程中不包含传统程序语言编译的连接步骤，一切方法调用在Class文件里存储的都只是符号引用，而不是方法在实际运行时内存布局的入口地址(即
直接引用)。这特性给java带来了更强大的动态扩展能力，但也使得java方法调用过程变得相对复杂，某些调用需在类加载期间，甚至到运行期才鞥呢确定目标方法的
直接引用。

#### 解析
所有方法调用的目标方法在Class文件里都是一个常量池中的符号引用，在类加载的解析阶段，会将其中一部分符号引用转化为直接引用，这种解析的前提是：方法在
程序运行之前就有一个可确定的调用版本，并且这个方法的调用版本在运行期是不可改变的。这类方法的调用被称为解析(Resolution)

java语言中符合“编译期可知，运行期不可变”要求的方法，主要是静态方法和私有方法，前者与类直接关联，后者在外部不可被方法。他们不可能通过集成或别的方式
重写出其他版本，适合在类加载阶段进行解析

调用不同类型的方法，字节码指令集里设计了不同的指令，5条方法调用字节码指令：
+ invokestatic：用于调用静态方法
+ invokespecial：用于调用实例构造器<init>()方法、私有方法和父类中方法
+ invokevirtual：用于调用所有虚方法
+ invokeinterface：用于调用接口方法，会在运行时再确定一个实现该接口的对象
+ invokedynamic：现在运行时动态解析出调用点限定符所引用的方法，然后再执行该方法。前面4个，分派逻辑都固化在java虚拟机内部，而本指令的分派逻辑是
  由用户设定的引导方法来决定

只要能被invokestatic和invokespecial指令调用的方法，
java中对应的是静态方法、私有方法、实例构造器、父类方法，被final修饰的方法(尽管他使用invokevirtual指令)，
都可以在类加载的解析阶段中确定唯一的调用版本，将符号引用解析为该方法的直接引用。被称为非虚方法(Non-Virtual Method)

参见StaticResolution
规范中定义了被final修饰的方法是一种非虚方法
解析调用一定是个静态的过程，在编译期间完全确定，在类加载的解析阶段就会把涉及的符号引用全部转变为明确的直接引用，不必延迟到运行期再去完成。

#### 分派
java面向对象，3个基本特征：继承、封装、多态。
分派调用过程更多揭示多态性特征，在java虚拟机中如何实现。

1. 静态分派
   Method Overload Resolution。
   参见StaticDispatch
   解析与分派这两者关系并不是二选一，他们是在不同层次上去筛选、确定目标方法的过程。如，静态方法会在编译期确定、在类加载期进行解析，而静态方法显然也可以拥有重载
   版本，选择重载版本的过程也是通过静态分派完成的。

2. 动态分派
   参见DynamicDispatch
```javap输出
public static void main(java.lang.String[]); Code:
Stack=2, Locals=3, Args_size=1
0: new #16; //class org/fenixsoft/polymorphic/DynamicDispatch$Man
3: dup
4: invokespecial #18; //Method org/fenixsoft/polymorphic/Dynamic Dispatch$Man."<init>":()V
7: astore_1
8: new #19; //class org/fenixsoft/polymorphic/DynamicDispatch$Woman
11: dup
12: invokespecial #21; //Method org/fenixsoft/polymorphic/DynamicDispatch$Woman."<init>":()V
15: astore_2
16: aload_1
17: invokevirtual #22; //Method org/fenixsoft/polymorphic/Dynamic Dispatch$Human.sayHello:()V
20: aload_2
21: invokevirtual #22; //Method org/fenixsoft/polymorphic/Dynamic Dispatch$Human.sayHello:()V
24: new #19; //class org/fenixsoft/polymorphic/DynamicDispatch$Woman
27: dup
28: invokespecial #21; //Method org/fenixsoft/polymorphic/DynamicDispatch$Woman."<init>":()V
31: astore_1
32: aload_1
33: invokevirtual #22; //Method org/fenixsoft/polymorphic/Dynamic Dispatch$Human.sayHello:()V
36: return
```
0~15行的字节码时准备动作，建立man和woman的内存空间、调用Man和Woman类型的实例构造器，将俩实例引用存放在第1、2个局部变量表的变量槽中，对应java源码：
Human man = new Man()
Human woman = new Woman()
16~21中，16和20的aload分别把刚创建的俩对象的引用压到栈顶，这俩对象时将要执行的sayHello()方法的所有者，称为接收者(Receiver)；17和21是方法调用，
都完全一样，但最终执行的目标方法不同。
正是因为invokevirtual指令执行的第一步就是在运行期确定接收者的实际类型，所以两次调用中invokevirtual指令并不是把常量池中方法的符号引用解析到直接引用
上就结束，还会根据方法接收者的实际类型来选择方法版本，此过程是java语言中方法重写的本质。把这种在运行期根据实际类型确定方法执行版本的分派过程称为动态分派。

规范中invokevirtual指令的运行时解析过程：
1)找到操作数栈顶的第一个元素所指向的对象的实际类型，记作C
2)若在类型C中找到与常量中的描述符和简单名称都相符的方法，则进行访问权限校验，若通过则返回这个方法的直接引用，查找结束；不通过则IllegalAccessError
3)否则按照继承关系从下往上一次对C的各个父类进行第二步的搜索和验证过程。
4)若始终没有找到合适的方法，则AbstractMethodError异常

java中只有虚方法存在，字段永远不可能是虚的，字段永远不参与多态，哪个累的方法访问某个名字的字段时，改名字指向的就是这个类能看到的那个字段。若子类与父类同名字段，
虽然在子类的内存中有俩字段，但子类的字段会遮蔽父类的同名字段。

3. 单分派与多分派
   方法的接收者与方法的参数统称为方法的宗量，根据分派基于多少种宗量，可以将分派划分为单分派和多分派。
   单分派是根据一个宗量对目标方法进行选择，多分派则是根据多于一个宗量对目标方法进行选择。
   参见Dispatch
   编译阶段中编译器的选择过程，静态分派过程，这时选择目标方法的依据有两点：一是静态类型是Father还是Son，二是方法参数是QQ还是360。这次选择结果的最终产物是产生两条
   inokevirtual指令，两条的参数分别是常量池中指向Father::hardChoice(360)和Father::hardChoice(QQ)方法的符号引用。因为是根据两个宗量进行选择， 所以java语言
   的静态分派属于多分派类型。
   运行阶段中虚拟机的选择，动态分派过程。执行son.hardChoice(new QQ())时，准确地说，是在执行这行代码所对应的invokevirtual时，由于编译期已经决定目标方法的签名
   必须为hardChoice(QQ)，虚拟机此时不会关心传来的参数是哪种QQ，因为这时参数的静态类型、实际类型都对方法的选择不会构成任何影响，唯一可以影响虚拟机选择的因素只有该
   方法的接受者的实际类型是Father还是Son。因为只一个宗量作为选择依据，所以java语言的动态分派属于单分派类型

总结：如今(java12)的java怨言是一门静态多分派、动态单分派的语言。

4. 虚拟机动态分派的实现
   动态分派是执行非常频繁的动作，而且版本选择过程需要运行时在接收者类型的方法元数据中搜索合适的目标方法，因此java虚拟机实现基于执行性能的考虑，真正运行时一般不会如此
   频繁地去反复搜搜类型元数据。一种优化手段是为类型在方法区建立一个虚方法表(Virtual Method Table，vtable，对应的在invokeinterface执行时也会用到接口方法表
   Interface Method Talbe,itable)，使用虚方法表索引来代替元数据查找以提高性能。

虚方法表中存放着各个方法的实际入口地址。若某个方法在子类中没有重写，那子类的虚方法表中的地址入口和父类相同方法的地址入口一致，都指向父类的实现入口。
若子类中重写了方法，子类虚方法表中的地址也会被替换为指向子类实现版本的入口地址。

为了程序实现方便，具有相同签名的方法，在父类、子类的虚方法表中都应当具有样的索引序号，这样当类型变换时，仅需要变更查找的虚方法表，就可以从不同的虚方法表中按
索引转换出所需的入口地址。
虚方法表一般在类加载的连接阶段进行初始化，准备了类的变量初始值后，虚拟机会把该类的虚方法表也一同初始化完毕。

由于java对象里的方法默认(即不用final修饰)就是虚方法，虚拟机除了使用虚方法表外，为了进一步提高性能，还会使用类型继承关系分析(Class Hierachy Analysis,(CHA))、
守护内联(Guarded Inlining)、内联缓存(Inline Cache)等多种非稳定的激进优化来争取更大的性能空间。
--一种缓存，省得每次执行动态分配时都从栈顶拿到对象实际类型然后还用从实际类型的元数据中查找对应的方法，以及向上递归查找。


## 动态类型语言支持
jdk7新增字节码，invokedynamic指令。是jdk7的项目目标：实现动态类型语言(Dynamically Typed Language)支持而进行的改进之一，也是为jdk8可以顺利实现Lambda表达式
而做的技术储备。

### 动态类型语言
动态类型语言的关键特征：他的类型检查的主体过程是在运行期而不是编译期进行。APL、Clojure、Erlang、Groovy、JavaScript、Lisp、Lua、PHP、Prolog、Python、Ruby、
Smaltak、Tcl等等。
静态语言，在编译期就进行类型检查过程的语言，如C++和java等

obj.println("hello world")
类型检查，java方法调用，必须是声明的静态类型或父类，不能是其他类型，而javaScript中，只要这种类型包含方法即可。
根因是，java语言在编译期已将println(String)方法完整的符号引用(本例为一项CONSTANT_InterfaceMethodref_info常量)生成出来，并作为方法调用指令的参数存储到Class
文件中。这个符号引用包含了该方法定义在哪个具体类型之中、方法的名字以及参数顺序、参数类型和方法返回值等信息。通过这个符号引用，java虚拟机可以翻译出该方法的直接
引用。
而javaScript等动态类型语言与java的一个核心差异是变量obj本身并没有类型，变量obj的值才具有类型，所以编译器在编译时最多只能确定方法名称、参数、返回值这些信息，
而不回去确定方法所在的具体类型(即方法接收者不固定)。变量无类型而变量值才有类型，这个特点是动态类型语言的一个核心特征。

静态类型语言能在编译期确定变量类型，显著好处是编译器可以提供全面严谨的类型检查，这样与数据类型相关的潜在问题能在编码时被及时发现，利于稳定性及让项目容易达到更大
的规模。
而动态类型语言在运行期才确定类型，可以为开发人员提供极大灵活性，某些在静态类型语言中要花大量臃肿代码实现的功能，由动态类型语言实现可能会清晰简洁，开发效率提升

### java与动态类型
java虚拟机层面对动态类型语言支持一致有所欠缺，表现在方法调用方面：jdk7以前，字节码指令集中，4条方法调用指令(invokevirtual、invokespecial、invokestatic、
invokeinterface)的第一个参数都是被调用的方法的符号引用(CONSTANT_Methodref_info或CONSTANT_InterfaceMethodref_info常量)，方法的符号引用
在编译时产生，而动态类型语言只有在运行期才能确定方法的接收者。这样，只能曲线救国(如编译时留个占位符类型，运行时动态生成字节码实现具体类型到占位符类型的适配)来
实现，但这样会让动态类型语言实现的复杂度增加，也会带来额外的性能和内存开销。
最严重的性能瓶颈在于动态类型方法调用时，由于无法确定调用对象的静态类型，而导致的方法内联无法有效进行。尽管也可以用调用点缓存缓解，但并不是本质。
譬如：
var arrays = {"abc",new ObjectX(), 123, Dog, Cat, Car..}
for(item in arrays){
item.sayHello();
}
动态类型语言下这代码没问题，但由于在运行时arrays中的元素可以是任意类型，即使他们的类型中都有sayHello方法，也肯定无法在编译优化时就确定具体的sayHello的代码
在哪里，编译器只能不停编译他所遇见的每个sayHello方法，并缓存起来供执行时选择、调用和内联，若arrays数组中不同类型的对象很多，必然对内联缓存产生很大压力。
所以这种动态类型方法调用的底层问题终归应当在java虚拟机层次上去解决。这边是jdk7invokedynamic以及java.lang.inovke包出现的背景

### java.lang.inovke包
此包的主要目的是在之前单纯依靠符号引用来确定调用的目标方法这条路之外，提供一种新的动态确定目标方法的机制，称为方法句柄(Method Handle)。
在拥有方法句柄后，java语言也可以拥有类似于函数指针或委托的方法别名这样的工具了。

参见MethodHandleTest
仅站在java语言的角度看，MethodHandle和Refleciton区别：
+ 本质上都是在模拟方法调用，但Refleciton是在模拟java代码层次的方法调用，而MethodHandle是在模拟字节码层次的方法调用。在MethodHandles.Loopup上的3个方法
  findStatic()、findVirtual()、findSpecial()对应于invokestatic、invokevirtual(以及invokeinterface)、invokespecial这几条字节码指令的执行权限
  校验行为，而这些底层细节在使用Reflection API时不用关心的。
+ Reflection中的java.lang.reflect.Method对象远比MethodHandle机制中的java.lang.invoke.MethodHandle对象所包含的信息来得多。
  前者是方法在java端的全面映射，包含了方法的签名、描述符以及方法属性表中各种属性的java端表示方式，还包含执行权限等的运行期信息。
  而后者仅包含执行该方法的相关信息。Reflection是重量级，MethodHandle是轻量级
+ 由于MethdoHandle是对字节码的方法指令调用的模拟，那理论上虚拟机在这方面做的各种优化(如方法内联)，在MethodHandle上也应当可以采用类似思路去支持(目前还在
  完善中)，而通过反射调用方法则几乎不可能直接去实施各类调用点优化措施。

最关键的一点在于，去掉前提“仅站在java语言的角度看”之后，Refleciton API的设计目标是只为java语言服务的，而MethodHandle设计为可服务于所有java虚拟机之上
的语言，其中也包括java，而且java在这里不是主角

### invokedynamic指令
某种意义上可以说invokedynamic指令与MethodHandle机制的作用是一样的，都是为了解决原有4条invoke*指令方法分派规则完全固化在虚拟机之中的问题，把如何查找
目标方法的决定权从虚拟机转嫁到具体用户代码之中，让用户有更高的自由度。
只是一个用上层代码和API来实现，另一个用字节码和Class中其他属性、常量来完成。

每一处含有invokedynamic指令的位置都被称作"动态调用点(Dynamically Computed Call Site)"，第一个参数不再是代表方法符号引用的CONSTANT_Methodref_info常量，
而是CONSTANT_InvokeDynamic_info常量，从这个常量可以得到3项信息：引导方法(Bootstrap Method,该方法存放在BootstrapMethods属性中)、方法类型(MethodType)
和名称。
引导方法时固定的参数，并且返回值规定是java.lang.invoke.CallSite对象，代表真正要执行的目标方法调用。
根据CONSTANT_InvokeDynamic_info常量中提供的信息，虚拟机可以找到并执行引导方法，从而获得一个CallSite对象，最终调用到要执行的目标方法上。
参见InvokeDynamic
invokedynamic指令面向的主要服务对象并非java语言，而是其他java虚拟机之上的其他动态类型语言。jdk7还没有办法生成invokedynamic指令的字节码，所以变通，用INDY工具(
http://blogs.oracle.com/jrose/entry/a_modest_tool_for_writing)完成最终需要的字节码。InvokeDynamic是要被INDY工具读取的。
把InvokeDynamic编译，再用INDY转换后重新生成的字节码如下
```InvokeDynamic指令演示
Constant pool:
#121 = NameAndType #33:#30 // testMethod:(Ljava/lang/String;)V 
#123 = InvokeDynamic #0:#121 // #0:testMethod:(Ljava/lang/String;)V

public static void main(java.lang.String[]) throws java.lang.Throwable; 
Code:
stack=2, locals=1, args_size=1
0: ldc #23 // String abc
2: invokedynamic #123, 0 // InvokeDynamic #0:testMethod: (Ljava/lang/String;)V 
7: nop
8: return

public static java.lang.invoke.CallSite BootstrapMethod(java.lang.invoke.Method Handles$Lookup, java.lang.Strin 
Code:
    stack=6, locals=3, args_size=3
0: new  #63 // class java/lang/invoke/ConstantCallSite
3: dup
4: aload_0
5: ldc  #1 // class org/fenixsoft/InvokeDynamicTest
7: aload_1
8: aload_2
9: invokevirtual #65 // Method java/lang/invoke/MethodHandles$Lookup.findStatic:(Ljava/lang/Cl
12: invokespecial #71  // Method java/lang/invoke/ConstantCallSite. "<init>":(Ljava/lang/invoke/M
15: areturn
```
从main中可见，原本的方法调用指令已经被替换为invokedynamic了，参数为第123项常量(第二个值为0的参数，在虚拟机中不会直接用到，与invokeinterface指令那个
值为0的参数一样是占位用的，目的是为了个常量池缓存流出足够的空间)
从常量池可见，第123项常量显示“#123 = InvokeDynamic #0:#121”，说明它是一项CONSTANT_InvokeDynamic_info类型常量，常量值前面的#0代表引导方法取
BootstrapMethods属性表的第0项(javap没列出属性表的内容，不过示例仅有一个引导方法即BootstrapMethod())，后面的#121代表引用第121项类型为
CONSTANT_NameAndType_info的常量，从这个常量中可获取方法名称和描述符，即"testMethod:(Ljava/lang/String;)V"
再看BootstrapMethods()是由INDY产生，逻辑是调用MethodHandles$Lookup的findStatic，产生testMethod()方法的MethodHandle，然后用它创建一个
ConstantCallSite对象，然后这个对象返回给invokedynamic指令实现对testMethod()方法的调用，invokedynamic指令的调用过程到此结束。

### 实战：掌控方法分派规则
invokedynamic指令与其他4条invoke*指令的最大区别是它的分派逻辑不是由虚拟机决定的，而是由程序员决定的。


## 基于栈的字节码解释执行引擎
将分析在概念模型下的java虚拟机解释执行字节码时，其执行引擎如何工作。
实际虚拟机实现中，如hostSpot的魔板解释器工作时，并不是按照概念模型一板一眼地进行机械式计算，而是动态产生每条字节码对应的汇编代码来运行，与概念模型中执行
过程的差异很大，但结果却能保证一致

### 解释执行

大部分的程序代码转换成物理机的目标代码或虚拟机能执行的指令集之前，都需要经过下列步骤。
下面的分支是传统编译原理中程序代码到目标机器代码的生成过程；中间分支，是解释执行的过程：
程序源码->词法分析->单词流->    语法分析
|
解释执行<-解释器<-指令流(可选)<-抽象语法树
|
目标代码<-生成器<-中间代码(可选)<-优化器(可选)

现在高级语言虚拟机(HLLVM)的代码执行过程，大体都遵循这种符合现代经典编译原理的思路，在执行前对程序源码进行词法分析和语法分析处理，把源码转化为抽象语法树(Abstract
Syntax Tree, AST)。
对于具体语言的实现来说，词法、语法分析以致后面的优化器和目标代码生活曾器都可以选择独立于执行引擎，形成一个完整意义的编译器去实现，如C/C++。
也可以选择把其中一部分步骤(如生成抽象语法树之前的步骤)时限为一个半独立的编译器，如java语言。
又或者把这些步骤和执行引擎全部集中封装在一个封闭的黑匣子中，如JavaScript执行引擎

java语言中，javac编译器完成了程序代码经过词法分析、语法分析到抽象语法树，再遍历语法树生成线性的字节码指令流的过程。因为这一部分动作实在java虚拟机之外进行的，而
解释器在虚拟机内部，所以java程序的编译就是半独立的实现。

### 基于栈的指令集与基于寄存器的指令集
javac编译器输出的字节码指令流，基本上是一种基于栈的指令集架构(Instruction Set Architecture, ISA)，字节码指令流里的指令大部分都是零地址指令，依赖操作数栈进行
工作。
另一套常用指令级架构是基于寄存器的指令集，典型的就是x86的二地址指令集，这些指令依赖寄存器进行工作。

例如：1+1
基于栈的指令集：
```
iconst_1
iconst_1
iadd
istore_0
```
两条iconst_1把两个常量1压入栈后，iadd把栈顶俩值出栈、相加，然后把结果放回栈顶，最后istore_0把栈顶的值放入局部变量表的第0个变量槽中。
这种指令流中的指令通常都被不带参数，使用操作数栈中的数据作为指令的运算输入，指令的运算结果也存在操作数栈中。

基于寄存器的指令集：
```
mov  eax, 1
add  eax, 1
```
mov把EAX寄存器的值设为1，add把这个值加1，结果保存在EAX寄存器里。
这种二地址指令时x86指令集中的主流，每个指令都貋两个单独的输入参数，依赖于寄存器来方法和存储数据

基于栈的指令集主要优点是可移植，因为寄存器由硬件直接提供，程序直接依赖这些硬件寄存器则不可避免地收到硬件的约束。若用栈架构的指令集，用户程序不会直接用到这些寄存
器，那就可以由虚拟机实现来自行决定把一些访问最频繁的数据(程序计数器、栈顶缓存等)放到寄存器中以获取尽量好的性能，这样实现也更简单一些。
栈架构指令集还有一些优点，如代码相对更加紧凑(字节码中每个字节都对应一条指令，而多地址指令集中还需要存放参数)、编译器实现更加简单(不需要考虑空间分配问题，所需
空间都在粘上操作)等

栈架构指令集主要缺点是理论上执行速度相对来说稍慢，所有主流物理机的指令集都是寄存架构也从侧面印证了。
不过这里的执行速度要局限在解释执行的状态下，若经过即使编译器输出成物理机上的汇编指令流，就与虚拟机采用哪种指令集架构没关系了。。--汇编后就是机器的二地址指令流?

在解释执行时，站架构指令集完成相同功能所需的指令数量一般会比寄存器架构多，因为出栈、入栈操作本身就产生相当大量的指令。更重啊哟的是栈实现在内存中，频繁的栈访问
也意味着频繁的内存访问，相对处理器，内存始终是执行速度瓶颈。尽管虚拟机可以采取栈顶缓存的优化，把最常用的操作映射到寄存器中避免直接内存访问，但也只是优化措施
恶如不是解决本质问题的方法，因此由于指令数据量和内存访问的原因，导致了栈架构指令集的执行速速会相对慢一些

### 基于栈的解释器执行过程
虚拟机执行的概念模型
// java
```
public int calc(){
  int a = 100;
	int b = 200;
	int c = 300;
	return (a + b) *c
}
```

// bytecode
```
public int calc(); 
Code:
Stack=2, Locals=4, Args_size=1   --需要深度为2的操作数栈和4个变量槽的局部变量空间
-- 偏移  助记符
0: bipush 100  --将单字节的整型常量值(-128~127)推入操作数栈顶，跟随一个参数，指明推送的常量值100，执行时pc=0
2: istore_1  --将操作数栈顶的整型值出栈并存放到第一个局部变量槽中，执行时pc=2
3: sipush 200
6: istore_2
7: sipush 300 
10: istore_3
11: iload_1  --将局部变量表第1个变量槽中的整型值复制到操作数栈顶，执行时pc=11
12: iload_2  --把第2个变量槽的整型值入栈
13: iadd  --将操作数栈中头俩栈顶元素出栈，做整型加法，将结果重新入栈。
14: iload_3  --把第三个局部变量槽中的300入栈到操作数栈中
15: imul  --将操作数栈中头俩栈顶元素出栈，做整型乘法，将结果重新入栈
16: ireturn  --结束方法执行并将操作数栈顶的整型值返回方法调用者。
```

可从这段程序的执行中看出栈结构指令集的一般运行过程，整个运算过程的中间变量都以操作数栈的出栈、入栈为信息交换途径。

实际情况中虚拟机中解释器和即时编译器都会对输入的字节码进行优化，即使解释器中也不是按照字节码指令去逐条执行的。如hotSpot虚拟机中，有很多以fast_开头的非标准
字节码指令用于合并、替换输入的字节码以提升解释执行性能，即时编译器的优化手段更多。


## 类加载及执行子系统的案例与实战
在Class文件格式与执行引擎这部分，程序能直接参与的内容不多，Class文件以何种格式存储，类型何时加载、如何连接，以及虚拟机如何执行字节码指令都由虚拟机直接控制
的行为，用户程序无法对其进行改变。
能通过程序进行操作的，主要是字节码生成与类加载器这两部分功能。

### Tomcat：正统的类加载器架构
主流java web服务器，如Tomcat、Jetty、WebLogic、WebSphere等服务器，都实现了自己定义的类加载器。
一个功能健全的Web服务器，要解决如下问题：
+ 部署在同一个服务器上的两个Web应用程序所使用的java类库可以实现相互隔离。俩个不同应用程序可能依赖同一个第三方类库的不同版本，服务器应当能保证两个独立应用程序
  的类库可以互相独立使用。
+ 部署在同一个服务器上的两个web应用程序所使用的java类库可以互相共享。不至于加载多份到内存及方法区
+ 服务器需要尽可能地保证自身的安全不受部署的Web应用程序影响。一般服务器本身也有类库依赖问题，基于安全考虑，服务器所使用的类库应该与应用程序的类库互相独立
+ 支持JSP应用的web服务器，需要支持HotSwap功能。JSP文件最终要被编译成java的Class文件才能被虚拟机执行，动态感知更新，无需重启。

基于上述问题，在部署web应用时，单独一个ClassPath不能满足需求，所以各种web服务器都提供了好几个不同含义的ClassPath路径供用户存放第三方类库，这些路径一般
以lib或classes命名。放置到不同路径中的类库，具备不同的访问范围和服务对象，通常每个目录都会有一个相应的自定义类加载去加载放置在里面的java类库。

在Tomcat目录结构中(tomcat6以前)，可以设置3组目录(/common/*、/server/*、/shared/*，但默认不一定是开放的，可能只有/lib/*目录存在)用于存放java类库，还加上Web应用
程序自身的"/WEB-INF/*"目录。
每一组都有独立含义：
+ /common中：类库可被Tomcat和所有的Web应用程序共同使用
+ /server中：类库可被Tomcat使用，对所有Web应用程序不可见
+ /shared中：类库可被所有Web应用程序共同使用，但对Tomcat不可见
+ /WebApp/WEB-INFO中：类库仅可被该Web应用程序使用，对Tomcat和其他Web应用程序不可见

为了支持这套目录结构，并对目录的类库进行加载和隔离，tomcat自定义了许多类加载器，按照经典的双亲委派模型实现
Bootstrap ClassLoader
|
Extension ClassLoader
|
Application ClassLoader
|
Commaon ClassLoader
|				                 |
Catalina ClassLoader     Shared ClassLoader
|
Webapp ClassLoader
|
JasperLoader
Common、Catalina、Shared和Webapp类加载器是Tomcat自定义的，分别加载/common/*、/server/*、/shared/*、WebApp/WEB-INF/*中的java类库。
WebApp类加载器和JSP类加载器通常还会有多个实例，每个Web应用程序对应一个WebApp类加载器，每一个JSP文件对应一个JasperLoader

可以看到Common能加载的类都可以被Catalina和Shared类加载使用，而Catalina和Shared类加载器自己能加载的类则与对方隔离。
WebApp可以使用Shared类加载器加载到的类，但各个WebApp类加载器实例之间相互隔离。JasperLoader的加载范围仅仅是这个JSP文件所编译出的Class文件，存在的
目的就是为了丢弃：当服务器检测到JSP文件被修改时，会替换掉目前的JasperLoader的实例，并通过再建立一个新的JSP类加载器实现JSP文件的HotSwap功能

tomact6简化了目录结构，只有指定了tomcat/conf/catalina.properties的server.loader和share.loader项才会真正建立Catalina和Shared类加载器，否则用
Common类加载器。默认没有配置，那么就是一个/lib目录，相当于以前的/common，是为了简化大多数的部署场景所做的一项易用性改进。用户可以修改。

### OSGi：灵活的类加载器架构
OSGi(Open Service Gateway Initiative)是OSGi联盟制定的一个基于java语言的动态模块化规范。目的是使服务提供商通过住宅网关为各种家用智能设备提供服务。
已成为java中事实上的动态模块化标准，已有Equinox、Felix等成熟的实现。

其每个模块(称为Bundle)与普通的ajva类库相似，一般都以JAR格式封装，内部存储的都是java的Package和Class。
一个Bundle可以声明它所以来的Package(通过Import-Package描述)，也可以声明它允许导出发布的Package(通过Export-Package描述)。
Bundle之间的依赖关系从传统的上层模块依赖底层模块变为平级模块之前的依赖，而类库的可见性能得到非常精确的控制，一个模块了只有被Export过得Package才可能被
外界访问。
现在，通常引入OSGi的主要理由是基于OSGi架构的程序很可能会实现模块级的热插拔功能，可以只停用、重新安装然后启用程序的其中一部分。

这种特点，需要灵活的类加载器架构。Bundle类加载器之间只有规则，没有固定的委派关系。例如，某个Bundle声明了一个它以来的Package，若有其他Bundle声明了发布
这个Package后，那么所有对这个Package的类加载动作都会委派给发布他的Bundle类加载器完成。

类加载时可能进行的查找规则：
+ 以java.*开头的类，委派给父类加载器加载。
+ 否则，委派列表名单内的类，委派给父类加载器加载
+ 否则，Import列表的类，委派给Export这个类的Bundle的类加载器加载
+ 否则，查找当前Bundle的ClassPath，使用自己的类加载器加载
+ 否则，查找是否在自己的Fragment Bundle中，若是则委派给Fragment Bundle的类加载器加载
+ 否则，查找Dynamic Import列表的Bundle，委派给对应的Bundle的类加载器加载
+ 否则，类查找失败

可能死锁，jdk7解决方案，类加载器架构进行专门升级，在ClassLoader中增加registerAsParallelCapable方法对可并行的类加载进行注册声明，把锁级别从ClassLoader
对象本身，降低为要加载的类名这个级别，目的是从底层避免死锁

### 字节码生成技术与动态代理的实现
javac就是字节码生成技术，并且也是一个由java语言写成的程序，代码在OpenJDK的jdk.compiler/share/classes/com/sun/tools/javac目录

动态代理中的动态，是针对使用java代码实际编写了代理类的静态代理而言的。优势不在于省去了编写代理类哪一点编码工作量，而是实现了可以再原始类和接口还未知的时候，就
确定代理类的代理行为，当代理类与原始类脱离直接联系后，就可以灵活地重用于不同的场景。
参见DynamicProxyTest
源码在java.base/share/classes/java/lang/reflect下的sun.mics.ProxyGenerator

### Backport工具：java的时光机器
一个稳健的团队不会碎一地改变底层的技术。。。但是新技术又有吸引力。

可以把高版本的JDK中编写的代码放到低版本JDK环境中部署。java逆向移植工具(Java Backporting Tools)。Retrotranslator和Retrolambda
http://retrotranslator.sf.net
Retrotranslator将jdk5的Class文件变为jdk1.4/1.3上部署的版本，Retrolambda将jdk8的lambda表达式和try-resources语法转变为jdk5/6/7中使用的形式。

### 实战：自己动手实现远程执行功能
需要再服务中执行一小段程序代码，可以定位或排除问题。但找不到可以让服务器执行临时代码的途径。通常解决类似问题途径：
+ 使用BTrace动态修改程序中某一部分代码，还有Arthas
+ 用jdk6提供的Compiler API，动态地编译java程序
+ 写一个JSP文件上传到服务器，在浏览器中运行它，或在服务端程序中加入一个BeanShell Script、JavaScript等的执行引擎(如Mozilla Rhino)去执行动态脚本
+ 在应用程序中内置动态执行的功能

需求：实现，在服务吨执行临时代码
目标，希望最终的产品：
+ 不依赖某个jdk版本才加入的特性(包括JVMTI)，能在目前还被普遍使用的jdk中部署，只要jdk1.4以上都行
+ 不改变原有服务端程序的部署，不依赖任何第三方类库
+ 不侵入原有程序，无需改动源程序的任何代码。也不会对原有程序的运行带来任何影响
+ 考虑到BeanShell Script或JavaScript等脚本与java对象交互不太方便，临时代码应该直接支持java语言
+ 临时代码应当具备足够的自由度，不需要依赖特定的类或实现特定的接口。
+ 临时代码的执行结果能返回到客户端，执行结果可以包括程序中输出的信息及抛出的异常等。

思路，实现过程中，需要解决3个问题：
1)如何编译提交到服务器的java代码
2)如何执行编译后的java代码
3)如何收集java代码的执行结果

第一个问题，两种方案：
+ 在服务器上编译，jdk6可以用Compiler API，jdk6执勤啊可用tools.jar包的com.sun.tools.Javac.Main类来编译java文件，与javac相似。
  缺点是引入了额外的依赖，而且把程序绑死在特定的jdk上，要部署到其他公司的jdk还得把tools.jar带上。
+ 直接在客户端编译好，把字节码传到服务端。

第二个问题
要执行编译后的java代码，让类加载器加载这个类生成一个Class对象，然后反射调用一下某个方法接口(因为不实现任何接口，可以借用一下java中约定的main()方法)。
还应考虑周全些：一段程序往往不是编写、运行一次就能达到效果，同一个类可能要被反复地修改、提交执行。提交上去的类要能访问到服务端的其他类库才行。临时代码，
那提交的java类在执行完后应当被卸载和回收掉。

第三个问题
想把程序往标准输出(System.out)和标准错误输出(System.err)中打印的信息收集起来。但标准输出设备时整个虚拟机进程全局共享的资源，若用System.setOut()/
System.setErr()把输出流重定向到自己定义的PrintStream对象上虽然可以收集到输出信息，但也会对原有程序产生影响：会把其他线程向标准输出中打印的信息也收集。
可以采用另一种办法：直接在执行的类中吧对System.out的符号引用替换为我们的PrintStream的符号引用。

参见inovketmpcode

了解虚拟机如何执行程序，才能更好理解怎样才能写出优秀的代码。


# 前端编译与优化
java中的编译期，
+ 可能是指编译器的前端，把*.java文件转变为*.class文件的过程；
  如JDK的javac、Eclipse JDT中的增量式编译器(ECJ)、
+ 也可能是java虚拟机的即时编译器(JIT, Just In Time Compiler)运行期把字节码转变成本地机器码的过程；
  如HotSpot虚拟机的C1、C2编译器，Grall编译器
+ 还可能是指使用敬爱的提前编译器(AOT, Ahead Of Time Compiler)直接把程序编译成与目标机器指令集相关的二进制代码的过程。
  如JDK的Jaotc、GNU Compiler for the Java(GCJ)、Excelsior JET

javac这类前端编译器对代码的运行效率几乎没有任何优化措施。因为java虚拟机设计团队选择把对性能的优化全部集中到运行期的即时编译器中，这样可以让那些不是由javac产生的
Class文件也同样能享受到编译器优化措施带来的性能红利。
但，若把优化定义放宽，把对开发阶段的优化也计算进来，javac确实是做了许多针对java语言编码过程的优化措施来降低程序员的编码复杂度、提高编码效率。很多java语法特性，都
是靠编译器的语法糖来实现，而不是依赖字节码或java虚拟机的底层改进来支持。

java中的即时编译器在运行期的优化过程，支撑了程序执行效率的不断提升；前端编译器在编译期的优化过程，是支撑程序员的编码效率和语言使用者的幸福感的提高。


## javac编译器
分析源码是了解一项技术的实现内幕最彻底的手段。
javac编译器本身就是一个由java语言编写的程序，为纯java的程序员了解他的编译过程带来很大便利。

jkd6后javac源码在JDK_SRC_HOME/langtools/src/share/classes/com/sun/tools/javac中
jdk9，javac源码在jdk.compiler模块(JDK_SRC_HOME/src/jdk.compiler/share/classes/com/sun/tools/javac)

下载路径：https://hg.openjdk.java.net/jdk6/jdk6/langtools/
配套下载jdk6：brew install homebrew/cask-versions/java6


javac编译器除了j
dk自身标准类库外，只引用了JDK_SRC_HOME/langtools/src/share/classes/com/sun/*中代码，所以可以建立java工程，把sun/*下的源文件复制，
然后执行Main.java即可
参见compilerjavac工程

规范中严格定义了Class文件格式的各种细节，但对如何把java源码编译为Class文件却描述得相当宽松
从javac总体结构看，编译过程大致分为1个准备过程和3个处理过程：
+ 准备过程：初始化插入式注解处理器
+ 解析与填充符号表过程：
    + 词法、语法分析。将源代码的字符流转变为标记集合，构造出抽象语法树
        + 填充符号表。产生符号地址和符号信息
+ 插入式注解处理器的注解处理过程：插入式注解处理器的执行阶段，本节会设计一个插入式注解处理器来影响javac的编译行为
+ 分析和字节码生成过程
    + 标注检查。对语法的静态信息进行检查
        + 数据流及控制流分析。对程序动态运行过程进行检查
        + 解语法糖。将简化代码编写的语法糖还原为原有形式
        + 字节码生成。将前面个步骤所生成的信息转化为字节码

上述3个处理过程中，执行插入式注解时又可能产生新的符号，若有新的符号产生，必须转回到之前的解析、填充符号表的过程中重新处理这些新符号。
javac编译动作的入口是com.sun.tools.javac.main.JavaCompiler类，上述3个过程代码逻辑集中在compile()和compile2()里。

### 解析与填充符号表
由parseFiles完成，包括经典程序编译原理中的词法分析和语法分析
1. 词法、语法分析
   词法分析是将源代码的字符流转变为标记(Token)集合的过程，单个字符是程序编写时的最小元素，但标记才是编译时的最小元素。
   关键字、变量名、字面量、运算符都可以作为标记，如"int a=b+2"包含了6个标记，int、a、=、b、+、2
   javac中，词法分析过程由com.sun.tools.javac.parser.Scanner类实现
   --出token集合

语法分析是根据标记序列构造抽象语法树的过程，抽象语法树(Abstract Syntax Tree, AST)是一种用来描述程序代码语法结构的树形表示方式，每一个节点都代表程序代码中的
一个语法结构(Syntax Construct)，如包、类型、修饰符、运算符、接口、返回值甚至连代码注释等都可以是一种特定的语法结构。
javac中语法分析由com.sun.tools.javac.parser.Parser类，产出的抽象语法树是以com.sun.tools.javac.tree.JCTree类表示
--出AST

IDEA插件JDT AstView，使用：Tools->Enable JDT AST View
后续操作都建立在抽象语法树之上


2. 填充符号表
   对符号表进行填充。即enterTrees。
   符号表(Symbol Table)是由一组符号地址和符号信息构成的数据结构。符号表中所登记的信息在编译的不同阶段都要用到。譬如在语义分析的过程中，符号表所登记的内容将用于
   语义检查(如检查一个名字的使用和原先的声明是否一致)和产生中间代码，在目标代码生成阶段，当对符号名进行地址分配时，符号表是地址分配的直接依据。
   javac中填充符号表的过程由com.sun.tools.javac.comp.Enter类，产出一个待处理列表，包含了每一个编译单元的抽象语法树的顶级节点，以及
   package-info.java(若存在的话)的顶级节点。

### 注解处理器
jdk5后java支持注解(Annotations)，在设计上原本与普通的java代码一样，只会在程序运行期间发挥作用。
但jdk6设计了一组被称为"插入式注解处理器"的标准API，可以提前至编译期对代码中的特定注解进行处理，从而影响到起前端编译器的工作过程。
插入式注解处理器类似一组编译器的插件，可以读取、修改、添加抽象语法树中的任意元素，若在处理注解期间对语法树有修改，
编译期将回到解析及填充符号表的过程重新处理，直到所有插入式注解处理器都没有再对语法树进行修改，每次循环过程成为一个轮次(Round)

有了编译器注解处理的标准API后，可以干涉编译器的行为。如Lombok。
javac中，插入式注解处理器的初始化过程在initProcessAnnotations中。会判断是否有新的注解处理器需要执行，若有则通过com.sun.tools.javac.
processing.JavacProcessingEnvironment.doProcessing来生成一个新的JavaCompiler对象，对编译的后续步骤进行处理。

### 语义分析及字节码生成
经过语法分析后，编译期获得了程序代码的抽象语法树表示，抽象语法树能表示一个结构正确的源程序，但无法保证源程序的语义是符合逻辑的。
语义分析的主要任务是对结构上正确的源程序进行上下文相关性质的检查，譬如进行类型检查、控制流检查、数据流检查等。
例如
```
int a = 1;
boolean b = false;
char c = 2;
// 后续可能出现的赋值运算
int d = a + c;
int d = b + c;
char d = a + c;
```
后续的赋值运算，都能构成结构正确的抽象语法树，但只有第一种的写法在语义上正确，能通过检查和编译。其余两种在java语言不符合逻辑，无法编译(是否合乎语义
逻辑必须限定在具体的语言与具体的上下文环境中才有意义)。ide中看到红线标注的错误，绝大部分都来源于语义分析阶段的检查结果。

语义分析过程可分为标注检查(attribute())和数据及控制流分析俩阶段(flow())
1. 标注检查
   标注检查步骤要检查的内容包括：变量使用前是否已被声明、变量与赋值之间的数据类型是否匹配等。上面3个变量定义的例子就属于标注检查的处理范畴。
   此阶段中，还会顺便进行常量折叠(Constant Folding)的代码优化。
   如：
```
int a = 1 + 2;
```
在抽象语法树上仍能看到字面量1和2和操作符+，但在经过常量折叠优化后，他们会被折叠为字面量3.
如图，这个插入式表达式(Infix Expression)的值已经在语法树上标注出来(ConstantExpressionValue:3)。
javac中com.sun.tools.javac.comp.Attr类和com.sun.tools.javac.comp.Check类

2. 数据及控制流分析
   是对程序上下文逻辑更进一步验证，可以检查出诸如程序局部变量在使用前是否有赋值、方法的每条路径是否有返回值、是否所有受检查异常都被正确处理了
   等问题。与类加载时的数据及控制流分析的目的基本上一致，但校验范围有所不同。
   final修饰的数据及控制流分析例子——只能在编译期而不能在运行期检查例子
```fiinal语义校验
public void foo1(final int arg){
  final int var = 0;
}
public void foo2(int arg){
  int var = 0;
}
```
看编译出来的字节码，一样，局部变量与类的字段(实例变量、类变量)的存储时不同的，局部变量在常量池中没有CONSTANT_Fieldref_info的符号引用，也就
不可能存储有访问标志(access_flags)的信息，甚至可能连变量名都不一定会保留，自然在Class文件中就不可能知道一个局部变量是不是final了。
可以肯定把局部变量声明为final，对运行期完全没有影响，变量的不变形仅仅由javac编译器在编译期保障

javac中数据及控制流分析入口是flow()，操作由com.sun.tools.javac.comp.Flow类

3. 解语法糖
   语法糖(Syntactic Sugar)，编程术语，指在计算机语言中添加的某种语法，这种语法对语言的编译结果和功能并没有实际影响，但却能更方便程序员使用该语言。
   通常可以减少代码量、增加程序的可读性，从而减少程序代码出错机会

java中常见的语法糖包括泛型、变长参数、自由装箱拆箱等。
java虚拟机运行时并不支持这些语法，他们在编译阶段被还原回原始的基础语法结构，称为解语法糖。

javac中，过程由desugar()触发，在com.sun.tools.javac.comp.TransTypes类和com.sun.tools.javac.comp.Lower类完成

4. 字节码生成
   javac最后一个阶段，在javac中com.sun.tools.javac.jvm.Gen类。
   此阶段将前面个步骤所生成的信息(语法树、符号表)转化成字节码指令写到磁盘，还进行少量代码添加和转换

例如，实例构造器<init>()和类构造器<clinit>()就在此阶段被添加到语法树中。
实例构造器并不等同于默认构造函数，若代码没有提供任何构造函数，编译器将会添加一个没有参数的、可访问性与当前类型一致的默认构造函数，这工作在填充符号表
阶段中完成。<init>()和<clinit>()俩构造器的产生是一种代码收敛的过程，编译器会把语句块({}/static{})、变量初始化(实例变量和类变量)、调用父类的
实例构造器等操作收敛到<init>()和<clinit>()中，并保证一定按先执行弗雷德实例构造器，然后初始化变量，最后执行语句块的顺序进行，由Gen:normalizeDefs()。
还有其他代码替换用于优化，如把字符串加操作替换为StringBuilder.append()等

完成了对语法树的遍历和调整后，会把填充了所有所需信息的符号表交到com.sun.tools.javac.jv.ClassWriter类，由其writeClass方法输出字节码，最终
生成到Class文件。

### 泛型
本质是参数化类型(Parameterized Type)或参数化多态(Parametric Polymophism)的应用，即可以将操作的数据类型指定为方法签名中的一种特殊参数，这种参数
类型能用在类、接口和方法的创建中，构成泛型类、泛型接口和泛型方法。
让程序员能针对泛化的数据类型编写相同的算法，极大地增强了编程语言的类型系统及抽象能力
java选择这样的泛型实现，是出于当时语言现状的权衡，而不是语言先进性或设计者水平不如C#之类的原因

1. java与C#的泛型
   java选择的泛型实现方式叫类型擦除式泛型(Type Erasure Generics)，C#选择的泛型实现时具现化泛型(Reified Generics)。
   C#里的泛型无论在程序源码、编译后的中间语言表示(Intermediate Language，这时泛型不是一个占位符)里面，抑或在运行期的CLR里都是且是存在的，List<int>
   和List<string>就是两个不同的类型，由系统在运行期生成，有着自己独立的虚方法表和类型数据。
   java语言的泛型，只在程序源码存在，在编译后的字节码文件中，全部泛型都被替换为为原来的罗类型(Raw Type)，且在相应的地方插入了强制类型转换代码，
   ArrayList<int>和ArrayList<String>是同一类型。
```java中不支持的泛型用法
class TypeErasuerGenerics<E>{
  public void doXXX(Object item){
    if (item instanceof E)  //不合法，无法对泛型进行实例判断
		E newItem = new E();  //不合法，无法使用泛型创建对象
		E[] itemArray = new E[10];  // 不合法，无法使用泛型创建数组
  }
}
```
C#进入泛型后，性能增强，因为在使用平台提供的容器类型(如List<T>等)时，无须像java那样拆箱和装箱。
java的类型擦除式泛型无论在使用效果还是运行效率上，几乎都落后于C#，而唯一的优势在于实现这种泛型的影响范围上：
几乎只需要在javac编译器上做出改动，不需要改动字节码、不需要改动java虚拟机，保证了以前没有使用泛型的库可以直接运行在java5.0之上。必须在那时的泛型
历史背景中去考虑不同实现方式带来的代价

2. 泛型历史背景
   最紧、最难的约束来源于被迫要完全向后兼容无泛型的java，保证二进制向后兼容性(Binary Backwards Compatibility)。

例如：
没有泛型时，由于java中的数组是支持协变(Convariant)的，对应的集合类也可以放入不同类型的元素
```可正常编译为Class但不支持
Object [] array = new String[10];
array[0] = 10;  //编译期没问题，运行时报错

ArrayList list = new ArrayList();
list.add(Integer.valueOf(10));  //编译、运行时都不会报错
list.add("hello")
```
为了保证这些编译出来的Class可以在jdk5.0引入泛型后继续运行，设计者大体有两种方案：
+ 需要泛型化的类型(主要是容器类型)，以前有的就保持不变，然后平行地加一套泛型化版本的新类型
+ 直接把已有的类型泛型化，即让所有需要泛型化的已有类型都原地泛型化，不添加任何平行于已有类型的泛型版

这个插口，C#选择第一条路，添加了一组System.Collections.Generic的新容器，之前的继续存存在。开发人员很快适应。
但若java相同选择可能就有不同结果了，java已经快10年历史，两者遗留代码不在一个数量级。而且java之前也做过第一条路的技术决策，jdk1.2时，遗留代码规模尚小，
java引入过新的集合类，并保留了旧集合类不动。导致了直到现在标准类库中还有Vector和Hashtable等两套容器代码并存。若当时再弄出Vector<T>、ArrayList<T>这样
可能骂声会更大。
这就是java只能选择第二条路，但并不意味着一定只能使用类型擦除来实现，若当时有足够的时间好好设计，完全能做出更好的泛型系统，否则也不会有今天的Valhalla项目来
还以前泛型偷懒留下的技术债了。

3. 类型擦除
   要让所有需要泛型化的已有类型，如ArrayList，原地泛型化后变成了ArrayList<T>，而且保证以前直接用ArrayList的代码在泛型新版本里必须还能继续用着同一个容器，
   就必须让所有泛型化的实例类型，如ArrayList<Integer>全部自动成为ArrayList的子类才可以，否则类型转换就不安全。
   由此引入“裸类型”(Raw Type)，裸类型应被视为所有该类型泛型化实例的共同父类型(Super Type)，只有这样，下面代码才是被系统允许的从子类到父类的安全转型。
```裸类型赋值
ArrayList<Integer> ilist = new ArrayList<Integer>();
ArrayList<String> slist = new ArrayList<String>();
ArrayList list; // 裸类型
list = ilist;
list = slist;
```
实现裸类型，两种选择：
+ 在运行期由java虚拟机来自地、真实地构造出ArrayList<Integer>这这样的类型，并自动实现从ArrayList<Integer>派生自ArrayList的继承关系来满足裸类型的定义
+ 直接在编译时将ArrayList<Integer>还原回ArrayList，只在元素访问、修改时自动插入一些强制类型转换和检查指令

参见GenericErase

泛型擦除缺陷：
+ 导致了对原始类型(Primitive Types)数据的支持又成了新的麻烦
```原始类型的泛型(假设支持)
ArrayList<int> ilist = new ArrayList<int>();
ArrayList<long> llist = new ArrayList<long>();
ArrayList list;
list = ilist;
list = llist;
``
这时，若擦除后，到要插入强制类型转换代码时就不行了，因为不支持int、long与Object之间的强制转型。当时java的方式是既然没法转换，那就别支持原生类型的泛型，只能用
包装类型的泛型ArrayList<Integer>等，反正都做了自动的强制类型转换，遇到原生类型时把装箱、拆箱自动做了(lsit.add(1)这样)。
这导致了后面的无数构造包装类和装箱、拆箱的开销，成为java泛型慢的重要原因，也是Valhalla项目重点解决的问题之一
+ 运行期无法取到泛型类型信息，会让一些代码变得啰嗦，上面方式(协变部分)都是由于运行期java虚拟机无法取得泛型类型而导致的。
···不得不加入的类型参数，由于不能从List中取得参数化类型T，所以不得不从一个额外参数中再传入一个数组的组件类型进去。
public static <T> T[] convert(List<T> list, Class<T> componentType){
  T[] array = (T[]) Array.newInstance(comonentType, list.size());
}
···
+ 丧失了一些面向对象思想应有的优雅，带来一些模棱两可的模糊状况
```当泛型遇见重载1
class GenericTypes{
  public static void method(List<String> list){
	  System.out.println("invoke method(List<String> list)");
	}
  public static void method(List<Integer> list){
	  System.out.println("invoke method(List<Integer> list)");
	}
}
```
不能编译，因为参数List<String>和List<Integer>编译后都被擦除了，变成同一种的裸类型List，类型擦除导致这俩方法的特征签名变得一样。
```当泛型遇见重载2
class GenericTypes{
  public static String method(List<String> list){
	  System.out.println("invoke method(List<String> list)");
		return "";
	}
  public static int method(List<Integer> list){
	  System.out.println("invoke method(List<Integer> list)");
		return 1;
	}
	main{
	  method(new ArrayList<String>());
	  method(new ArrayList<Integer>());
	}
}
```
差别仅仅是添加了不同的返回值，方法重载成功了。
之所以编译成功，因为来method方法加入了不同的返回值后才能共存在一个Class文件中。
Class文件方法表(method_info)的数据结构中，方法重载要求方法具备不同的特征签名，返回值并不包含在方法的特征签名中，所以返回值不参与重载选择。
但在Class文件格式之中，只要描述符不完全一致的俩方法可以共存。即俩方法若有相同的名称和特征签名，但返回值不同，那他们也是可以合法地共存于一个Class文件中。

由于泛型的引入，各种场景(虚拟机解析、反射等)下的方法调用都可能对原有的基础产生影响并带来新的需求，如在泛型类中如何获取传入的参数化类型等。
规范进行了修改，引入Signature、LocalVariableTypeTable等新的属性用于解决伴随泛型而来的参数类型的识别问题，Signature作用是存储一个方法在字节码层面的
特征签名，这个属性中保存的参数类型并不是原生类型，而是包括了参数化类型的信息。

从上面的2例子中看到，擦除对实际编码的不良影响，由于List<String>和List<Integer>擦除后是同一个类型，只能添加俩并不需要实际使用到的返回值才能完成重载，
毫无优雅和美感，而且存在一定语义上的混乱，如必须用jdk6的javac才能编译成功，其他版本或ECJ编译器都可能拒绝编译。

从Signature属性的出现还可以得出结论，擦除法所谓的擦除，仅仅是对方法的Code属性中的字节码进行擦除，实际上元数据中还是保留了泛型信息，这也是编码时能通过反射
手段取得参数化类型的根本依据

4. 值类型与未来的泛型

### 自动装箱、拆箱与遍历循环
被使用较多的语法糖。
参见AutoBox

### 条件编译
C、C++中使用预处理器指示符(#ifdef)完成条件编译。C、C++预处理器最初的任务时解决编译时的代码依赖关系(如#include预处理命令)，而在java语言中没有用
预处理器，因为java语言的编译方式(编译器并非一个个地编译java文件，而是将所有编译单元的语法树顶级节点输入到待处理列表后再进行编译，因此各个文件之间
能互相提示符号信息)就无需使用到预处理器。

java也可以进行条件编译，使用条件为常量的if语句
参见ConditionCompile

java中条件编译的实现，也是语法糖，根据布尔常量值的真假，编译器把分支中不成立的代码块消除掉，这一工作在编译期解除语法糖阶段(com.sun.tools.javac.comp.
Lower类)完成。

### 实战：插入式注解处理器
使用自定义的插入式注解处理器API来对ava编译子系统的行为施加影响

javac前端编译器在把java源码编译为字节码时，会对源码做各方面的检查校验。主要是以程序写的对不对为出发点，比较少去校验程序写得好不好。鉴于此，业界出现了
许多CheckStyle、FindBug、Klocwork等。

驼式命名法(Camel Case Name)

规范中要求java程序命名推荐应当符合格式：
+ 类(或接口)：符合驼式命名法，首字母大写
+ 方法：符合驼式命名法，首字母小写
+ 字段
    + 类或实例变量。符合驼式命名法，首字母小写
        + 常量。要求全部由大写字母或下划线构成，并且第一个字符不能是下划线

目标：为javac编译器添加一个额外的功能，在编译程序时检查程序名是否符合上述对类(或接口)、方法、字段的命名要求

自定义注解处理器继承javax.annotation.processing.AbstractProcessor，参数annotations可以获取到所要处理的注解集合，参数roundEnv可访问
到当前这个轮次(Round)中的抽象语法树节点，每个语法树节点在这里都表示为一个Element。在javax.lang.model.ElementKind中定义了Element。
还有一个实例变量processingEnv在注解处理器初始化时(init()执行时)创建，代表了注解处理器框架提供的一个上下文环境，要创建新的代码、想编译器输出
信息、获取其他工具类等都需要用到这个实例变量。

还有俩经常配合使用的注解，@SupportedAnnotationType和@SupportedSourceVersion，前者代表这个注解处理器对那些注解感兴趣，后者指出这个注解
处理器可以处理那些版本的java代码。

每一个注解处理器在运行时都是单例，若不需改变或添加抽象语法树内容，process返回false，通知编译器这个轮次中的代码未发生变化，无需构造新的JavaCompiler实例参考precompile/inaction

还有Hibernate Validator Annotation Processor、Lombok等。


## 后端编译与优化
若把字节码看做程序语言的一种中间表示形式(Intermediate Representation, IR)的话，那编译器无论在何时、在何种状态下吧Class文件转换成与本地基础设施(
硬件指令集、操作系统)相关的二进制机器码，都可以视为整个编译过程的后端。

后端编译器性能的好坏、代码优化质量的高低却是衡量一款商用虚拟机优秀与否的关键指标之一，是最能体现技术水平与价值的功能。

### 即时编译器
java程序最初都是通过解释器(Interpreter)进行解释执行，当虚拟机发现某个方法或代码块的运行特别频繁，会把这些代码认为"热点代码"(Hot Spot Code)，为了
提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成本地机器码，以各种手段尽可能地进行代码优化，运行时完成这个任务的后端编译器称为即使编译器。

本结解决一下问题：
+ 为何hostSpot虚拟机要使用解释器与即使编译器并存的架构？
+ 为何HotSpot虚拟机要实现两个(或三个)不同的即时编译器?
+ 程序何时使用解释器执行？何时使用编译器执行?
+ 哪些程序代码挥别编译为本地代码？如何编译本地代码？
+ 如何从外部观察到即时编译器的编译过程和编译结果？

#### 解释器与编译器
hotSpot内部同时包含了解释器与编译器，两者有其各自优势：当程序徐亚哦迅速启动和执行时，解释器可以首先发挥作用，省去编译的时间，立即运行。当程序启动后，
随着时间推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码，可以减少解释器的中间损耗，获得更高的执行效率。
当程序运行环境中内存资源限制较大，可以用解释执行节约内存(如部分嵌入式系统和大部分的javaCard应用中就只有解释器)，反之可以使用编译执行来提升效率。
解释器还可以作为编译器激进优化时后备的"逃生门"(若情况允许，hotSpot会采用不进行激进优化的客户端编译器充当"逃生门"的角色)，让编译器根据概率选择一些
不能保证所有情况都正确的，但大多数能提升运行速度的优化手段，当激进优化的假设不成立，如加载了新类后，类型继承结构出现变化、出现"罕见陷阱"(Uncommon
Trap)时可以通过逆优化(Deoptimization)退回到解释状态继续执行，因此在整个虚拟机执行架构里，解释器与编译器常相辅相成配合。

hotSpot内置了两个(或三个)即时编译器，两个存在很长，客户端编译器(Client Compiler)和服务端编译器(Server Compiler)，或称为C1和C2。
第三个是jdk10出现，长期目标是代替C2的Graal编译器。

分层编译(Tiered Compilation)的工作模式出现前，hotSpot通常采用计时器与其中一个编译器直接搭配方式，程序使用哪个编译器，取决于虚拟机运行的模式，其根据
自身版本与宿主机器的硬件性能自动选择运行模式，或指定-client、-server强制指定虚拟机运行在哪种方式。

解释器与编译器搭配使用称为缓和模式(Mixed Mode)，用户也可指定-Xint强制虚拟机运行于解释模式(Interpreted Mode)，这时编译器不介入工作，全部代码都用解释
方式执行。
也可用-Xcomp强制虚拟机运行于编译模式(Compiled Mode)，优先采用编译方式执行程序，但解释器仍要在编译无法进行时介入执行过程。
可通过-version输出结果显示这三种模式
```虚拟机执行模式
java -verison
java -Xint -version
java -Xcomp -version
```

由于即使编译器本地代码需要占用程序运行时间，通常要编译出优化程度越高的代码，花费时间越长，要想编译出优化程度更高的代码，解释器可能还要替编译器收集性能
监控信息，这对解释执行阶段的速度也有所影响。
为了在程序启动响应速度与运行效率之间达到最佳平衡，hotSpot在编译子系统中加入分层编译的功能，jdk7的服务端模式虚拟机中作为默认编译策略。

分层编译根据编译器编译、优化的规模与耗时，划分出不同的编译层次，包括：
+ 第0层，程序纯解释执行，并且解释器不开启性能监控功能(Profiling)
+ 第1层，使用客户端编译器将字节码编译为本地代码来运行，进行简单可靠的稳定优化，不开启性能监控功能。
+ 第2层，使用客户端编译器执行，仅开启方法及回边次数统计等优先的性能监控功能
+ 第3层，使用客户端编译器执行，开启全部性能监控，除了第2层的统计信息外，还收集如分支跳转、虚方法调用版本等全部的统计信息
+ 第4层，使用服务端编译器将字节码编译为本地代码，相比起客户端编译器，服务端编译器会启用更多编译耗时更长的优化，还会根据性能监控信息进行一些不可靠的
  激进优化。

实时分层编译后，解释器、客户端编译器和服务端编译器会同时工作，热点代码可能会被多次编译，用客户端编译器获取更高的编译速度，用服务端编译器来获取更高
的编译质量，在解释执行时无须额外承担收集性能监控信息的任务，在服务端编译器采用高复杂度的优化算法时，客户端编译器可先采用简单优化来为它争取更多的
编译时间。

#### 编译对象与触发条件
热点代码包括：
+ 被多次调用的方法
+ 被多次执行的循环体

编译的目标对象是整个方法体。第一种情况，由于是依赖方法调用触发的编译，那编译器自然会以整个方法作为编译对象。是虚拟机中标准的即时编译方式。
后一种情况，尽管编动作是由循环体所触发，热点只是方法的一部分，但编译器依然必须以整个方法作为编译对象，只是执行入口(从方法第几条字节码指令开始
执行)会稍有不同，编译时会传入执行入口点字节码序号(Byte Code Inex, BCI)。因为编译发生在方法执行的过程中，因此成为栈上替换(On Stack Replacement,
OSR)，即方法的栈帧还在栈上，方法就被替换了。

要知道某段代码是不是热点代码，是不是需要触发即使编译，这个行为成为"热点探测"(HotSpot Code Detection)，主流判定方式：
+ 基于采样的热点探测(Sample Based Hot Spot Code Deteciton)。虚拟机会周期性地检查各个线程的调用栈顶，若发现某个(或某些)方法经常出现在栈顶，那
  这个方法就是热点方法。这种方式好处是实现简单高效，容易获取方法调用关系(将调用堆栈展开即可)，缺点是很难精确地确认一个方法的热度，容易因为受到线程阻塞
  或别的外界因素的影响而扰乱热点探测
+ 基于计数器的热点探测(Counter Based Hot Spot Code Detection)。虚拟机会为每个方法(甚至代码块)建立计数器，统计方法的执行次数，若执行次数超过一
  定的阈值就认为它是热点方法。实现麻烦一些，需要为每个方法建立并维护计数器，而不能直接获取到方法的调用关系，但他的统计结果相对更加精确严禁。

hotSpot用第二种，为每个方法准别了两类计数器：方法调用计数器(Invocation Counter)和回边计数器(Back Edge Counter，指在循环边界往回跳转)。当虚拟机
运行参数确定的前提下，这俩计数器都有一个明确的阈值，计数器阈值一旦溢出，会触发即时编译。

方法调用计数器：
用于统计方法被调用的次数，默认阈值在客户端模式下1500次，在服务端模式下是10000次，可用-XX:CompileThreshold设定。
当一个方法被调用时，虚拟机会检查该方法是否存在被即使编译过的版本，若有，则优先用编译后的本地代码执行。若不存在则将该方法的调用计数器值+1，然后判断方法
调用计数器与回边计数器值只和是否超过方法调用计数器的阈值，一旦超过，将会向即使编译器提交一个该方法的代码编译请求。
若没有设置，执行引擎不会同步等待编译请求完成，而是继续进入解释器按照解释方式执行字节码，直到提交的请求被即使编译器完成。当编译工作完成，这个方法的调用
入口地址会被系统自动改写成新值，下次调用该方法会用已编译的版本。
默认设置下，方法调用计数器统计的是一个相对的执行频率，即一段时间内方法被调用的次数。当超过一定的时间限度，若方法的调用次数仍不足以让它提交给即使
编译器，那该方法的调用计数器就会减半，称为方法调用计数器热度的衰减(Counter Decay)，这段时间称为此方法统计的半衰周期(Counter Half Life Time)。
进行热度衰减的动作是在虚拟机进行垃圾收集时顺便进行的，可以用-XX:-UseCounterDecay来关闭热度衰减，让方法计数器统计方法调用的绝对次数。
还可用-XX:CounterHalfLifeTime设定半衰周期的时间，单位秒

回边计数器：
作用是统计方法中循环体代码执行的次数，在字节码中遇到控制流向后跳转的指令称为回边(Back Edge)，建立回边计数器统计的目的是为了触发栈上的替换编译。
用-XX:BackEdgeThreshold设定阈值，目前hotSpot没有使用，需要设置另一个参数-XX:OnStackReplacePercentage来间接调整回边计数器的阈值。
计算公式有两种：
+ 虚拟机运行在客户端模式下，回边计数器阈值计算公式为：方法调用计数器阈值(-XX:CompileThreshold)乘以OSR比率(-XX:OnStackRepalcePercentage(其
  默认值为933))除以100。
+ 虚拟机运行在服务端模式下，公式：方法调用计数器阈值(-XX:CompileThreshold)乘以(OSR比率(默认140)减去
  解释器监控比率(-XX:InterpreterPorfilePercentage(默认33))的差值)除以100.

当解释器遇到一条回边指令时，会先查找将要执行的代码片段是否有已经编译好的版本，如有，将会优先执行已编译的代码，否则会把回边计数器的值+1，然后判断方法
调用计数器与回边计数器值只和是否超过回边计数器的阈值。当超过时，提交一个栈上替换编译请求，并把回边计数器的值稍微降低一些，以便继续再解释其中执行
循环，等待编译器输出编译结果。

没有计数器热度衰减的过程，因此统计的就是该方法循环执行的绝对次数。当计数器溢出时，还会把方法计数器的值也调整到溢出状态，这样下次再进入该方法时会
执行标准编译过程。

在MethodOop.hpp(一个methodOop对象代表了一个java方法)中，定义了java方法在虚拟机中的内存布局。
```
// |------------------------------------------------------| 
// | header | 
// | klass | 
// |------------------------------------------------------| 
// | constMethodOop (oop) | 
// | constants (oop) | 
// |------------------------------------------------------| 
// | methodData (oop) | 
// | interp_invocation_count | 
// |------------------------------------------------------| 
// | access_flags | 
// | vtable_index | 
// |------------------------------------------------------| 
// | result_index (C++ interpreter only) | 
// |------------------------------------------------------| 
// | method_size | max_stack | 
// | max_locals | size_of_parameters | 
// |------------------------------------------------------| 
// |intrinsic_id| flags | throwout_count | 
// |------------------------------------------------------| 
// | num_breakpoints | (unused) | 
// |------------------------------------------------------| 
// | invocation_counter |   --这里
// | backedge_counter | 
// |------------------------------------------------------| 
// | prev_time (tiered only, 64 bit wide) |
// |
// |------------------------------------------------------| 
// | rate (tiered) | 
// |------------------------------------------------------|
// | code(pointer)
// | i2i(pointer)
// | adapter(pointer)
// | from_compiled_entry(pointer)  --编译的入口
// | from_interpreted_entry(pointer)  --解释的入口
// |------------------------------------------------------| 
// | native_function (present only if native) | 
// | signature_handler (present only if native) | 
// |------------------------------------------------------|
```
每一行表示占用32bit，


#### 编译过程
虚拟机在编译期还未完成编译前，都将按照解释方式继续执行代码，而编译动作则在后台的编译线程中进行。
可通过-XX:-BackgroundCompilation禁止后台编译，禁止后，当达到触发即时编译器的条件时，执行线程向虚拟机提交编译请求以后将会一直阻塞等待，直到编译过程
完成再开始执行编译器输出的本地代码

对于客户端编译器，是一个快速的三段式编译器，主要的关注点在于局部性的优化，而放弃了许多耗时较长的全局优化手段
+ 第一阶段，一个平台独立的前端将字节码构造成一种高级中间代码表示(High-Level Intermediate Representation, HIR,即与目标机器指令集无关的中间表示)。
  HIR使用静态单分配(Static Single Assignment, SSA)的形式来代表代码值，可以使得一些在HIR的构造过程之中和之后进行优化动作更容易实现。在此之前，编译器
  已经会在字节码上完成一部分基础优化，如方法内联、常量传播等优化将会在字节码被构造成HIR之前完成。
+ 第二阶段，一个平台相关的后台从HIR中产生低级中间代码表示(Low-Level Intermediate Pepresetation, LIR, 即与目标机器指令集相关的中间表示)，而此之前
  会在HIR上完成另外一些优化，如空值检查消除、范围检查消除等，以便让HIR达到更高效的代码表示形式
+ 最后阶段，是在平台相关的后端使用线性扫描算法(Liner Scan Register Allocation)在LIR上分配寄存器，并在LIR上做窥孔(Peephole)优化，然后产生机器代码。

服务端编译器是专门面向服务端的典型应用场景，并未服务端的性能配置针对性调整过得编译器，也是一个容忍很高优化复杂度的高级编译器，几乎达到GNU C++编译器使用
-O2参数时的优化强度。
会执行大部分经典的优化动作，如：无用代码消除(Dead Code Elimination)、循环展开(Loop Unrolling)、循环表达式外提(Loop Expression Hoisting)、
消除公共子表达式(Common Subexpression Elimination)、常量传播(Constant Propagation)、基本块重排序(Basic Block Reordering)等。
还会实施一些与java语言特性密切相关的优化技术，如范围检查消除(Range Check Elimination)、空值检查消除(Null Check Elimination)等。
还可能根据解释器或客户端编译器提供的性能监控信息，进行一些不稳定的预测性激进优化，如守护内联(Guarded Inlining)、分支频率预测(Branch Frequency
Prediction)等。

服务端编译采用的寄存器分配是一个全局图着色分配器，可以充分利用某些处理器架构(如RISC)上的大寄存器集合。
以即时编译的标准看，服务端编译器无疑是比较缓慢，但他的编译速度依然超过传统的静态优化编译器，而且相对于客户端编译器编译输出的代码质量有很大提高，可大幅
减少本地代码的执行时间，从而抵消掉额外的编译时间开销。

即时编译过程是一个虚拟机中最能体现技术水平也是最复杂的部分。

#### 实战：查看及分析即时编译结果
本结提到的参数需要FastDebug或SlowDebug优化级别的hotSpot虚拟机支持。Product级别不支持。--with-debug-level=fastdebug或slowdebug
若用Product，则要加入-XX:+UnlockDiagnosticVMOptions打开虚拟机诊断模式
参见JitCompileTest
虚拟机提供了一组通用的反汇编接口，可以接入各种平台下的反汇编适配器，如hsdis-amd64等。将其放在JAVA_HOME/lib/amd64/server下，与jvm.dll或libjvm.so
路径相同。jdk8及以前，放在JRE_HOME/bin/server下
然后用-XX:+PrintAssembly要求虚拟机打印编译方法的汇编代码
若没有HSDIS插件，也可以用-XX:+PrintOptoAssembly(服务端模式)或-XX:PrintLIR(客户端模式)来输出比较接近最终结果的中间代码表示，伪汇编结果。

想跟踪本地代码生成的具体过程，可用-XX:+PrintCFGToFile(客户端模式)或-XX:PrintIdealGraphFile(服务端模式)要求java虚拟机将编译过程中各阶段的数据(如对
客户端编译器来说包括字节码、HIR生成、LIR生成、寄存器分配过程、本地代码生成等数据)输出到文件中。然后用Java HotSpot Client Compiler Visualizer(分析
客户端编译器)或Ideal Graph Visualizer(用于分析服务端编译器)打开这些数据文件进行分析。
Ideal Graph Visualizer：http://ssw.jku.at/General/Staff/TW/igv.html

服务端编译器的中间代码表示，是一种名为理想图(Ideal Graph)的程序依赖图(Program Dependence Graph, PDG)，在java程序的FastDebug或SlowDebug优化级别的
虚拟机上的参数中加入-XX:PrintIdealGraphLevel=2 -XX:PrintIdealGraphFile=index.xml，即时编译后将会产生一个ideal.xml文件，包含了服务端编译器编译
代码的全过程，可以用Ideal Graph Visualizer对这些信息分析
用其加载ideal.xml后，显示程序运行过程中编译过的方法列表，展开方法根节点，看到下面有方法优化过程的各个阶段(根据优化措施不同，每个方法经过的阶段也不同)的
理想图，
After Parsing阶段，时服务端编译器刚完成解析，还没有做任何优化时的理想图表示。打开后，每一个方块代表了一个程序的基本块(Basic Block)。
基本块指程序按照控制流分割出来的最小代码块，特点是只有唯一的一个入口和唯一的出口，只要基本快的第一条指令被执行，那么基本块内所有指令都会按照顺序全部执行一次。

doubleValue方法，按照基本块划分后，形成的图形结构复杂，因为一方面要满足java语言所定义的安全需要(如类型安全、空指针检查)和java虚拟机方法的运作需要(如
Safepoint轮询)，另一方面有些程序代码中一行语句就可能形成几个基本块(如循环语句)。
本例doubleValue可以简单理解为按顺序执行：
1)程序入口，建立栈帧
2)设置j=0，进入安全点(Safepoint)轮询，跳转到4的条件检查
3)执行j++
4)条件检查，若j<100000，跳转到3
5)设置i=i*2，进行安全点轮询，函数返回

右击Difference to current graph，分析俩阶段的差异
到最后的Final Code阶段，不仅空循环的开销消除，许多语言安全保障措施和GC安全点的轮询操作也被一起消除，因为编译器判断到即使不做这些保障措施，
程序也能得到相同的结果，不会有可观察到的副作用，虚拟机的运行安全也不会受到威胁


### 提前编译器
现在提前编译产品和对其的研究有俩分支
+ 做与传统C、C++编译器类似的，在程序运行之前把程序代码编译成机器码的静态翻译工作
+ 把原本即时编译器在运行时要做的编译工作提前做好并保存下来，下次运行到这些代码(譬如公共库代码被同一台机器其他java进程使用)时直接把它加载进来使用。

第一方案，是传统的提前编译应用形式，在java中存在的价值直指即使编译的最大弱点：即使编译要占用程序运行时间和运行资源。
具体例子，在编译过程中最耗时的优化措施之一是通过"过程间分析"(InterProcedural Analysis, IPA，称为全程序分析,Whole Program Analysis)来获得
注入某个程序点上某个变量的值是否一定为常量、某段代码块是否永远不可能被使用、在某个点调用的某个虚方法是否只能有单一版本等的分析结论。但需要在全程
范围内做大量耗时的计算工作。但若在程序运行前进行静态编译，这些耗时的优化可以放心大胆地进行。

第二方案，本质是给即使编译器做缓存加速，去改善java程序的启动时间，以及需要一段时间预热后才能到达最高性能的问题。称为动态提前编译(Dynamic AOT)或
即时编译缓存(JIT Caching)。已被主流商用jdk支持。jd9带的Jaotc提前编译器，是一个基于Graal编译器实现的新工具，目的是让用户可以针对目标机器，为应用
程序进行提前编译。HotSpot运行时可以直接接在这些编译的结果，实现加快程序启动速度，减少程序达到全速运行状态所需时间的目的。

即时编译器相对于提前编译器的天然优势
+ 性能分析制导优化(Profile-Guided Optimization, PGO)，解释器或客户端编译器运行时，会不断收集性能监控信息，譬如某个程序点抽象类通常会是什么实际
  类型、条件判断通常会走哪条分支、方法调用通常会选择哪个版本、循环通常会进行多少次等，这些数据一般在静态分析时无法得到，或不可能存在确定且唯一的解，最多
  只能依照一些启发性的条件去进行猜测。但在动态运行时能看出他们具有非常明显的偏好性。若一个条件分支某一条路径执行特别频繁，而其他路径鲜有问津，就可以把
  热的代码集中放到一起，集中优化和分配更好的资源(分支预测、寄存器、缓存等)给他。
+ 激进预测性优化(Aggressive Speculative Optimization)。静态优化无论如何都必须保证优化后所有的程序外部可见影响(不仅仅是执行结果)与优化前是等效，
  不然优化后会导致程序报错或结果不对。然而，提前编译，即时编译的策略就可以不必这样保守，若性能监控信息能支持他卓楚一些正确的可能性很大但无法保证绝对正确
  的预测判断，就已经可以大胆地按照高概率的假设进行优化，万一走错，大不了退回到低级编译器甚至解释器上去执行，并不会出现无法挽救的后果。只要出错概率足够低，
  这样的优化往往能大幅降低目标程序的复杂度，输出运行速度非常高的代码。譬如，java中默认方法都是虚方法调用，但若java虚拟机真的遇到虚方法就去查虚表而不做
  内联的话，java技术可能因性能问题而被淘汰。实际上，虚拟机会通过类继承关系分析等一系列激进的猜测去做去虚拟化(Devitalization)，以保证绝大部分有内联
  价值的虚方法都可以顺利内联。内联是最基础的一项优化措施。
+ 链接时优化(Link-Time Optimization, LTO)，java语言天生就是动态连接的，Class文件在运行期被加载到虚拟机内存当中，然后在即时编译器里产生优化后的
  本地代码。

### 实战：Jaotc的提前编译
选择第二条分支，即做即时编译的缓存，而Substrate VM是选择第一条分支。


### 编译器优化技术
编译器的目标虽然是由程序diamante翻译为本地机器码的工作，但难点并不在于能不能成功翻译出机器码，输出代码优化质量的高低才是决定编译器优秀与否的关键。

#### 优化技术概览
即时编译器优化技术一览：
类型  优化技术
+  编译器策略(Compiler Tactics)  延迟编译(Delayed Compilation)/分层编译(Tiered Compilation)/栈上替换(OnStack Replacement)/延迟
   优化(Delayed Reoptimization)/程序依赖图表示(Program Dependence Graph Representation)/静态单赋值表示(Static Single Assignment
   Representation)
+ 基于性能监控的优化技术(Profile Based Techniques)  乐观空值断言(Optimistic Nullness Assertions)/乐观类型断言(Optimistic Type
  Assertions)/乐观类型增强(Optimitic Type Strengthening)/乐观数组长度增强(Optimistic Array Length Strengthening)/裁剪未被选择的
  分支(Untaken Branch Pruning)/乐观的多态内联(Optimistic N-Morphic Inlining)/分支频率预测(Branch Frequency Prediction)/调用频率
  预测(Call Frequency Prediction)
+ 基于证据的优化技术(Proof Based Techniques)  精确类型推断(Exact Type Interface)/内存值推断(Memory Value Interface)/内存值跟踪(
  Memory Value Tracking)/常量折叠(Constant Folding)/重组(Reassociation)/操作符退化(Operator Strength Reduction)/控制检查消除(
  Null Check Elimination)/类型检测退化(Type Test Strength Reduction)/类型检测消除(Type Test Elimination)/代数化简(Algebraic
  Simplification)/公共字表达式消除(Common Subexpression Elimination)
+ 数据流敏感重写(Flow Sensitive Rewrites)  条件常量传播(Conditional Constant Propagation)/基于流承载的类型缩减转换(Flow Carried
  Type Narrowing)/无用代码消除(Dead Code Elimination)
+ 语言相关的优化技术(Language Specific Techniques)  类型继承关系分析(Class Hierarchy Analysis)/去虚拟化(Devirtualization)/符号
  常量传播(Symbolic Constant Propagation)/自动装箱消除(Autobox Elimination)/逃逸分析(Escape Analysis)/锁消除(Lock Elision)/锁
  膨胀(Lock Coarsening)/消除反射(De Reflection)
+ 内存及代码位置变换(Memory And Placement Transformation)  表达式提升(Expression Hoisting)/表达式下沉(Expression Sinking)/冗余
  存储消除(Redundant Store Elimination)/相邻存储合并(Adjacent Store Fusion)/交汇点分离(Merge Point Splitting)
+ 循环变换(Loop Transformations)  循环展开(Loop Unrolling)/循环剥离(Loop Peeling)/安全点消除(Safepoint Elimination)/迭代范围分离
  (Iteration Range Splitting)/范围检查消除(Range Check Elimination)/循环向量化(Loop Vectorization)
+ 全局代表调整(Global Code Shaping)  内联(Inlining)/全局代码外提(Global Code Motion)/基于热度的代码布局(Heat Based Code Layout)/
  Switch调整(Switch Balancing)
+ 控制流图变换(Control Flow Graph Transformation)  本地代码编排(Local Code Scheduling)/本地代码封包(Local Code Bundling)/延迟槽
  填充(Delay Slot Filing)/着色图寄存器分配(Graph Coloring Register Allocaiton)/线性扫描寄存器分配(Linear Scan Register Allocation)/
  复写聚合(Copy Coalescing)/常量分裂(Constant Splitting)/复写移除(Copy Removal)/地址模式匹配(Address Mode Matching)/指令窥孔优化(
  Instruction Peepholing)/基于确定优先状态机的代码生成(DFA Based Code Generator)

即时编译器对这些代码优化变换时建立在代码的中间表示或是机器码之上，不是直接在java源码上去做的。
优化过程举例：
```原始代码
static class B{
  int value;
	final int get(){
	  return value;
	}
}

public void foo(){
  y = b.get();
	// ... do stuff...
	z = b.get();
	sum = y + z;
}
```
第一个要进行的优化是方法内联，主要目的：去除方法调用的成本(如查找方法版本、建立栈帧等)；为其他优化建立良好的基础。
方法内联膨胀后可以便于在更大范围上进行后续的优化手段，可以获得更好的优化效果。因此各种编译器一般都会把内联优化放在优化序列最靠前的位置。
```内联后的代码
public void foo(){
  y = b.value;  --这里
	// ... do stuff...
	z = b.value;
	sum = y + z;  --这里
}
```
冗余访问消除(Redundant Loads Elimination)，假设中间代码`... do stuff...`不会改变b.value的值，那可以把`z = b.value`替换为`z=y`,这样可以
不再去访问对象b的局部变量了。若把b.value看做一个表达式，那么也可以把这项优化看作一种公共字表达式消除(Common Subexpression Elimination)。
```冗余访问消除后的代码
public void foo(){
  y = b.value;
	// ... do stuff...
	z = y;  --这里
	sum = y + z;  
}
```
复写传播(Copy Propagation)，因为这段逻辑中没有必要使用一个额外的变量z，可以用y来代替z。
```复写传播后的代码
public void foo(){
  y = b.value;
	// ... do stuff...
	y = y;  --这里
	sum = y + y;  --这里
}
```
无用代码消除(Dead Code Elimination)，消除的可能是永远不会被执行的代码，也可能是完全没有意义的代码。
```无用代码消除后的代码
public void foo(){
  y = b.value;
	// ... do stuff...
	sum = y + y;
}
```
经过上述优化后，现在代码与原始代码所达到的效果是一致的，但比后者省略不少，体现在字节码和机器码指令上的差距更大，执行效率的差距也会更高。

#### 方法内联
方法内联，除了消除方法调用的成本外，更重要的意义是为其他优化手段建立良好的基础。
testInline()方法的内部全部是无用代码，但若不做内联，后续即使进行了无用代码消除的优化，也无法发现任何Dead Code。若分开来看foo和testInline俩方法
里的操作可能都是有意义的
```原始代码
public static void foo(Object obj){
  if(obj != null){
	  System.out.println("do something");
	}
}

public static void testInline(String[] args){
  Object obj = null;
	foo(obj);
}
```
内联的优化行为是把目标方法的代码复制到发起调用的方法中，避免发生真实的方法调用。但实际上java虚拟机中的内联过程若不是即时编译器做了一些特殊努力，按照
经典编译原理的优化理论，大多数的java方法都无法进行内联。

无法内联的原因是：只有使用invokespecial指令调用的私有方法、实例构造器、父类方法和使用invokestatic指令调用的静态方法才会在编译期进行解析，加上被
final修饰的方法(它用的invokevirtual指令调用，但也是非虚方法)，其他的java方法调用都必须在运行时进行方法接收者的多态选择，都有可能存在多于一个版本
的方法接收者，java语言中默认的实例方法是虚方法。
对于一个虚方法，编译器静态地去做内联时很难确定应该用哪个方法版本。例如b.get()若不依赖上下文，是无法确定b的实际类型，进而不能直接内联为b.value。应该
根据实际类型动态分派，而实际类型必须在实际运行到这一行代码时才能确定，编译器很难在编译时得出绝对准确的结论

java提倡使用面向对象的方式进行编程，java对象的方法默认就是虚方法，可以说java间接鼓励程序员使用大量的虚方法来实现程序逻辑。根据上面分析可知，内联与
虚方法之间会产生矛盾。C和C++语言是默认方法是非虚方法，若需要用到多态，就用virtual关键字来修饰，但java选择了在虚拟机中解决此问题。

为解决此问题，java虚拟机引入类型关系分析(Class Hierarchy Analysis, CHA)的技术，是整个应用程序范围内的类型分析技术，用于确定在目前已加载的类中，
某一个接口是否有多于一种的实现、某个类是否存在子类、某个子类是否覆盖了父类的某个虚方法等信息。
编译器在进行内联时分情况：
+ 若是非虚方法，那么直接进行内敛，安全
+ 若遇到虚方法，则会向CHA查询此方法在当前程序状态下是否真的有多个目标版本可供选择，
    + 若只有一个版本，那可以假设现在这样可以内联，称为守护内敛(Guarded Inlining)。而由于java是动态连接，可能后期新加载类，因此要预留退路(Slow Path)。
    + 若有多个版本，最后一次努力，使用内联缓存(Inline Cache)的方式来所见方法调用的开销。内联缓存是一个建立在目标方法正常入口之前的缓存，工作原理：缓存
      并判断方法接收者版本，
        + 若一样，那它是一种单态内联缓存(Monomorphic Inline Cache)。
            + 若不一样，说明多态，退化成超多态内联缓存(Megamorphic Inline Cache)，相当于真正查找虚方法表进行方法分派
              这种激进优化常见，还有，对于出现概率很小(通过经验数据或解释器收集到的性能监控信息确定概率大小)的隐式异常、使用概率很小的分支等都可以被激进优化移除，
              若真的出现了小概率事件，这时才会从逃生门回到解释状态重新执行
              -- 大概率

#### 逃逸分析(Escape Analysis)
与类型继承关系分析一样，并不是直接优化代码的手段，而是为其他优化措施提供依据的分析技术。

基本原理：分析对象动态作用域，当一个对象在方法里被定义后，可能被外部方法所引用，例如作为调用参数传递到其他方法中，称为方法逃逸；甚至还有可能被外部线程
访问到，譬如赋值给可以再其他线程中访问到实例变量，称为线程逃逸；不同逃逸程度。

若能证明一个对象不会逃逸到方法或线程外(即别的方法或线程无法通过任何途径访问到这个对象)，或逃逸程度比较低(指套溢出方法而不会逃逸出线程)，则可能为这个
对象采用不同程度的优化：
+ 栈上分配(Stack Allocations)：java默认在堆上份分配创建对象的内存空间，堆中对象对于各个线程都是共享和可见的，只要持有这个对象的引用就可以访问到
  堆中存储的对象数据。垃圾收集子系统会回收堆中不再使用的对象，但要耗费资源。若确定一个对象不会逃逸出线程外，那让这个对象在栈上分配内存将不错，对象所占
  用的内存空间可以随栈帧出栈而销毁，垃圾收集子系统压力也小。栈上分配可以支持方法逃逸，但不能支持线程逃逸。
+ 标量替换(Scalar Replacement)：
  标量：一个数据已经无法再分解成更小的数据来表示(java虚拟机中的原始数据类型，int、long等及reference类型等)
  聚合量(Aggregate)：一个数据可以继续分解。如java的对象。
  标量替换：把一个java对象拆散，根据程序访问的情况，将其用到的成员变量恢复为原始类型来访问。
  假若逃逸分析能证明一个对象不会被方法外部访问，并且这个对象可以被拆散，那么程序真正执行时可能不去创建这个对象，而改为直接创建它的若干个被这个方法使用的
  成员变量来代替。将对象拆分后，除了可以让对象的成员变量在栈上(栈上存储的数据，很大机会被虚拟机分配至物理机器的高速寄存器中)分配和读写外，还可以为后续
  进一步的优化手段创造条件。标量替换，不允许对象逃逸出方法范围内
+ 同步消除(Synchronization Elimination)：线程同步本身是比较耗时的过程，若逃逸分析能确定一个变量不会套溢出线程，无法被其他线程访问，那这个变量的
  读写肯定不会有竞争，对这个变量实施的同步措施也就可以安全地消除掉。

jdk现在对逃逸分析还不太成熟，原因主要是其计算成本非常高，甚至不能保证逃逸分析带来的性能收益会高于他的消耗。若要百分百准确地判断一个对象是否会逃逸，需要
进行一系列复杂的数据流敏感的过程间分析，才能确定程序各个分支执行时对此对象的影响。若分析完但几乎没有逃逸对象，则不值当，所以目前虚拟机正采用不那么
准确，但时间压力相对较小的算法完成分析。

C和C++支持栈上分配(不用new即可)，C#也支持值类型，可以很自然地做到标量替换。灵活运用占内存方面是java的弱项。Valhalla中，设计了新的inline关键字用于
定义java的内联类型，目的是实现与C#中值类型对标的功能。以后逃逸分析做起来简单多。
--还是让程序员自己控制，进而帮助虚拟机进行分析判定

模拟逃逸分析，展示逃逸分析实现的效果
```原始代码
public int test(int x){
  int xx = x + 2;
	Point p = new Point(xx, 42);
	return p.getX();
}
```
将Point的构造函数和getX()进行内联
```
public int test(int x){
  int xx = x + 2;
	Point p = point_memory_alloc();  // 在堆中分配P对象的示意方法
	p.x = xx;  // Point构造函数被内联后
	p.y = 42;
	return p.x;  // Point::getX()被内联后
}
```
经过逃逸分析，发现在test()范围内Point对象实例不会发生任何程度的逃逸，可以对它进行标量替换，把其内部的x和y直接置换出来，分解为test()方法内的局部变量。
避免Point对象实例被实际创建
```
public int test(int x){
  int xx = x + 2;
	int px = xx;
	int py = 42;
	return px;
}
```
通过数据流分析，发现py的值对方法不会造成任何影响，可以做无效代码消除
```
public int test(int x){
  return x + 2;
}
```
jdk7才成为服务端编译器默认开启的选项，可以用-XX:+DoEscapeAnalysis手动开启逃逸分析，用-XX:+PrintEscapeAnalysis分查看分析结果。
有了逃逸分析支持后，可以用-XX:+EliminateAllocations开启标量替换，用-XX:PrintEliminateAllocations查看标量替换情况，用-XX:+EliminateLocks开启同步消除，

#### 公共子表达式消除
普遍用于各种编译器的优化技术
若一个表达式E之前已经被计算过，并从先前的计算到现在，E中所有变量的值都没有发生变化，E的这次出现称为公共子表达式
对于这种表达式，只需直接用前面计算过得表达式结果代替E即可。
若这种优化仅限于程序基本块内，可称为局部公共子表达式消除(Local Common Subexpression Elimination)，若这种优化的范围涵盖了多个基本块，称为全局公共
子表达式消除(Global Common Subexpression Elimination)。

举例说明优化过程：
```原始代码
int d = (c * b) * 12 + a + (a + b * c);

未做任何优化的字节码
iload_2 // b
imul // 计算b*c
bipush 12 // 推入12
imul //计算(c*b)*12
iload_1 //a
iadd //计算(c*b)*12+a
iload_1 //a
iload_2 //b
iload_3 //c
imul  //计算b*c
iadd  //计算a+b*c
iadd //计算(c*b)*12+a+a+b*c
istore 4
```
进入虚拟机即时编译器后，将进行如下优化：编译器检测到c*b与b*c是一样的表达式，而且在计算期间b与c的值不变
```
int d = E * 12 + a + (a + E);
```
这时编译器还可能进行代数化简(Algebraic Simplification)，在E本来就有乘法运算的前提下，把表达式变为：
```
int d = E * 13 + a + a;
```
表达式进行变换后，再计算就可以节省时间了。

#### 数组边界检查消除(Array Bounds Checking Elimination)
是即时编译器中的一项语言相关的经典优化技术。
java语言是一门动态安全的语言，对数组的读写访问不像C、C++那样实质上就是裸指针操作。如，一个数组foo[]，访问foo[i]时，系统会自动进行上下界的范围检查，
必须满足i>=0&&i<foo.length，否则出现ArrayIndexOutOfBoundsException。但对虚拟机的执行子系统，每次数据元素的读写都带有一次隐含的条件判定，对于
拥有大量数组访问的程序代码，必定是一种性能负担。

为了安全，数组边界检查肯定要做，但势是不是必须在运行期间一次不漏地进行则可以商量。例如，foo[3]，只要在编译期根据数据流分析来确定foo.length值，并判断
3没有越界，执行时无需判断了。更常见的是，数组访问发生在循环中，并用循环变量来进行数组的访问。若编译期只要通过数据流分析即可判定循环变量的取值范围在
区间[0,foo.length)之内，那么循环中可以把整个数组的上下界检查消除掉，可以节省很多次的条件判断操作

更高视角的检查，如ArrayIndexOutOfBoundsException、NullPointException、AritheticException，使得java虚拟机要做更多的检查，隐式开销。
为了消除隐士开销，除了如数组边界检查优化这种尽可能把运行期检查提前到编译期完成的思路外，还有一种避开的处理思路——隐式异常处理，java中空指针检查和算术
运算中除数为零的检查都采用这种方案。
例如，程序访问一个对象foo的某个属性value，
```虚拟机类似代码
if (foo != null){
  return foo.value;
}else{
  throw new NullPointException();
}
```
使用隐式异常优化后
```
try {
  return foo.value;
}catch(segment_fault){
  uncommon_trap();
}
```
虚拟机会注册一个Segment Fault信号的异常处理器(如uncommon_trap，进程层面的异常处理器)，当foo不为空时对value的访问不会有任何额外的判空开销，而代价是
当foo真为空时，必须转到异常处理器中恢复中断并抛出NullPointException异常。进入异常处理器的过程涉及进程从用户态转到内核态中处理的过程，结束后再回到用户
态，速度远比一次判空检查要慢得多。
当foo极少为空时，隐式异常优化是值得的，hotSpot虚拟机会根据运行期收集到的性能监控信息自动选择最合适的方案。  --大概率事情
其他语言相关的消除操作不少，如Autobox Elimination、Safepoint Elimination、Dereflection等

### 实战：深入理解Graal编译器
背景
Oracle Labs希望它最终能成为一款高编译效率、高输出质量、支持提前编译和即时编译，同时支持应用于包括hotSpot在内的不同虚拟机的编译器。
使用java编写，代码清晰，又继承了许多来自hotSpot服务端编译器的高质量优化技术。

Graal编译器在jdk9时以Jaotc提前编译工具的形式加入，jdk10起，Graal编译器可以替换服务端编译器，成为hotSpot分层编译中最顶层的即时编译器。
这种可替换的即时编译器架构的实现，得益于hotSpot的编译器接口的出现。

jdk9发布的JEP245:Java虚拟机编译器接口(Java Level JVM Compiler Interface, JVMCI)使得Graal可以从HotSpot的代码中分离出来。
JVMCI主要提供三种功能：
+ 响应hotSpot的编译请求，并将该请求分发给java实现的即时编译器
+ 允许编译器访问hotSpot中与即时编译相关的数据结构，包括类、字段、方法及其性能监控数据等，并提供了一组这些数据结构在java语言层面的抽象表示
+ 提供HotSpot代码缓存(Code Cache)的java端抽象表示，允许编译器部署编译完成的二进制机器码。

综合上述，可以把一个在HotSpot虚拟机外部、用java语言实现的即时编译器集成到HotSpot中，响应HotSpot发出的最顶层的编译请求，并将编译后的二进制代码
部署到HotSpot的代码缓存中。

#### 构建编译调试环境
Graal编译器要同时支持Graal VM下的各种子项目，如Truffle、Substrate VM，Sulong等，还要支持作为HotSpot和Maxine虚拟机的即时编译器，所以配置管理复杂。
为了降低代码管理、依赖项管理、编译和测试等环节的复杂度，Graal团队专门用Python 2写了一个名为mx的工具来自动化做好这些事。
安装mx
git clone https://github.com/graalvm/mx.git
export PATH=`pwd`/mx:$PATH
获取Graal编译器代码，代码与整个Graal VM放在一起
git clone https://github.com/graalvm/graal.git
进入compiler子目录，用mx构建Graal编译器，
cd graal/compiler
mx build
创建ideal项目操作
cd graal/compiler
mx intellijinit
设定IDEA的堆用2GB，选择Graal根目录


#### JVMCI编译器接口
JVMCI面向的是java语言的编译器接口，
JVMCI接口需要输入，除了字节码外，hotSpot还会向编译器提供各种该方法的相关信息，如局部变量表中变量槽的个数、操作数栈的最大深入，还有分层编译在底层
收集到的统计信息等。
JVMCI接口，参见JVMCICompiler/CompilationRequest/JavaMethod
找到HotSpotGraalCompiler，是分析的入口
参见GraalDemo

由于存在无限循环，workload方法肯定很快会被虚拟机发现时热点代码因而进行编译。为避免干扰信息太多，加入-XX:CompileOnly来限制只允许workload方法被编译。
采用如下命令，用标准的服务端编译器来运行
javac Demo.java
java -XX:+PrintCompilation -XX:CompileOnly=Demo::workload Demo
193 1 3 Demo::workload (4 bytes)
199 2 1 Demo::workload (4 bytes)
199 1 3 Demo::workload (4 bytes) made not entrant
确实被分层变异了多次，"made not entrant"表示方法的某个已编译版本被丢弃过。
可以看到，分层编译机制及最顶层的服务端编译都以正常工作，下一步是用我们的Graal编译器代替HotSpot的服务端编译器

为简单，加上-XX:-TieredCompilation关闭分层编译，让虚拟机只采用有一个JVMCI编译器而不是由客户端编译器和JVMCI混合分层。用-XX:+EableJVMCI、
-XX:+UseJVMCICompiler启用JVMCI接口和JVMCI编译器。使用-XX:+UnlockExperimentalVMOptions解锁当前实验阶段。

如何让hotSpot找到Graal编译器位置？
若采用特殊版的jdk8，虚拟机将会自动查找JAVA_HOME/jre/lib/jvmci目录。若不存在，会从-Djvmci.class.path.append参数中搜索。
```jdk8的运行配置
-Djvmci.class.path.append=~/graal/compiler/mxbuild/dists/jdk1.8/graal.jar:~/graal/skd/mxbuild/dists/jdk/jdk1.8/graal.jar
-XX:+UnlockExperimentalVMOptions -XX:+EnableJVMCI -XX:UseJVMCICompiler -XX:-TieredCompilation -XX:+PrintCompilation -XX:CompileOnly=Demo::workload
```
若采用jdk9及以上，那原本的Graal编译器是实现在jdk.internal.vm.compiler模块中，用-upgrade-model-path指定这个模块的升级包即可。
```jdk9及以上的运行配置
--module--path=~/graal/sdk/mxbuild/dists/jdk11/graal.jar --upgrade-module-path=~/graal/compiler/mxbuild/dists/jdk11/jdk.internal.vm.compiler.jar
-XX:+UnlockExperimentalVMOptions -XX:+EnableJVMCI -XX:UseJVMCICompiler -XX:-TieredCompilation -XX:+PrintCompilation -XX:CompileOnly=Demo::workload
```
为了确认效果，对HotSpotGraalCompiler类的compileMethod方法改动，输出编译的方法名称和编译耗时，如下
```
public CompilationRequestResult compileMethod(CompilationRequest request) {
long time = System.currentTimeMillis();
CompilationRequestResult result = compileMethod(request, true, graalRuntime.getOptions()); 
System.out.println("compile method:" + request.getMethod().getName()); 
System.out.println("time used:" + (System.currentTimeMillis() - time));
return result; 
}
```
在eclipse中运行这个代码，不需要重新运行mx build，可以看到类似如下输出：
```
97 1 Demo::workload (4 bytes) 
......
compile method:workload
time used:4081
```

#### 代码中间表示
从编译器内部看：字节码->理想图->优化->机器码(以Mach Node Graph表示)的转变过程

理想图是一种有向图，用节点表示程序中的元素，譬如变量、操作符、方法、字段等，用边表示数据或控制流。
譬如表达式：x+y，在理想图中可表示为x、y两个节点的数据流流入加法操作符，表示相加操作读取了x、y的值，流出的便是表示数据流的流向。
理想图本质上是这种将数据流图和控制流图以某种方式合并到一起，用一种边来表示数据流向，另一种边表示控制流向的图形表示

加入参数-Dgraal.Dump，要求Graal编译器把构造的理想图输出
用mx igv命令获取能够支持Graal编译器生成的理想图格式的新版本的Ideal Graph Visualizer工具(https://www.oracle.com/technetwork/graalvm/downloads/index.html)

#### 代码优化与生成
在OutLine视图中找到创建理想图的方法时greateGraph()，可以从Call Hierarchy视图中找到从JVMCI的入口方法compileMethod()到greateGraph之前的调用

greateGrap中调用了StructuredGrap h::Builder创建理想图，两个关键点：
+ 理想图本身的数据结构。是一组不为空的节点的集合，它的节点都是用ValueNode的不同类型的子类节点表示。
+ 如何从字节码转换到理想图。在BytecodeParser勒种，

每一个理想图的节点都有两个共同的主要操作
+ 一是规范化(Canonicalisation)，指如何所见理想图的规模，即在理想图的基础上优化代码索要采取的操作。对应编译器的代码优化
+ 一个是生成机器码(Generation)。对应编译器的代码翻译

从AddNode.canonical可看到为了缩减理想图的规模而做的努力，即使简单也尝试过了：常量折叠(若俩操作数都为常量，则直接返回一个常量节点)、算术聚合(聚合树的
常量子节点，譬如将(a+1)+2聚合为a+3)、符号合并(聚合树的相反符号子节点，譬如(a-b)+b或b+a(a-b)直接合并为a)等多种优化。

对理想图的规范化并不局限在单个操作码的局部范围内，很多优化都要立足于全局来进行，在CanonicalizerPhase中。

代码生成，Graal和其他编译器一样，会先生成低级中间表示(LIR，与具体机器指令集相关的中间表示)，再由HotSpot同一后端来产生机器码。

未验证代码阅读成果，将对AddNode代码做改动，generate中emitAdd->emitSub
用参数-XX:+PrintAssembly，因为从低级中间表示到真正机器码的转换是由HotSpot统一负责，用HSDIS插件，帮助我们输出汇编代码。

Graal编译器的出现对学习和研究虚拟机代码编译技术是实在有着不可估量的价值。
对java编译器的深入了解，有助于在工作中分辨哪些代码时编译器可以帮我们处理的，哪些代码需要自己调节以便更适合编译器的优化。

//todo 剩余课题，graal如何进行编译?
https://github.com/oracle/graal
https://ssw.jku.at/General/Staff/TW/igv.html这不支持mac?..


## java内存模型与线程
衡量一个服务性能的高低好坏，每秒事务处理数(Transactions Per Seoncd, TPS)是重要的指标之一，代表一秒内服务端平均能响应的请求总数。

了解并发内幕仍然是成为一个高级程序员不可缺少的课程

由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统加入一层或多层读写速度尽可能接近处理器运算速度的告诉缓存(Cache)来作为
内存与处理器之间的缓冲。

基于高速缓存交互很好滴解决了处理器与内存速度之间的矛盾，但也为计算机系统带来了更高的复杂度，引入了一个新的问题：缓存一致性(Cache Coherence)。
在多路处理器系统中，每个处理器都有自己的高速缓存，而他们又共享同一主内存(Main Memory)，这种系统称为共享内存多核系统(Shared Memory Multiprocessors
System)。为解决一致性问题，需要各个处理器访问缓存时都遵循一些协议，在读写时根据协议来进行操作，协议有MSI、MESI(Illinois Protocol)、MOSI、
Synapse、Firefly及Dragon Protocol等。

除增加高速缓存外，为了使处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行(Out Of Order Execution)优化，处理器会在计算之后将乱序
执行的结果重组，保证结果与顺序执行的结果一致，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致，因此若存在一个计算任务依赖另外一个计算任务的
中间结果，那么其顺序并不能靠代码的先后顺序来保证。java虚拟机的即时编译器中也有指令重排序(Instruction Reorder)优化。

### java内存模型
规范中曾视图定义一种"java内存模型"(Java Memory Model, JMM)来屏蔽各种硬件和操作系统的内存访问差异，以实现让java程序在各种平台下都能达到一致
的内存访问效果。
这个模型必须定义得足够訡，才能让java的并发内存访问操作不会产生歧义；但也必须定义得足够宽松，使得虚拟机的实现能有足够的自由空间去利用硬件的各种特性(
寄存器、高速缓存和指令集中某些特有的指令)来获取更高的执行速度。

#### 主内存与工作内存
java内存模型的主要目的是定义程序中各种变量的访问规则，关注在虚拟机中把变量值存储到内存和从内存中取出变量值这样的底层细节。
此处变量(Variables)包括实例字段、静态字段和构成数组对象的元素，不包括局部变量与方法参数，因为后者是线程私有，不会被共享，不存在竞争。
为获得更高的执行效能，java内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器是否要进行调整代码执行顺序
这类优化措施。

java内存模型规定了所有的变量都存储在主内存(Main Memory)中(也是虚拟机的一部分)。每条线程还有自己的工作内存(Working Memory)，线程的工作内存中
保存了被该线程使用的变量的主内存副本，线程对变量的所有操作(读取、赋值等)都必须在工作内存中进行，不能直接读写主内存中的数据。不同的线程之间也无法
直接访问对方工作内存中的变量，线程间变量值的传递均需通过主内存完成。

#### 内存间交互操作
关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存这一类的实现细节，java内存模型中定义了8
种操作来完成。java虚拟机实现时必须保证下面每一种操作都是原子、不可再分。
+ lock(锁定)：作用于主内存的变量，把一个变量表示为一条线程独占的状态
+ unlock(解锁)：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。
+ read(读取)：作用于主内存的变量，把一个变量的值从主内存传输到线程的工作内存，以便随后的load动作使用
+ load(载入)：作用于工作内存的变量，把read操作从主内存中得到的变量值放入工作内存的变量副本中。
+ use(使用)：作用于工作内存的变量，把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。
+ assign(赋值)：作用于工作内存的变量，把一个从执行引擎接收的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。
+ store(存储)：作用于工作内存的变量，把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用
+ write(写入)：作用于主内存的变量，把store操作从工作内存中得到的变量值放入主内存的变量中。

若要把一个变量从主内存拷贝到工作内存，要按顺序执行read和load操作。若要把变量从工作内存同步回主内存，按顺序执行store和write操作。
注意，java内存模型只要求上述两个操作必须按顺序执行，但不要求连续执行。

java内存模型还规定在执行上述8种基本操作时必须满足规则：
+ 不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或工作内存发起回写了但主内存不接受的情况。
+ 不允许一个线程丢弃它最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。
+ 不允许一个线程无原因地(没有发生过任何assign操作)把数据从线程的工作内存同步回主内存中
+ 一个新的变量只能在主内存中"诞生"，不允许在工作内存中直接使用一个未被初始化(load或assign)的变量，即对一个变量实施use、store之前，必须先执行
  assign和load操作
+ 一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock，变量才会解锁
+ 若对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，要重新执行load或assign操作以初始化变量的值。
+ 若一个变量事先没有被lock锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定的变量
+ 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中(执行store、write操作)

这8中内存访问操作以及上述规则限定，再加上专门针对volatile的一些特殊规定，就能准确地描述出java程序中哪些内存访问操作在并发下才是安全的

#### 对于volatile型变量的特殊规则
volatile是java虚拟机提供的最轻量级的同步机制

当变量被定义为volatile后，具备特性：
1)保证此变量对所有线程的可见性，这里的“可见性”指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。

由于volatile只能保证可见性，在不符合一下两条规则的运算场景中，仍然要通过加锁来保证原子性：
+ 运算结果并不依赖变量的当前值，或者能确保只有单一的线程修改变量值
+ 变量不需要与其他状态变量共同参与不变约束

例如shutdown场景，控制多线程停止
```
while (!shutdownRequested) {
}
```
--但这种真的好吗？都在空旋转

2)禁止指令重排序优化。普通的变量仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码
中的执行顺序一致。
因为同一个线程的方法执行过程中无法感知到这点，这就是java内存模型中描述的"线程内表现为串行的语义"(Within-Thread As-IF-Serial Semantics)

```指令重排序影响程序并发执行
Map configOptions;
char [] configText;
volatile boolean initialized = false;

// a线程
configOptions = new HashMap();
configText = readConfigFile(fileName);
processConfigOptions(configText, configOptions);
initialized = true;

// b线程
while(!initialized){
  sleep();
}
dosomethingWithConfig();
```
若没有用volatile修饰initialized变量，可能由于指令重排序的优化，导致线程a中最后一条代码`initialized = true`被提前执行，这样在线程b中使用配置
信息的代码可能出现错误，而volatile可以避免此类问题

另一个双重检测(Double Check Lock, DCL)代码，可观察到加入volatile和未加入volatile时生成的汇编代码的差别(获取即时编译的汇编代码用HSDIS)
```DCL单例代码
public class Singleton{
  private volatile static Singleton instance;
	public static Singleton getInstance(){
	  if (instance == null){
		  synchronized(Singleton.class){
			  if (instance == null){
				 instance = new Singleton();
				}
			}
		}
		return instance;
	}
	main(){
	  Singleton.getInstance();
	}
}
```
编译后前后对比，发现，关键变化在于有volatile修饰的变量，赋值后(mov %eax, 0x150(%esi))多执行了一个`lock addl $0x0, (%esp)`操作，这个操作的作用
相当于一个内存屏障(Memory Barrier或Memory Fence，指令重排序时不能把后面的指令重排序到内存屏障之前的位置，不要混淆于垃圾收集时捕获变量访问
的内存屏障)，只有一个处理器访问内存时，不需要内存屏障；但若有多个处理器访问同一块内存时，且其中有一个在观测另一个时，需要内存屏障保证一致性。

指令`addl $0x0, (%esp)`(把ESP寄存器的值加0)是一个空操作，用这个空操作而不是专用指令nop，是因为IA32手册规定lock前缀不允许配合nop指令使用。
关键在于lock前缀，查询IA32手册可知，他的作用是将本处理器的缓存写入了内存，该写入动作也会引起别的处理器或别的内核无效化(Invalidate)其缓存，相当于对
缓存中的变量做了一次store和write操作。通过这样一个空操作，可让前面volatile变量的修改对其他处理器立即可见。

从硬件架构上讲，指令重排徐是指处理器采用了允许将多条指令不安程序规定的顺序分开发送给各个相应的电路单元进行处理。但并不是说指令任意重排，处理器必须能
正确处理指令依赖情况保障程序能得出正确的执行结果。因此，`addl $0x0, (%esp)`指令把修改同步到内存时，意味着所有之前的操作都已经执行完成，这便
形成了“指令重排序无法越过内存屏障”的效果。--就是将内存刷新，保证可见性了，也就看起来不重排序了。。

volatile变量读操作的性能消耗与普通变量几乎没有差别，但写操作可能会慢一些，因为需要在本地代码中插入许多内存屏障指令来保证处理器不会发生乱序执行。
在选择volatile与锁的唯一判断依据仅仅是volatiel的语义能否满足使用场景的需求。

java内存模型对volatile变量定义的特殊规则的定义。
假定T表示一个线程，V和W表示两个volatile型变量，进行read、load、use、assign、store、write时需要满足规则：
+ 只有当线程T对变量V执行的前一个动作是load时，线程T才能对变量V执行use动作；并且只有当线程T对变量V执行的后一个动作是use时，线程T才能对变量V执行
  load动作。线程T对变量V的use动作可以认为是和线程T对变量V的load、read动作相关联的，必须连续且一起出现。--read/load/use
  这规则要求在工作内存中，每次使用V前都必须先从主内存刷新最新的值，用于保证其能看见其他线程对变量V所做的修改。
+ 只有当线程T对变量V执行的前一个动作是assign时，线程T才能对变量V执行store动作；并且，只有当线程T对变量V执行的后一个动作是store时，线程T才能对
  变量V执行assign操作。线程T对变量V的assign动作可以认为是和线程T对变量V的store、write动作相关联的，必须连续且一起出现。--assign/store/write
  这规则要求在工作内存中，每次修改V后都必须立刻同步回主内存中，用于保证其他线程可以看到自己对变量V所做的修改
+ 假定：
  动作A是线程T对变量V实施的use或assign动作，动作F是和动作A相关联的laod或store动作，动作P是和动作F相应的堆变量V的read或write动作；
  动作B是线程T对变量实施的use或assign动作，动作G是和动作B相关联的laod或store动作，动作Q是和动作G相应的对变量W的read或write动作。
  若A先于B，那么P先于Q。
  这规则要求volatile修饰的变量不会被指令重排序优化，从而保证代码的执行顺序与程序的顺序相同

#### 针对long和double型变量的特殊规则
java内存模型要求lock、unlock、read、load、assign、use、store、write这8种操作原子性，
但对64位的数据类型(long和double)，在模型中特别定义了一条宽松的规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作，
即允许虚拟机实现自行选择是否要保证64位数据类型的load、store、read和write操作的原子性，是long和double的非原子性协定(Non-Atomic Treatment of
double and long Variables)

若有多个线程共享一个并未声明为volatile的long或double类型的变量，并同时对他们进行读取和修改，那么某些线程可能会读取到一个“半个变量”的数值。不过对于
目前主流64位java虚拟机并不会出现这种问题。
实际开发中，除非该数据有明确可知的线程竞争，否则在代码中一般不需要因为这个原因刻意把long和double声明为volatile
--看样子，只需要关注是否有线程安全，否则不用考虑处理器处理64位数据的问题。

#### 原子性、可见性与有序性
java内存模型是围绕在并发过程中如何处理原子性、可见性和有序性这三个特征来建立的。

1. 原子性(Atomicity)
   由java内存模型来直接保证原子性变量操作包括read、load、assign、use、store和write，基本可认为，基本数据类型的访问、读写操作都具备原子性。
   若应用需要更大范围的原子性保证，java内存模型还提供了lock和unlock满足，提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这俩操作。
   反映到java代码就是同步块——synchronized。

2. 可见性(Visibility)
   指当一个线程修改了共享变量的值时，其他线程能够立刻得知这个修改。java内存模型是通过在变量修改后将新值同步到主内存，在变量读取前从主内存刷新变量值
   这种依赖主内存作为传递媒介的方式来实现可见性的，不论是普通变量还是volatile变量都是如此。
   区别是：volatile特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。因此可以说volatile保证了多线程操作时变量的可见性，
   而普通变量则不能保证这一点。

还有俩关键字也能实现可见性：synchronized和final。
同步块的可见性是由"对一个变量执行unlock操作之前，必须先把此变量同步回主内存中(执行store、write操作)"这条规则获得的。
final的可见性是指：被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把this的引用传递出去(this引用逃逸很危险，其他线程可能通过这个引用
访问到初始化一半的对象)，那么其他线程就能看见final字段的值。

如下i和j都具备可见性，无须同步就能被其他线程正确访问
```final与可见性
public static final int i;
public final int j;
static{
  i = 0;
}
{
	j = 0;  // 也可在构造函数中初始化
}
```
--构造对象时由jvm保证可见性，多线程使用时即可见

3. 有序性(Ordering)
   java程序中天然的有序性：若在本线程内观察，所有的操作都是有序的；若在一个线程中观察另一个线程，所有的操作都是无序的。
   前半句指"线程内表现为串行的语义"(Within Thread As-If-Serial Semantics)，后半句指"指令重排序"现象和"工作内存与主内存同步延迟"现象

java语言提供了volatile和synchronized保证线程之间操作的有序性，volatile本身包含了禁止指令重排序的语义。
synchronized是由"一个变量在同一个时刻只允许一条线程对其进行lock操作"这条规则获得。这个规则决定了持有一个锁的两个同步块只能串行地进入。

synchronized在需要这三种特性的时候都能作为其中一种解决方案，但万能也间接造就了滥用，越万能的并发控制，通常伴随越大的性能影响。

#### 先行发生原则
若java内存模型中所有的有序性都仅靠volatile和synchronized来完成，那么很多操作都会变得啰嗦，而java语言中有一个Happens-Before原则让我们简洁。
它是判断数据是否存在竞争，线程是否安全的有用手段。

先行发生是ajva内存模型中定义的两项操作之前的偏序关系，比如操作A先行发生于操作B，是说在发生操作B之前，操作A产生的影响能被操作B观察到。"影响"包括
修改了内存中共享变量的值、发送了消息、调用了方法等。
```先行发生原则实例
// a线程执行
i = 1;

// b线程执行
j = i;

// c线程执行
i = 2;
```
假设：线程a中操作`i=1`先行发生于线程B的`j=i`，那就可以确定在线程b的操作执行后，变量j的值一定是1，
依据有俩：
+ 一是根据先行发生原则，i=1的结果可以被观察到；
+ 二是线程C还没登场，线程a操作结束后没有其他线程会修改i的值。

考虑线程c，依然保持a和b的先行发生关系，而c出现在线程a和b操作之间，但c和b没有先行发生关系，那j的值时多少？答案不确定，1和2都可能，因为线程c对变量i
的影响可能会被线程b观察到，也可能不会。这时线程b存在读取到过期数据的风险，不具备多线程安全性。

java内存模型下一些"天然的"先行发生关系(若俩操作之间的关系不在此列，并无法从下列规则推导出来，则他们没有顺序性保障，虚拟机可以对他们随意重排序)：
+ 程序次序规则(Program Order Rule)：一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。
  注：这里说的是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构
+ 管程锁定规则(Monitor lock Rule)：一个unlock操作先行发生于后面对同一个锁的lock操作。必须强调同一个锁，"后面"指时间上的先后
+ volatile变量规则(Volatile Variable Rule)：对一个volatile变量的写操作先行发生于后面对这个变量的读操作。"后面"指时间上的先后
+ 线程启动规则(Thread Start Rule)：Thread对象的start()方法先行发生于此线程的每一个动作。
+ 线程终止规则(Thread Termination Rule)：线程中的所有操作都先行发生于对此线程的终止检测，可以通过Thread::join()方法是否结束、Thread::isAlive()
  的返回值等手段检测线程是否已终止执行。--返回true之前的任何动作都可见
+ 线程中断规则(Thread Interruption Rule)：对线程interrupt()调用先行发生于被中断线程的代码检测到中断事件的发生，可通过Thread::interrupted检测
+ 对象终结规则(Finalizer Rule)：一个对象的初始化完成(构造函数执行结束)先行发生于他的finalize()方法的开始
+ 传递性(Transitivity)：若操作A先行发生于操作B，操作B先行发生于操作C，那可得出操作A先行发生于操作C的结论

演示如何使用这些规则去判定操作间是否具备顺序性，对于读写共享变量的操作，就是线程是否安全。可从下面例子感受"时间上的先后顺序"与"先行发生"之间不同

```先行发生原则示例
private int value = 0;
public void setValue(int value){
  this.value = value;
}
public int getValue(){
  return value;
}
```
假设存在线程a和b，线程a先(时间上的先后)调用了setValue(1)，然后线程b调用了同一个对象的getValue()，那么线程b收到的返回值是什么？
依次分析一下先行发生原则中的各项规则：
由于俩方法分别由线程a和b调用，不在一个线程中，所以程序次序规则不适用；
由于没有同步块，不会发生lock和unlock，所以管程锁定规则不适用；
由于value没有被volatile修饰，所以volatile变量规则不适用；
后面的线程启动、终止、中断规则和对象终结规则也不适用；
因为没有一个适用的先行发生规则，所以传递性也没有。
因此可以判定，尽管线程a在操作时间上先于b，但无法确定线程b中getValue()犯法的返回结果，不能确定happens-before，即这里的操作不是线程安全。

简单修复方案：
+ 把getter/setter方法定义为synchronized，可以套用管程锁定规则
+ 把value定义为volatile，由于setter方法对value的修改不依赖value的原指，满足volatile使用场景，可以套用volatile变量规则来实现先行发生关系。

上例，可得出结论：一个操作"时间上的先发生"不代表这个操作会是"先行发生"。
但一个操作"先行发生"，也不能推导出这个操作必定是"时间上的先发生"，如下例子，指令重排徐。

```先行发生原则示例3
// 同一个线程中
int i = 1;
int j = 2;
```
一个线程中执行，根据程序次序规则，int i=1操作先行发生于int j=2，但后者完全可能先被处理器执行，这并不影响先行发生原则的正确性，因为我们在这条
线程之中没有办法感知到这一点。 --关键是，不影响结果，那么没必要考虑一定时间上先后执行

以上可得出结论：时间先后顺序与先行发生原则之间基本没有因果关系，所以衡量并发安全问题时不要受时间顺序的干扰，一切必须以现象发生原则为准。happens-before

### java与线程

#### 线程的实现
线程是比进程更轻量级的调度执行单位，可以把一个进程的资源分配和执行调度分开，各个线程既可以共享进程资源(内存地址、文件I/O等)，又可以独立调度。
目前线程是java里进行处理器资源调度的最基本单位，不过日后Loom项目引入纤程(Fiber)可能会改变。

主流操作系统都提供线程实现，java语言则提供了在不同硬件和操作系统平台下对线程操作的统一处理，每个已经调用过start()方法且还未结束的Thread类的实例代表
一个线程。
一个native方法意味着没有使用或无法使用平台无关的手段来实现(通常最高效的手段是平台相关手段)。

实现线程主要三种方式：使用内核线程实现(1:1实现)，使用用户线程实现(1:N实现)，使用用户线程加轻量级进程混合实现(N:M实现)

1. 内核线程实现
   内核线程(Kernel-Level Thread, KLT)，是直接由操作系统内核(Kernel)支持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器(Scheduler)对线程
   进行调度，并负责将线程的任务映射到各个处理器上。
   每个内核线程都可以视为内核的一个分身，这样操作系统就有能力同时处理多件事情，支持多线程的内核称为多线程内核(Multi-Threads Kernel)。

程序一般不会直接用内核线程，而是使用内核线程的一种高级接口——轻量级进程(Light Weight Proces，LWP)，轻量级进程就是通常意义上的线程，由于每个轻量级进程
都由一个内核线程支持，因此只有线支持内核线程，才能有轻量级进程。
这种轻量级进程与内核线程之间1:1的关系成为一对一的线程模型

由于内核线程的支持，每个轻量级进程都成为一个独立的调度单元。
局限性：
+ 由于是基于内核线程实现，所以各种线程操作，如创建、析构及同步，都需要进行系统调用。系统调用的代价相对较高，需要再用户态(User Model)和内核态(Kernel
  Mode)中来回切换。
+ 每个轻量级进程都需要有一个内核线程的支持，因此轻量级进程要消耗一定的内核资源(如内核线程的栈空间)，因此一个系统支持轻量级进程的数量有限

2. 用户线程实现
   广义上，一个线程只要不是内核线程，都可以认为是用户线程(User Thread, UT)的一种。
   狭义上，指完全建立在用户空间的线程库上，系统内核不能感知到用怒线程的存在及如何实现的。用户线程的建立、同步、销毁和调度完全在用户态完成，不需内核的
   帮助。若实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗，也能支持规模更大的线程数量，部分高性能数据库的多线程就是由用户线程
   实现的。
   这种进程与用户线程之间的1:N的关系成为一对多的线程模型

优势在于不需要系统内核支援，劣势也在于没有系统内核的支援，所有线程操作都需要由用户程序自己去处理。
线程的创建、销毁、切换和调度都是用户必须考虑的问题，而且由于操作系统只把处理器资源分配到进程，那诸如"阻塞如何处理"，"多处理器系统中如何将线程映射
到其他处理器上"这类问题需要解决，甚至有些事不可能实现的。

3. 混合实现
   既存在用户线程，又存在轻量级进程。用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。
   而操作系统支持的轻量级进程则作为用户线程和内核线程之前的桥梁，这样可以使用内核提供线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级
   进程来完成，大大降低整个进程被完全阻塞的风险。
   混合模式中，用户线程与轻量级进程的数量比是不定的，是N:M关系。

许多Unix系列的操作系统，如Solaris、HP-UX等都提供了M:N的线程模型实现。这些操作系统上的应用也相对容易应用M:N的线程模型

4. java线程的实现
   java线程在jdk1.3起，主流商用java虚拟机的线程模型普遍用基于操作系统原生线程模型来实现，即采用1:1的线程模型
   例如hotSpot，每一个java线程都是直接映射到一个操作系统原生线程来实现的，中间没有额外的间接结构，所以hotSpot自己不会去干涉线程调度。全权交给地下的
   操作系统去处理，所以何时冻结或唤醒、该给线程分配多少处理器执行时间、改把线程安排给哪个处理器核心去执行等，都是由操作系统完成、全权决定。

线程模型只对线程的并发规模和操作成本产生影响，而对java程序的编码和运行过程来首，这些差异都是完全透明的。

#### java线程调度
线程调度指系统为线程分配处理器使用权的过程，主要方式有两种：
+ 协同式(Cooperative Threds Scheduling)线程调度
+ 抢占式(Preemptive Threads Scheduling)线程调度

使用协同式调度的多线程系统，线程的执行时间由线程本身控制，线程把自己的工作执行完后，要主动统治系统切换到另外一个线程去。
好处：是实现简单，而且由于线程要把自己的事情干完后才进行线程切换，切换操作对线程自己可知，所以一般没有什么线程同步问题。
坏处：线程执行时间不可控制，甚至若一个线程的代码有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在哪里。

使用抢占式调度的多线层系统，每个线程将由系统来分配执行时间，线程的切换不由线程本身决定。如java中，Thread::yield()可以主动让出执行时间，但若想要
主动获取执行时间，线程本身没有办法。这种实现线程调度的方式下，线程的执行时间时系统可控的，也不会有一个线程导致整个进程甚至整个系统阻塞的问题。
java使用的线程调度方式就是抢占式调度。

#### 状态转换
java语言定义了6种线程状态，在任意一个时间点上，一个线程只能有且只有其中一种状态，并可以通过特定的方法在不同状态之间转换：
+ 新建(New)：创建后尚未启动的线程。
+ 运行(Runnable)：包括操作系统线程状态中的Running和Ready，可能正在执行，也可能正在等待着操作系统为它分配执行时间。
+ 无限期等待(Waiting)：不会被分配处理器执行时间，要等待被其他线程显式唤醒。以下方式会让线程陷入无限期的等待状态：
    + 没有设置Timout参数的Obejct::wait()方法
        + 没有设置Timeout的Thread::join()方法
        + LockSupport::park()方法
+ 限期等待(Timed Waiting)：不会被分配处理器执行时间，在一定时间之后会由系统自动唤醒。
    + Thread.sleep()
        + 设置了Timeout的Object::wait()
        + 设置了Timeout的Thread::Join()
        + LockSupport::parkNanos()
        + LockSupport::parkUntil()
+ 阻塞(Blocked)：线程被阻塞了，在程序等待进入同步区域时，线程进入这种状态。
  阻塞状态在等待着获取到一个排他锁，这个事件在另一个线程放弃这个锁时发生。
  等待状态是在等待一段时间，或唤醒动作的发生。
+ 结束(Terminated)：已终止线程的线程状态，线程已经结束执行

状态转换：
New->Running：start
Running->Blocked：synchronized
Running->Timed Waiting：sleep
Running->Waiting：wait
Running->Terminated：run结束
Waiting->Running：notify/notifyAll

### java与协程
java早起，java语言抽象出隐藏了各种操作系统差异性的统一线程接口，曾经是区别于其他编程语言的一大优势，语言与框架自动屏蔽了很多同步和并发的复杂性。
时至今日，这种便捷的并发编程方式和同步的机制依然在有效的运作着，但在某些场景下，显得出疲态

#### 内核线程的局限
java目前的并发编程机制与现在的微服务矛盾，1:1的内核线程模型是如今java虚拟机线程实现的主流选择，但这种映射到操作系统上的线程坦然的缺陷是切换、调度
成本高昂，系统能容纳的线程数量业有限。

传统的java web服务器的线程池的容量通常几十个到两百之间，当程序员把数以百万技的请求往线程池里灌时，系统即使能处理的来，但其中的切换损耗也相当可观。
现实的需求在破事java去研究新的解决方案。

#### 协程的复苏
内核线程的调度成本主要来自于用户态和核心态之间的状态转换，而这两种状态转换的开销主要来自于响应中断、保护和恢复执行现场的成本。

如下场景，发生了一次线程切换
线程A->系统中断->线程B
处理器要去执行线程A的程序代码时，程序是数据与代码的组合体，代码执行时需要有上下文数据的支撑。
这里的上下文
+ 以程序员角度看，是方法调用过程中的各种局部变量与资源；
+ 以线程的角度看，是方法的调用栈中存储的各类信息
+ 以操作系统和硬件的角度看，是存储在内存、缓存和寄存器中的一各个具体数值。

物理硬件的各种存储设备和寄存器是被操作系统内所有线程共享的资源，当中断发生，从线程A切换到线程B去执行之前，操作系统首先要把线程A的山下文数据妥善
保管好，然后把寄存器、内存分页等恢复到线程B挂起时的状态，这样线程B被重新激活后才能仿佛从来没有被挂起过。
这种保护和恢复现场的工作，涉及一系列数据在各种寄存器、缓存中的来回拷贝，不可能是一种轻量级的操作

如果说内核线程的切换开销是来自保护和恢复现场的成本，那若改为采用用户线程，这部分的开销也不能省略。但是，一旦把保护、恢复现场及调度的工作从操作系统
交到程序员手上，可以脑洞大开，玩出很多新的花样来缩减这些开销

古老操作系统是单人单工作业形式，就出现栈纠缠(Stack Twine)的、由用户自己模拟多线程、直接保护恢复现场的工作模式。
大致原理是：通过在内存里划出一片额外空间来模拟调用栈，只要其他线程中方法压栈、退栈时遵守规则，不破坏这片空间即可。

由于最初多数的用户线程是被设计成协同式调度(Cooperative Scheduling)的，所以有别名——协程(Coroutine)。又由于这时的协程会完整地做调用栈的保护、
恢复工作，所以也称为有栈协程(Stackfull Coroutine)。
无栈协程，典型应用是各种语言中的await、async、yield这类关键字。本质是一种有限状态机，状态保存在闭包里，比有栈协程恢复调用栈要轻量得多，但功能
也相对更有限。

协程的主要优势是轻量，无论是有栈协程还是无栈协程，都比传统内核线程轻量得多。
也有局限，需要再应用层面实现的内容(调用栈、调度器等)特别多。甚至今天，很多语言和框架中会被设计成协同式调度，这样在语言运行平台或框架上的调度器就可以
做得非常简单。

具体到java语言，还会有一些特别的限制，如hotSpot，java调用栈和本地调用栈是做在一起的。若在协程中调用了本地方法，还能否正常切换协程而不影响整个线程？
若协程中遇传统的线程同步措施会怎样？譬如kotlin提供的协程实现，一旦遇到synchronized，那挂起来的仍将是整个线程。

#### java的解决方案
对于有栈协程，有一种特例实现名为纤程(Fiber)。openjdk创建Loom项目，是java用来解决上述场景的方案，是一种典型的有栈协程

What is a fiber?
+ A light weight or user model thread, scheduled by the java virtual machine, not the operating system
+ Fibers are low footprint and have negligible task-switching overhead. You can have millions of them!

Loom背后的意图是重新提供对用户线程的支持，会有两个并发编程模型在java虚拟机中共存。新模型有意识地保留了与目前线程模型相似的API设计，这样现有代码不需要
为了使用纤程而进行过多改动。

在新并发模型下，一段使用纤程并发的代码会被分为两部分——执行过程(Continuation)和调度(Scheduler)。
执行过程主要用于维护执行现场，保护、恢复上下文状态，调度器则负责编排所有要执行的代码的顺序。
将调度程序与执行过程分离的好处是，用户可以选择自行控制其中的一个或者多个，而且java中现有的调度器也可以被直接重用。
实际上，Loom中默认的调度器是已存在的用于任务分解的Fork/Join池


## 线程安全与锁优化
面向过程的编程思想：以算法为核心，把数据和过程分别作为独立的部分来考虑，数据代表问题空间中的客体，程序代码用于处理这些数据，站在计算机的角度去抽象
问题和解决问题。
面向对象的编程思想：站在现实世界的角度去抽象和解决问题，把数据和行为都看做对象的一部分，可以让程序员以符合现实世界的思维方式来编写和组织程序

面向对象的编程思想极大地提升了现代软件开发的效率和软件可以达到的规模，但现实世界与计算机世界之间不可避免地存在一些差异。如，人们很难想象现实中对象
在一项工作进行期间，会不停地中断和切换，对象的属性(数据)可能会在中断期间被修改和变脏，而这些事件在计算机世界中很普遍。
有时，良好的设计原则不得不向现实做出一些妥协，必须保证程序在计算机中正确地运行，再考虑如何将代码组织得更好，让程序运行的更快。

### 线程安全
当多个线程同时访问一个对象时，若不用考虑这些线程在运行时环境性下的调度和交替执行，也不需要进行额外的同步，或在调用方进行任何其他的协调操作，调用这个
对象的行为都可以额获得正确的结果，那称这个对象是线程安全的。

线程安全的代码具备一个共同特征：代码本身封装了所有必要的正确性保障手段(如互斥同步等)，令调用者无须关心多线程下的调用问题，更无须自己实现任何措施来
保证多线程环境下的正确调用。

### java语言中的线程安全
按照线程安全的"安全程度"由强至弱来排序将java语言中各种操作共享的数据分为以下五类：不可变、绝对线程安全、相对线程安全、线程兼容和线程对立

1. 不可变
   java语言中不可变(Immutable)的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要进行任何线程安全保障措施。
   只要一个不可变的对象被正确地构建出来(没有发生this引用逃逸)，那其外部的可见状态永远都不会改变，永远都不会看到他在多线程之中处于不一致的状态。

java中，若多线程共享的数据是一个基本数据类型，那在定义时用final就可以保证它是不可变的。若共享数据是一个对象，需要对象自行保证其行为不会对其状态产生
任何影响。

2. 绝对线程安全
   一个类要达到"不管运行时环境如何，调用者都不需要任何额外的同步措施"可能需要付出非常高昂的，甚至不切实际的代价
   javaAPI中保住线程安全的类，大多都是绝对的线程安全。
   参见VectorSafeTest 假如Vector一定要做到绝对的线程安全，必须在它内部维护一组一致性的快照访问才行，每次对其中元素进行改动都要产生新的快照，这样付出的时间和空间成本都非常大。
   --类似copyOnWrite？

3. 相对线程安全
   需要保证对这个对象单次的操作是线程安全的，在调用时不需要进行额外的保障措施，但是对于一些特定顺序的连续调动，可能需要再调用端使用额外的手段保证调用的
   正确性。
   VectorSafeTest中都是相对安全的例子
   java中大部分生成线程安全的类都属于这种类型。如Vector、HashTable、Collections的synchronizedCollection等

4. 线程兼容
   指对象本身并不是线程安全，但可以通过在调用端正确地使用同步来保证对象在并发环境中可以安全地使用。通常说一个类不是线程安全的，就是这种。
   如hashmap、arrayList

5. 线程对立
   指不管调用端是否采取同步措施，都无法在多线程环境中并发使用代码。由于java天生支持多线程，线程对立这种排斥多线程的代码很少出现，通常要避免
   如Thread的suspend/resume，System.setIn()/System.setOut/System.runFinalizersOnExit等

### 线程安全的实现方法
只要明白了java虚拟机线程安全措施的原理与运作过程，自己再去思考代码如何编写就不是困难事了。

1. 互斥同步(Mutual Exclusion & Synchronization)
   一种常见也是最主要的并发正确性保障手段。
   同步，指在多个线程并发访问共享数据时，保证共享数据在同一时刻只被一条(或一些，当使用信号量时)线程使用。
   互斥，是实现同步的一种手段，如临界区(Critial Section)、互斥量(Mutex)和信号量(Semaphore)。
   互斥是因，同步是果；互斥是方法，同步是目的

java中最基本的互斥同步手段是synchronized，是一种块结构(Blck Structured)的同步语法。经javac编译后，在同步块的前后形成monitorenter和
monitorexit俩字节码。其需要一个reference类型的参数指明要锁定和解锁的对象。
规范要求，执行monitorenter时，先去尝试获取对象的锁，若对象没有被锁定，或当前线程已持有对象的锁，就把锁的计数器+1，在执行monitorexit时将
计数器-1。一旦计数器值为0，锁随即被释放。若获取对象锁失败，那当前线程就应当被阻塞等待，直到请求锁定的对象被持有它的线程释放为止。

得出直接推论：
+ 被synchronized修饰的同步块对同一条线程来说是可重入的。反复进入同步块不会出现死锁
+ 被synchronized修饰的同步块在持有锁的线程执行完毕并释放锁之前，会无条件地阻塞后面其他线程的进入。无法像处理某些数据库中的锁那样，强制已获取
  锁的线程释放锁；也无法强制正在等待锁的线程中断等待或超时退出。

持有锁是一个和重量级(Heavy-Weight)的操作。java的线程是映射到操作系统的原生内核线程之上的，若要阻塞或唤醒一条线程，需要操作系统帮忙，不可避免
地陷入用户态到核心态的转换，要耗费很多处理器时间。
jdk5起java.util.concurrent中提供Lock接口，用户能以非块结构(Non-Block Structured)来实现互斥同步，摆脱语言特性的束缚，改为在类库层面去实现
同步，也为日后扩展出不同调度算法、不同特征、不同性能、不同语义的各种锁提供了广阔空间

ReentrantLock与synchronized增加了一些高级功能，主要有3项：等待可中断、可实现公平锁、可以绑定多个条件
+ 等待可中断：指当前持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情。这对处理执行时间非常唱的同步块有帮助
+ 公平锁：指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来一次获得锁。synchronized中的锁时非公平的，ReentrantLock默认也是非公平的。
  不过一旦使用公平锁，会导致性能下降，明显影响吞吐量
+ 锁绑定多个条件：值一个ReentrantLock对象可以同时绑定多个Condition对象。在synchronized中，锁对象的wait和notify、notifyAll可以实现一个
  隐含的条件，若要和多于一个的条件关联时，不得不额外添加一个锁

基于以下原因，推荐在synchronized和ReentrantLock都可满足时优先用synchronized
+ synchronized是在java语法层面的同步，足够清晰，简单。都熟悉
+ Lock应该确保在finally中释放锁。必须由程序员自己保证，而用synchronized可以由java虚拟机确保即时异常，锁也能被自动释放
+ 长远看，虚拟机更容易对synchronized进行优化，因为虚拟机可以在线程和对象的元数据中记录synchronized中锁相关信息，而用Lock，虚拟机很难得知具体
  哪些锁对象是由特定线程锁持有的。

2. 非阻塞同步
   互斥同步面临的主要问题是：进行线程阻塞和线程唤醒所带来的性能开销，被称为阻塞同步(Blocking Synchronization)。属于一种悲观的并发策略，总是认为
   只要不去做正确的同步措施(如加锁)，那肯定会有问题，五路你共享的数据是否真的会出现竞争，都会进行加锁。将会导致用户态到核心态转换、维护锁计数器和
   检查是否有被阻塞的线程需要被唤醒等开销。
   随着硬件指令集的发展，有另外一种选择：基于冲突检测的乐观并发策略，不管风险，先进行操作，若没有其他线程争用共享数据，那操作成功；若有争用产生冲突，
   那再进行其他的补偿措施，例如不断地重试，直到出现没有争用的共享数据为止。不需要把线程阻塞挂起，被称为非阻塞同步(Non-Blocking Synchronization)，
   使用这种措施的代码被称为无锁(Lock-Free)编程。
   --非阻塞，是针对线程是否被阻塞挂起的

必须要求操作和冲突检测俩步骤具备原子性，靠硬件来完成。这类常用指令
+ 测试并设置(Test-and-Set)
+ 获取并增加(Fetch-and-Increment)
+ 交换(Swap)
+ 比较并交换(Compare-and-Swap,CAS)
+ 加载链接/条件存储(Load-Linked/Store-Conditional，LL/SC)

CAS指令需要三个操作数：
+ 内存位置(java中可简单理解为变量的内存地址，用V表示)
+ 旧的预期值(用A表示)
+ 准别设置的新值(用B表示)
  CAS指令执行时，当且仅当V符合A时，处理器才会用B更新V的值，否则不执行更新。不管是否更新了V的值，都返回V的旧值。整个过程是一个原子操作，执行期间不会
  被其他线程中断

参见AtomicTest，保证原子性而且比synchronized高效

CAS无法涵盖互斥同步的所有使用场景。
CAS从语义上存在一个逻辑漏洞：若一个变量V初次读取时是A值，并且在准备赋值时检查到它仍然是A值，那就能说明它的值没有被其他线程改变过吗？不能，因为若
在这段期间它的值曾被改变成B，后来又改回为A，那CAS操作会误认为它没有被改变过。称为CAS操作的ABA问题。解决方案是用AtomicStampedReference，带有
标记的原子引用类，可以通过控制变量值的版本来保证CAS的正确性。
不过大部分情况下ABA不会影响程序的正确性，若需要解决ABA问题，改用传统的互斥同步可能会比原子类更为高效
--可能要考虑竞争程度的量来决定使用cas还是synchronized方式。

3. 无同步方案
   同步与线程安全没有必然的联系，同步只是保障存在共享数据争用时正确性的手段，若能让一个方法本来就不涉及共享数据，那就不用任何同步措施去保证正确定。

天生线程安全：
+ 可重入代码(Reentrant Code)：纯代码(Pure Code)，指可以在代码执行的任何时刻中断它，转而去执行另外一段代码(包括递归调用它本身)，而在控制
  权返回后，原来的程序不会出现任何错误，也不会对结果有影响。
  在特指多线程的上下文语境里(不涉及信号量等因素)，可以认为可重入代码是线程安全代码的一个真子集，意味着相对线程安全来说，可重入性是更为基础的特性，
  可以保证代码线程安全，即所有可重入的代码时线程安全的，但并非所有线程安全的代码都是可重入的

可重入代码共同特征：不依赖全局变量、存储在堆上的数据和公用的系统资源，用到的状态量都由参数传入，不调用非可重入的方法等。
简单原则判定：若一个方法的返回结过时可以预测的，只要输入相同数据，就返回相同的结果，那满足可重入性，也线程安全

+ 线程本地存储(Thread Local Store)：若一段代码中所需要的数据必须与其他代码共享，那就看这些共享数据的代码是否能保证在同一个线程中执行。若能
  保证，就可以把共享数据的课件范围限制在同一个线程内，这样，无须同步也能保证线程之间不出现数据争用问题。

大部分使用消费队列的架构模式(如生产者-消费者)都会将产品的消费过程限制在一个线程中消费完，最重要的一种应用实例是web交互模型中的一个请求对应一个
服务器线程(Thread-per-Request)的处理方式。这种处理方式的广泛应用使得很多web服务端应用都可以使用线程本地存储来解决线程安全难问题。

java可以用ThreadLocal实现线程本地存储。

### 锁优化
jdk6一项改进项是高效并发，hotSpot虚拟机开发团队在这个版本上花费大量资源去实现各种锁优化技术，如适应性自旋(Adaptive Spining)、锁消除(Lock
Elimination)、锁膨胀(Lock Coarsening)、轻量级锁(Lightweight Locking)、偏向锁(Biased Locking)等，这些技术都是为了在线程之间更高效
地共享数据及解决竞争问题，提高程序的执行效率。

#### 自旋锁与自适应自旋
互斥同步对性能最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态完成，给java虚拟机的并发性带来很大的压力。虚拟机开发团队注意到，
在许多应用上，共享数据的锁定状态只会持续很短一段时间，为了这段时间去挂起和恢复线程并不值得。可以让后面请求锁的线程"稍等一会"，但不放弃处理的
执行时间，看看持有锁的线程是否很快释放锁，为了让线程等待，只须让线程执行一个忙循环(自旋)，这项技术称为称为自旋锁

自旋等待不能代替阻塞，自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间，所以若锁被占用的时间很短，自旋等待的效果非常好，反之则浪费
处理器资源，带来性能的浪费。因此自旋等待的时间必须有一定的限度，若超过了限定的次数仍没有成功获得锁，应当使用传统方式去挂起线程。默认10次，
可以-XX:PreBlockSpin更改

jdk6对自旋锁的优化，引入了自适应的自旋。自旋时间不在固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。若在同一个锁对对象上，
自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机会认为这次自旋也很可能再次成功，进而允许自旋等待持续相对更长时间。反之，若对于
某个锁，自旋很少成功获取过锁，那么以后要获取这个锁时将可能直接省略自旋。
随着程序运行时间的增长及性能监控信息不断完善，虚拟机堆程序锁的状况预测会越来越精准。

#### 锁消除
指虚拟机即时编译器在运行时，对一些代码要求同步，但是检测到不可能存在共享数据竞争的锁进行消除。
主要判定依据来源于逃逸分析的数据支持，若判断到一段代码中，在堆上的所有数据都不会淘一出去被其他线程访问，那可以把他们当做栈上数据对待，认为他们
是线程私有，同步加锁自然无须进行
"a"+"b"+"c"-->StringBuffer().append()其中加锁->进行锁消除

#### 锁粗化
编写代码时，总是推荐将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，为了使得需要同步的操作数量尽可能少，即使存在锁竞争，等待
锁的线程也能尽快拿到锁
但若一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作时出现循环体中，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的开销。

若虚拟机探测到有这样一串零碎的操作都对同一对象加锁，将会把加锁同步的范围扩展(粗化)到整个操作序列的外部。

#### 轻量级锁
新型锁机制，轻量级是相对于使用操作系统互斥量来实现的传统锁而言，传统锁机制被称为重量级锁。
轻量级锁设计的初衷是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗

hotSpot虚拟机的对象头(Object Header)分为两部分，
第一部分用于存储对象自身的运行时数据，如哈希吗(HashCode)、GC分代年龄(Generational GC Age)等。
这部分数据的长度在32和64位虚拟机中占用32和64比特，称为Mark Word。是实现轻量级锁和偏向锁的关键。
第二部分用于存储指向方法区对象类型数据的指针，若是数组对象，还会有一个额外的部分用于存储数组长度。

由于对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间使用效率，Mark Word被设计成一个非固定的动态数据结构，
以便在极小的空间内存储尽量多的信息，会根据对象的状态复用自己的存储空间。
如在32位的hotSpot虚拟机中，对象未被锁定的状态下，Mark Word的32个比特空间有25个比特用于存储哈希吗，4个比特用于存储对象分代年龄，2个比特
用于存储锁标志位，1比特固定位0(表示未进入偏向模式)。
对象除了未被锁定的状态外，还有轻量级锁定、重量级锁定、GC标记、可偏向等几种不同状态。

hotSpot虚拟机对象头Mark Word
|             32bit
锁状态|       25bit         |4bit      |1bit     |2bit
23bit |  2bit      |          |偏向模式  |标志位
未锁定|      对象哈希吗       |分代年龄   |0        |01
轻量级锁定         指向调用栈中锁记录的指针          |00
重量级锁定(锁膨胀)   指向重量级锁的指针              |10
GC标记              空                          |11
可偏向|  线程ID| Epoch      |分代年龄    |1       |01

轻量级锁的工作过程：在代码即将进入同步块的时候，若此同步对象没有被锁定(锁标志位01)，虚拟机首先将当前线程的栈帧中建立一个名为锁记录(Lock Record)
的空间，用于存储锁对象目前的Mark Word的拷贝(称为Displaced Mark Word)
然后，虚拟机将使用CAS操作尝试把对象的Mark Word更新为指向Lock Recode的指针。
若成功，代表该线程拥有了这个对象的锁，并对Mark Word的锁标志位(Mark Word的最后俩比特)转变为00，表示此对象处于轻量级锁定状态。
若失败，意味着至少存在一条线程于当前线程竞争获取该对象的锁。虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，若是，说明当前线程已经拥有了这
个对象的锁，那直接进入同步块继续执行即可，否则说明这个锁对象已经被其他线程抢占，所标志的状态变为10，此时Mark Word中存储的就是指向重量级锁(互斥量)
的指针，后面等待锁的线程也必须进入阻塞状态。

轻量级锁的解锁过程也是通过CAS操作进行，若对象的Mark Word仍然指向线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中复制的Displaced Mark
Word替换回来。假若成功替换，那整个同步过程完成；若替换失败，说明有其他线程尝试过获取该锁，就要在释放锁的同时，唤醒被挂起的线程。

轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都不存在竞争的”这一经验法则。若没有竞争，轻量级锁便通过CAS操作成功避免了使用
互斥量的开销；但若确实存在锁竞争，除了互斥量的本身开销，还额外发生了CAS操作开销，因此在有竞争的情况下，轻量级锁反而比传统的重量级锁更慢。

#### 偏向锁
目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。
若说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁是在无竞争的情况下把整个同步都消除掉，连CAS都不做。

意思是整个锁会偏向于第一个获取它的线程，若在接下来的执行过程中，该锁一直没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。

当锁对象第一次被线程获取时，虚拟机将会把对象头中的标志位设置01，把偏向模式设置为1，表示进入偏向模式。同时用CAS把后去到的这个锁的线程的ID记录在
对象的Mark Word中。若CAS成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作(如加锁、解锁及对Mark Word
的更新等)

一旦出现另外一个线程尝试获取这个锁的情况，偏向模式马上结束。根据锁对象的目前是否处于被锁定的状态决定是否撤销偏向(偏向模式设为0)，撤销后标志位
恢复到未锁定(标志位01)或轻量级锁定(标志位00)的状态，后续的同步操作就按照轻量级锁那样执行。
--看样子是未锁定->先偏向，然后是未锁定、轻量级锁定，然后是重量级

当一个对象已经计算过一致性哈希吗后，就再也无法进入偏向锁状态了；当一个对象当前正处于偏向锁状态，又都到需要计算其一致性哈希吗请求时，他的偏向状态
被立即撤销，并且锁会膨胀为重量级锁。在重量级锁实现中，对象头指向了重量级锁的位置，代表重量级锁的ObjectMonitor类里有字段可以记录非加锁状态(标志
位为01)下的Mark Word，自然可以存储原来的哈希吗

偏向锁可以提高带有同步但无竞争的程序性能，但同样是一个有效益权衡(Trade Off)性质的优化。
若程序中大多数的锁总是被多个不同的线程访问，那偏向模式就是多余。在具体问题具体分析下，有时用-XX:-UseBiasedLocking来禁止偏向锁优化反而提升性能。

能够写出高性能、高伸缩性的并发程序是一门艺术，了解并发在系统底层是如何实现的，是掌握这门艺术的前提条件，也是称为高级工程师的必备知识之一

